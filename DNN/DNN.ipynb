{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd168d4",
   "metadata": {},
   "source": [
    "# DNN\n",
    "1. 把all_keys.csv, ESun_public_y_answer.csv加到工作區\n",
    "2. 調整 # Main 下方的兩個block，第一個調參數，第二個建network\n",
    "3. 其他block應該不需要動\n",
    "4. 最後一個block會印成績"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b3266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c48c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db01d53",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6647343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 1vHDhZSPmhithLVRRzkNw0ak_kk7PhInu # V_trade\n",
    "# !gdown 145T8z3XXlsaISzWdrJgJVANGokG1XuFI # V_remit\n",
    "# !gdown 1AubrUmeNUgpgiOu4tay6Gwl8O3lBaokF # V_info\n",
    "# !gdown 1zZo9RLt3mMmJZxEETSY2g9ND31qkZIn0 # V_cred\n",
    "# !gdown 1uFCx21bqE3FnrdfvN_mwtw2-nvogTEex # V_cons\n",
    "# !gdown 1ZOXGT_rIdEGIliHGKEH3ha77ZlZyq1Gn # train_y\n",
    "# !gdown 1qjEwmi97OWdshSNdgQj2ccXnoM4UvT25 # V_trade_public\n",
    "# !gdown 1g8trBiC6OxuoTU94u_UMygVrA-fSASpB # V_remit_public\n",
    "# !gdown 14KTfY56Mz2xBXdP27GvGB2HVeb_4Ks4T # V_info_public\n",
    "# !gdown 1EaIWnjQxUl4KRgVCqYT7AB4PaSNvc_GL # V_cred_public\n",
    "# !gdown 1owf1urxHZywAxJfCgVXCpXEMQ6VZGhnO # V_cons_public\n",
    "# !gdown 1LbF8RTlCAuSm_78kA7oLaj91MxlZqhro # public_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf319e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cons = pd.read_csv('V_cons.csv').iloc[:, 1:]\n",
    "V_cred = pd.read_csv('V_cred.csv').iloc[:, 1:]\n",
    "V_info = pd.read_csv('V_info.csv').iloc[:, 1:]\n",
    "V_remit = pd.read_csv('V_remit.csv').iloc[:, 1:]\n",
    "V_trade = pd.read_csv('V_trade.csv').iloc[:, 1:]\n",
    "train_y = pd.read_csv('train_y.csv').iloc[:, 1:]\n",
    "\n",
    "V_cons_public = pd.read_csv('V_cons_public.csv').iloc[:, 1:]\n",
    "V_cred_public = pd.read_csv('V_cred_public.csv').iloc[:, 1:]\n",
    "V_info_public = pd.read_csv('V_info_public.csv').iloc[:, 1:]\n",
    "V_remit_public = pd.read_csv('V_remit_public.csv').iloc[:, 1:]\n",
    "V_trade_public = pd.read_csv('V_trade_public.csv').iloc[:, 1:]\n",
    "public_y = pd.read_csv('public_y.csv').iloc[:, 1:]\n",
    "\n",
    "all_keys = pd.read_csv('all_keys.csv')\n",
    "ESun_public_y_answer = pd.read_csv('ESun_public_y_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee62d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_overall = pd.concat([V_info, V_cred, V_cons, V_remit, V_trade], axis=1).fillna(0)\n",
    "V_overall_public = pd.concat([V_info_public, V_cred_public, V_cons_public, V_remit_public, V_trade_public], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fa34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23906, 4)\n",
      "(23906, 117)\n",
      "(23906, 1965)\n",
      "(23906, 1572)\n",
      "(23906, 3537)\n",
      "(23906, 7195)\n",
      "\n",
      "(1845, 4)\n",
      "(1845, 117)\n",
      "(1845, 1965)\n",
      "(1845, 1572)\n",
      "(1845, 3537)\n",
      "(1845, 7195)\n",
      "\n",
      "(23906, 1)\n",
      "(1845, 1)\n",
      "\n",
      "(25751, 1)\n",
      "(1845, 2)\n"
     ]
    }
   ],
   "source": [
    "print(V_info.shape)\n",
    "print(V_cred.shape)\n",
    "print(V_cons.shape)\n",
    "print(V_remit.shape)\n",
    "print(V_trade.shape)\n",
    "print(V_overall.shape)\n",
    "print()\n",
    "print(V_info_public.shape)\n",
    "print(V_cred_public.shape)\n",
    "print(V_cons_public.shape)\n",
    "print(V_remit_public.shape)\n",
    "print(V_trade_public.shape)\n",
    "print(V_overall_public.shape)\n",
    "print()\n",
    "print(train_y.shape)\n",
    "print(public_y.shape)\n",
    "print()\n",
    "print(all_keys.shape)\n",
    "print(ESun_public_y_answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c111eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = torch.tensor(V_overall.values).to(torch.float32)\n",
    "# print(torch.any(torch.isnan(instance)))\n",
    "# for row in range(len(instance)):\n",
    "#     for i in instance[row]:\n",
    "#         if torch.isnan(i):\n",
    "#             print(row, instance[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5548a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "1840  0\n",
      "1841  0\n",
      "1842  0\n",
      "1843  0\n",
      "1844  0\n",
      "\n",
      "[1845 rows x 1 columns]\n",
      "0    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(public_y)\n",
    "print(public_y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa743e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1845 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "1840  0\n",
       "1841  0\n",
       "1842  0\n",
       "1843  0\n",
       "1844  0\n",
       "\n",
       "[1845 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424a177",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f65b89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_epoch = 500\n",
    "batch = 128 #\n",
    "lr = 0.0000001\n",
    "w = 1\n",
    "d = 99 # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72ca6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.network = nn.Sequential( # 7195 -> 1\n",
    "            nn.Linear(7195, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid() # last one must be sigmoid \n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d43d74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prob, ans):\n",
    "    #print(prob, ans)\n",
    "    return (w * (1 - prob) * ans + (prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3ad1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, val_data, model, n_epoch, batch, lr, device):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_loss = 1000000\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        idx = 0\n",
    "        for data, ans in train_data:\n",
    "            data, ans = data.to(device), ans.to(device)\n",
    "            prob = model(data)\n",
    "            loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += (loss.item() / len(train_data))\n",
    "            print('[Epoch %d | %d/%d] loss: %.4f' % ((epoch+1), idx*batch, len(train_data) * batch, loss.item()), end='\\r')\n",
    "            idx += 1\n",
    "        print(\"\\n  Training  | Loss:%.4f \" % total_loss)\n",
    "\n",
    "        # validation set\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        idx = 0 \n",
    "        with torch.no_grad():\n",
    "            for data, ans in val_data:\n",
    "                data, ans = data.to(device), ans.to(device)\n",
    "                prob = model(data)\n",
    "                loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "                total_loss += (loss.item() / len(val_data))\n",
    "                idx += 1\n",
    "            print(\" Validation | Loss:%.4f \" % total_loss)\n",
    "        # save model\n",
    "        if total_loss < best_loss:\n",
    "                best_loss = total_loss\n",
    "                print(\"saving model with loss %.4f...\\n\" % total_loss)\n",
    "                torch.save(model.state_dict(), \"%s\" % \"model.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93609199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # oversampling\n",
    "        print(\"Train\")\n",
    "        V_overall_list = V_overall.values.tolist()\n",
    "        train_y_list = train_y.values.tolist()\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_list[i][0] == 1:\n",
    "                V_overall_list.extend([V_overall_list[i] for j in range(d)])\n",
    "                train_y_list.extend([train_y_list[i] for j in range(d)])\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_list).to(torch.float32)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        print(\"Val\")\n",
    "        V_overall_public_list = V_overall_public.values.tolist()\n",
    "        train_y_public_list = public_y.values.tolist()\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_public_list[i][0] == 1:\n",
    "                V_overall_public_list.extend([V_overall_public_list[i] for j in range(d)])\n",
    "                train_y_public_list.extend([train_y_public_list[i] for j in range(d)])\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_public_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_public_list).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.tensor(V_overall_public.values).to(torch.float32)\n",
    "        self.Y = torch.tensor(public_y.values).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ba0c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Before: total=: 23906 flag=0: 23672 flag=1: 234 SAR_rate= 0.009788337655818623\n",
      "After: total=: 47072 flag=0: 23672 flag=1: 23400 SAR_rate= 0.4971108089734874\n",
      "Val\n",
      "Before: total=: 1845 flag=0: 1834 flag=1: 11 SAR_rate= 0.005962059620596206\n",
      "After: total=: 2934 flag=0: 1834 flag=1: 1100 SAR_rate= 0.37491479209270623\n"
     ]
    }
   ],
   "source": [
    "trainset = TrainDataset()\n",
    "valset = ValDataset()\n",
    "train_dataloader = DataLoader(trainset, batch, True)\n",
    "val_dataloader = DataLoader(valset, batch, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f226b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | 46976/47104] loss: 0.2788\n",
      "  Training  | Loss:0.4408 \n",
      " Validation | Loss:0.3647 \n",
      "saving model with loss 0.3647...\n",
      "\n",
      "[Epoch 2 | 46976/47104] loss: 0.3442\n",
      "  Training  | Loss:0.4171 \n",
      " Validation | Loss:0.4091 \n",
      "[Epoch 3 | 46976/47104] loss: 0.2964\n",
      "  Training  | Loss:0.3975 \n",
      " Validation | Loss:0.3712 \n",
      "[Epoch 4 | 46976/47104] loss: 0.3073\n",
      "  Training  | Loss:0.3853 \n",
      " Validation | Loss:0.3503 \n",
      "saving model with loss 0.3503...\n",
      "\n",
      "[Epoch 5 | 46976/47104] loss: 0.3306\n",
      "  Training  | Loss:0.3762 \n",
      " Validation | Loss:0.3437 \n",
      "saving model with loss 0.3437...\n",
      "\n",
      "[Epoch 6 | 46976/47104] loss: 0.2669\n",
      "  Training  | Loss:0.3659 \n",
      " Validation | Loss:0.3321 \n",
      "saving model with loss 0.3321...\n",
      "\n",
      "[Epoch 7 | 46976/47104] loss: 0.2241\n",
      "  Training  | Loss:0.3560 \n",
      " Validation | Loss:0.3165 \n",
      "saving model with loss 0.3165...\n",
      "\n",
      "[Epoch 8 | 46976/47104] loss: 0.2602\n",
      "  Training  | Loss:0.3500 \n",
      " Validation | Loss:0.3065 \n",
      "saving model with loss 0.3065...\n",
      "\n",
      "[Epoch 9 | 46976/47104] loss: 0.2764\n",
      "  Training  | Loss:0.3402 \n",
      " Validation | Loss:0.2998 \n",
      "saving model with loss 0.2998...\n",
      "\n",
      "[Epoch 10 | 46976/47104] loss: 0.2922\n",
      "  Training  | Loss:0.3322 \n",
      " Validation | Loss:0.2973 \n",
      "saving model with loss 0.2973...\n",
      "\n",
      "[Epoch 11 | 46976/47104] loss: 0.2575\n",
      "  Training  | Loss:0.3245 \n",
      " Validation | Loss:0.3043 \n",
      "[Epoch 12 | 46976/47104] loss: 0.2049\n",
      "  Training  | Loss:0.3167 \n",
      " Validation | Loss:0.2951 \n",
      "saving model with loss 0.2951...\n",
      "\n",
      "[Epoch 13 | 46976/47104] loss: 0.3039\n",
      "  Training  | Loss:0.3104 \n",
      " Validation | Loss:0.2834 \n",
      "saving model with loss 0.2834...\n",
      "\n",
      "[Epoch 14 | 46976/47104] loss: 0.2526\n",
      "  Training  | Loss:0.3014 \n",
      " Validation | Loss:0.2734 \n",
      "saving model with loss 0.2734...\n",
      "\n",
      "[Epoch 15 | 46976/47104] loss: 0.1970\n",
      "  Training  | Loss:0.2970 \n",
      " Validation | Loss:0.2697 \n",
      "saving model with loss 0.2697...\n",
      "\n",
      "[Epoch 16 | 46976/47104] loss: 0.2355\n",
      "  Training  | Loss:0.2918 \n",
      " Validation | Loss:0.2646 \n",
      "saving model with loss 0.2646...\n",
      "\n",
      "[Epoch 17 | 46976/47104] loss: 0.2234\n",
      "  Training  | Loss:0.2833 \n",
      " Validation | Loss:0.2580 \n",
      "saving model with loss 0.2580...\n",
      "\n",
      "[Epoch 18 | 46976/47104] loss: 0.1497\n",
      "  Training  | Loss:0.2798 \n",
      " Validation | Loss:0.2869 \n",
      "[Epoch 19 | 46976/47104] loss: 0.1320\n",
      "  Training  | Loss:0.2763 \n",
      " Validation | Loss:0.2824 \n",
      "[Epoch 20 | 46976/47104] loss: 0.1793\n",
      "  Training  | Loss:0.2736 \n",
      " Validation | Loss:0.2776 \n",
      "[Epoch 21 | 46976/47104] loss: 0.2107\n",
      "  Training  | Loss:0.2695 \n",
      " Validation | Loss:0.2716 \n",
      "[Epoch 22 | 46976/47104] loss: 0.1685\n",
      "  Training  | Loss:0.2649 \n",
      " Validation | Loss:0.2961 \n",
      "[Epoch 23 | 46976/47104] loss: 0.1793\n",
      "  Training  | Loss:0.2615 \n",
      " Validation | Loss:0.2921 \n",
      "[Epoch 24 | 46976/47104] loss: 0.2030\n",
      "  Training  | Loss:0.2585 \n",
      " Validation | Loss:0.2896 \n",
      "[Epoch 25 | 46976/47104] loss: 0.2570\n",
      "  Training  | Loss:0.2542 \n",
      " Validation | Loss:0.2861 \n",
      "[Epoch 26 | 46976/47104] loss: 0.2107\n",
      "  Training  | Loss:0.2519 \n",
      " Validation | Loss:0.2826 \n",
      "[Epoch 27 | 46976/47104] loss: 0.1335\n",
      "  Training  | Loss:0.2468 \n",
      " Validation | Loss:0.2781 \n",
      "[Epoch 28 | 46976/47104] loss: 0.1548\n",
      "  Training  | Loss:0.2450 \n",
      " Validation | Loss:0.3060 \n",
      "[Epoch 29 | 46976/47104] loss: 0.2367\n",
      "  Training  | Loss:0.2455 \n",
      " Validation | Loss:0.3024 \n",
      "[Epoch 30 | 46976/47104] loss: 0.1487\n",
      "  Training  | Loss:0.2428 \n",
      " Validation | Loss:0.2997 \n",
      "[Epoch 31 | 46976/47104] loss: 0.2079\n",
      "  Training  | Loss:0.2409 \n",
      " Validation | Loss:0.2979 \n",
      "[Epoch 32 | 46976/47104] loss: 0.2310\n",
      "  Training  | Loss:0.2388 \n",
      " Validation | Loss:0.2933 \n",
      "[Epoch 33 | 46976/47104] loss: 0.1640\n",
      "  Training  | Loss:0.2348 \n",
      " Validation | Loss:0.2916 \n",
      "[Epoch 34 | 46976/47104] loss: 0.1744\n",
      "  Training  | Loss:0.2312 \n",
      " Validation | Loss:0.2854 \n",
      "[Epoch 35 | 46976/47104] loss: 0.1876\n",
      "  Training  | Loss:0.2289 \n",
      " Validation | Loss:0.3169 \n",
      "[Epoch 36 | 46976/47104] loss: 0.2027\n",
      "  Training  | Loss:0.2270 \n",
      " Validation | Loss:0.3148 \n",
      "[Epoch 37 | 46976/47104] loss: 0.1129\n",
      "  Training  | Loss:0.2255 \n",
      " Validation | Loss:0.3124 \n",
      "[Epoch 38 | 46976/47104] loss: 0.2010\n",
      "  Training  | Loss:0.2240 \n",
      " Validation | Loss:0.3108 \n",
      "[Epoch 39 | 46976/47104] loss: 0.2133\n",
      "  Training  | Loss:0.2223 \n",
      " Validation | Loss:0.3073 \n",
      "[Epoch 40 | 46976/47104] loss: 0.2016\n",
      "  Training  | Loss:0.2197 \n",
      " Validation | Loss:0.3044 \n",
      "[Epoch 41 | 46976/47104] loss: 0.1326\n",
      "  Training  | Loss:0.2184 \n",
      " Validation | Loss:0.3033 \n",
      "[Epoch 42 | 46976/47104] loss: 0.1765\n",
      "  Training  | Loss:0.2168 \n",
      " Validation | Loss:0.3006 \n",
      "[Epoch 43 | 30592/47104] loss: 0.1600\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_356/870323459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_356/1691746710.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, val_data, model, n_epoch, batch, lr, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model = Net().to(device) \n",
    "model = train(train_dataloader, val_dataloader, model, n_epoch, batch, lr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f183c",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "269463ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "best_model = best_model.eval()\n",
    "\n",
    "testset = TestDataset()\n",
    "test_dataloader = DataLoader(testset, 1, False)\n",
    "result = []\n",
    "for x, _ in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    result.append(best_model(x).item())\n",
    "print(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3bcdf616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.65073e+05 1.00000e+00]\n",
      " [3.58988e+05 1.00000e+00]\n",
      " [3.59393e+05 1.00000e+00]\n",
      " ...\n",
      " [3.61851e+05 0.00000e+00]\n",
      " [3.63895e+05 0.00000e+00]\n",
      " [3.58472e+05 0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "keys_to_predict = sorted(ESun_public_y_answer['alert_key'].values.tolist())\n",
    "pairs = np.array(list(zip(keys_to_predict, result)))\n",
    "sorted_pairs = np.flip(pairs[pairs[:, 1].argsort()], 0)\n",
    "print(sorted_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39f1e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "1174\n",
      "score:  0.008517887563884156\n"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "SAR_count = 0\n",
    "for key, flag in ESun_public_y_answer.values.tolist():\n",
    "    if flag == 1:\n",
    "        SAR_count += 1\n",
    "        for idx in range(len(sorted_pairs)):\n",
    "            if key == sorted_pairs[idx][0]:\n",
    "                index_list.append(idx + 1)\n",
    "                break\n",
    "print(len(index_list))\n",
    "print(SAR_count)\n",
    "index_list.sort()\n",
    "print(index_list[-2])\n",
    "print(\"score: \", str((SAR_count - 1) / index_list[-2]))\n",
    "\n",
    "# 0.01, 0.05, 0.1, 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9eafb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['alert_key','probability'])\n",
    "    for row in sorted_pairs:\n",
    "        writer.writerow([int(row[0]), row[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c4569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e318ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
