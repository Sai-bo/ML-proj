{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd168d4",
   "metadata": {},
   "source": [
    "# DNN\n",
    "1. 把all_keys.csv, ESun_public_y_answer.csv加到工作區\n",
    "2. 調整 # Main 下方的兩個block，第一個調參數，第二個建network\n",
    "3. 其他block應該不需要動\n",
    "4. 最後一個block會印成績"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb364be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c48c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db01d53",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6647343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 1vHDhZSPmhithLVRRzkNw0ak_kk7PhInu # V_trade\n",
    "# !gdown 145T8z3XXlsaISzWdrJgJVANGokG1XuFI # V_remit\n",
    "# !gdown 1AubrUmeNUgpgiOu4tay6Gwl8O3lBaokF # V_info\n",
    "# !gdown 1zZo9RLt3mMmJZxEETSY2g9ND31qkZIn0 # V_cred\n",
    "# !gdown 1uFCx21bqE3FnrdfvN_mwtw2-nvogTEex # V_cons\n",
    "# !gdown 1ZOXGT_rIdEGIliHGKEH3ha77ZlZyq1Gn # train_y\n",
    "# !gdown 1qjEwmi97OWdshSNdgQj2ccXnoM4UvT25 # V_trade_public\n",
    "# !gdown 1g8trBiC6OxuoTU94u_UMygVrA-fSASpB # V_remit_public\n",
    "# !gdown 14KTfY56Mz2xBXdP27GvGB2HVeb_4Ks4T # V_info_public\n",
    "# !gdown 1EaIWnjQxUl4KRgVCqYT7AB4PaSNvc_GL # V_cred_public\n",
    "# !gdown 1owf1urxHZywAxJfCgVXCpXEMQ6VZGhnO # V_cons_public\n",
    "# !gdown 1LbF8RTlCAuSm_78kA7oLaj91MxlZqhro # public_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf319e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cons = pd.read_csv('V_cons.csv').iloc[:, 1:]\n",
    "V_cred = pd.read_csv('V_cred.csv').iloc[:, 1:]\n",
    "V_info = pd.read_csv('V_info.csv').iloc[:, 1:]\n",
    "V_remit = pd.read_csv('V_remit.csv').iloc[:, 1:]\n",
    "V_trade = pd.read_csv('V_trade.csv').iloc[:, 1:]\n",
    "train_y = pd.read_csv('train_y.csv').iloc[:, 1:]\n",
    "\n",
    "V_cons_public = pd.read_csv('V_cons_public.csv').iloc[:, 1:]\n",
    "V_cred_public = pd.read_csv('V_cred_public.csv').iloc[:, 1:]\n",
    "V_info_public = pd.read_csv('V_info_public.csv').iloc[:, 1:]\n",
    "V_remit_public = pd.read_csv('V_remit_public.csv').iloc[:, 1:]\n",
    "V_trade_public = pd.read_csv('V_trade_public.csv').iloc[:, 1:]\n",
    "public_y = pd.read_csv('public_y.csv').iloc[:, 1:]\n",
    "\n",
    "all_keys = pd.read_csv('all_keys.csv')\n",
    "ESun_public_y_answer = pd.read_csv('ESun_public_y_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee62d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_overall = pd.concat([V_info, V_cred, V_cons, V_remit, V_trade], axis=1).fillna(0)\n",
    "V_overall_public = pd.concat([V_info_public, V_cred_public, V_cons_public, V_remit_public, V_trade_public], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fa34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23906, 4)\n",
      "(23906, 117)\n",
      "(23906, 1965)\n",
      "(23906, 1572)\n",
      "(23906, 3537)\n",
      "(23906, 7195)\n",
      "\n",
      "(1845, 4)\n",
      "(1845, 117)\n",
      "(1845, 1965)\n",
      "(1845, 1572)\n",
      "(1845, 3537)\n",
      "(1845, 7195)\n",
      "\n",
      "(23906, 1)\n",
      "(1845, 1)\n",
      "\n",
      "(25751, 1)\n",
      "(1845, 2)\n"
     ]
    }
   ],
   "source": [
    "print(V_info.shape)\n",
    "print(V_cred.shape)\n",
    "print(V_cons.shape)\n",
    "print(V_remit.shape)\n",
    "print(V_trade.shape)\n",
    "print(V_overall.shape)\n",
    "print()\n",
    "print(V_info_public.shape)\n",
    "print(V_cred_public.shape)\n",
    "print(V_cons_public.shape)\n",
    "print(V_remit_public.shape)\n",
    "print(V_trade_public.shape)\n",
    "print(V_overall_public.shape)\n",
    "print()\n",
    "print(train_y.shape)\n",
    "print(public_y.shape)\n",
    "print()\n",
    "print(all_keys.shape)\n",
    "print(ESun_public_y_answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c111eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = torch.tensor(V_overall.values).to(torch.float32)\n",
    "# print(torch.any(torch.isnan(instance)))\n",
    "# for row in range(len(instance)):\n",
    "#     for i in instance[row]:\n",
    "#         if torch.isnan(i):\n",
    "#             print(row, instance[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5548a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "1840  0\n",
      "1841  0\n",
      "1842  0\n",
      "1843  0\n",
      "1844  0\n",
      "\n",
      "[1845 rows x 1 columns]\n",
      "0    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(public_y)\n",
    "print(public_y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa743e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1845 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "1840  0\n",
       "1841  0\n",
       "1842  0\n",
       "1843  0\n",
       "1844  0\n",
       "\n",
       "[1845 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c4c9b0",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e5e66",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3154f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set parameters\n",
    "# n_epoch = 500\n",
    "# batch = 128 \n",
    "# lr = 0.0000001\n",
    "# w = 1\n",
    "# d = 99 # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b09cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define network\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.network = nn.Sequential( # 7195 -> 1\n",
    "#             nn.Linear(7195, 2048),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(2048, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1024, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16, 1),\n",
    "#             nn.Sigmoid() # last one must be sigmoid \n",
    "#         )\n",
    "                \n",
    "#     def forward(self, x):\n",
    "#         x = self.network(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376671f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_function(prob, ans):\n",
    "#     #print(prob, ans)\n",
    "#     return (w * (1 - prob) * ans + (prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ebb17",
   "metadata": {},
   "source": [
    "### quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_epoch = 500\n",
    "batch = 128 \n",
    "lr = 0.000001\n",
    "w = 1\n",
    "d = 99 # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a59eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.network = nn.Sequential( # 7195 -> 1\n",
    "            nn.Linear(7195, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid() # last one must be sigmoid   \n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prob, ans):\n",
    "    #print(prob, ans)\n",
    "    # a * x**n\n",
    "    a = 4\n",
    "    n = 2\n",
    "    return (w * a * (1 - prob)**n * ans + a * (prob)**n * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82971f",
   "metadata": {},
   "source": [
    "### log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9541e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob = torch.minimum(prob, torch.full((prob.size(dim=0), 1), 0.9999999).to(device))\n",
    "# prob = torch.maximum(prob, torch.full((prob.size(dim=0), 1), 0.0000001).to(device))\n",
    "# return (w * torch.log(1 - prob) * ans + torch.log(prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424a177",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3ad1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, val_data, model, n_epoch, batch, lr, device):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_loss = 1000000\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        idx = 0\n",
    "        for data, ans in train_data:\n",
    "            data, ans = data.to(device), ans.to(device)\n",
    "            prob = model(data)\n",
    "            loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += (loss.item() / len(train_data))\n",
    "            print('[Epoch %d | %d/%d] loss: %.4f' % ((epoch+1), idx*batch, len(train_data) * batch, loss.item()), end='\\r')\n",
    "            idx += 1\n",
    "        print(\"\\n  Training  | Loss:%.4f \" % total_loss)\n",
    "\n",
    "        # validation set\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        idx = 0 \n",
    "        with torch.no_grad():\n",
    "            for data, ans in val_data:\n",
    "                data, ans = data.to(device), ans.to(device)\n",
    "                prob = model(data)\n",
    "                loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "                total_loss += (loss.item() / len(val_data))\n",
    "                idx += 1\n",
    "            print(\" Validation | Loss:%.4f \" % total_loss)\n",
    "        # save model\n",
    "        if total_loss < best_loss:\n",
    "                best_loss = total_loss\n",
    "                print(\"saving model with loss %.4f...\\n\" % total_loss)\n",
    "                torch.save(model.state_dict(), \"%s\" % \"model.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93609199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # oversampling\n",
    "        print(\"Train\")\n",
    "        V_overall_list = V_overall.values.tolist()\n",
    "        train_y_list = train_y.values.tolist()\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_list[i][0] == 1:\n",
    "                V_overall_list.extend([V_overall_list[i] for j in range(d)])\n",
    "                train_y_list.extend([train_y_list[i] for j in range(d)])\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_list).to(torch.float32)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        print(\"Val\")\n",
    "        V_overall_public_list = V_overall_public.values.tolist()\n",
    "        train_y_public_list = public_y.values.tolist()\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_public_list[i][0] == 1:\n",
    "                V_overall_public_list.extend([V_overall_public_list[i] for j in range(d)])\n",
    "                train_y_public_list.extend([train_y_public_list[i] for j in range(d)])\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_public_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_public_list).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.tensor(V_overall_public.values).to(torch.float32)\n",
    "        self.Y = torch.tensor(public_y.values).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ba0c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Before: total=: 23906 flag=0: 23672 flag=1: 234 SAR_rate= 0.009788337655818623\n",
      "After: total=: 47072 flag=0: 23672 flag=1: 23400 SAR_rate= 0.4971108089734874\n",
      "Val\n",
      "Before: total=: 1845 flag=0: 1834 flag=1: 11 SAR_rate= 0.005962059620596206\n",
      "After: total=: 2934 flag=0: 1834 flag=1: 1100 SAR_rate= 0.37491479209270623\n"
     ]
    }
   ],
   "source": [
    "trainset = TrainDataset()\n",
    "valset = ValDataset()\n",
    "train_dataloader = DataLoader(trainset, batch, True)\n",
    "val_dataloader = DataLoader(valset, batch, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9f226b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | 46976/47104] loss: 1.5246\n",
      "  Training  | Loss:1.7234 \n",
      " Validation | Loss:1.8349 \n",
      "saving model with loss 1.8349...\n",
      "\n",
      "[Epoch 2 | 46976/47104] loss: 0.8598\n",
      "  Training  | Loss:1.5688 \n",
      " Validation | Loss:1.9139 \n",
      "[Epoch 3 | 46976/47104] loss: 1.3341\n",
      "  Training  | Loss:1.5009 \n",
      " Validation | Loss:1.7962 \n",
      "saving model with loss 1.7962...\n",
      "\n",
      "[Epoch 4 | 46976/47104] loss: 1.2007\n",
      "  Training  | Loss:1.4871 \n",
      " Validation | Loss:1.8148 \n",
      "[Epoch 5 | 46976/47104] loss: 1.0858\n",
      "  Training  | Loss:1.4753 \n",
      " Validation | Loss:1.7724 \n",
      "saving model with loss 1.7724...\n",
      "\n",
      "[Epoch 6 | 46976/47104] loss: 1.1186\n",
      "  Training  | Loss:1.4712 \n",
      " Validation | Loss:1.7777 \n",
      "[Epoch 7 | 46976/47104] loss: 1.1971\n",
      "  Training  | Loss:1.4594 \n",
      " Validation | Loss:1.7495 \n",
      "saving model with loss 1.7495...\n",
      "\n",
      "[Epoch 8 | 46976/47104] loss: 1.1875\n",
      "  Training  | Loss:1.4605 \n",
      " Validation | Loss:1.7289 \n",
      "saving model with loss 1.7289...\n",
      "\n",
      "[Epoch 9 | 46976/47104] loss: 1.0775\n",
      "  Training  | Loss:1.4611 \n",
      " Validation | Loss:1.7310 \n",
      "[Epoch 10 | 46976/47104] loss: 1.3183\n",
      "  Training  | Loss:1.4623 \n",
      " Validation | Loss:1.6977 \n",
      "saving model with loss 1.6977...\n",
      "\n",
      "[Epoch 11 | 46976/47104] loss: 0.8619\n",
      "  Training  | Loss:1.4524 \n",
      " Validation | Loss:1.6739 \n",
      "saving model with loss 1.6739...\n",
      "\n",
      "[Epoch 12 | 46976/47104] loss: 0.7021\n",
      "  Training  | Loss:1.4472 \n",
      " Validation | Loss:1.6656 \n",
      "saving model with loss 1.6656...\n",
      "\n",
      "[Epoch 13 | 46976/47104] loss: 1.3418\n",
      "  Training  | Loss:1.4435 \n",
      " Validation | Loss:1.6435 \n",
      "saving model with loss 1.6435...\n",
      "\n",
      "[Epoch 14 | 46976/47104] loss: 1.1009\n",
      "  Training  | Loss:1.4496 \n",
      " Validation | Loss:1.6226 \n",
      "saving model with loss 1.6226...\n",
      "\n",
      "[Epoch 15 | 46976/47104] loss: 1.0532\n",
      "  Training  | Loss:1.4554 \n",
      " Validation | Loss:1.6144 \n",
      "saving model with loss 1.6144...\n",
      "\n",
      "[Epoch 16 | 46976/47104] loss: 1.1007\n",
      "  Training  | Loss:1.4579 \n",
      " Validation | Loss:1.5963 \n",
      "saving model with loss 1.5963...\n",
      "\n",
      "[Epoch 17 | 46976/47104] loss: 0.9900\n",
      "  Training  | Loss:1.4553 \n",
      " Validation | Loss:1.5876 \n",
      "saving model with loss 1.5876...\n",
      "\n",
      "[Epoch 18 | 46976/47104] loss: 1.1120\n",
      "  Training  | Loss:1.4564 \n",
      " Validation | Loss:1.5694 \n",
      "saving model with loss 1.5694...\n",
      "\n",
      "[Epoch 19 | 46976/47104] loss: 0.9266\n",
      "  Training  | Loss:1.4633 \n",
      " Validation | Loss:1.5691 \n",
      "saving model with loss 1.5691...\n",
      "\n",
      "[Epoch 20 | 46976/47104] loss: 1.0208\n",
      "  Training  | Loss:1.4619 \n",
      " Validation | Loss:1.5718 \n",
      "[Epoch 21 | 46976/47104] loss: 1.0381\n",
      "  Training  | Loss:1.4592 \n",
      " Validation | Loss:1.5592 \n",
      "saving model with loss 1.5592...\n",
      "\n",
      "[Epoch 22 | 46976/47104] loss: 1.0758\n",
      "  Training  | Loss:1.4572 \n",
      " Validation | Loss:1.5605 \n",
      "[Epoch 23 | 46976/47104] loss: 1.2944\n",
      "  Training  | Loss:1.4547 \n",
      " Validation | Loss:1.5578 \n",
      "saving model with loss 1.5578...\n",
      "\n",
      "[Epoch 24 | 46976/47104] loss: 1.1188\n",
      "  Training  | Loss:1.4536 \n",
      " Validation | Loss:1.5561 \n",
      "saving model with loss 1.5561...\n",
      "\n",
      "[Epoch 25 | 46976/47104] loss: 0.9708\n",
      "  Training  | Loss:1.4522 \n",
      " Validation | Loss:1.5550 \n",
      "saving model with loss 1.5550...\n",
      "\n",
      "[Epoch 26 | 46976/47104] loss: 0.9626\n",
      "  Training  | Loss:1.4515 \n",
      " Validation | Loss:1.5559 \n",
      "[Epoch 27 | 46976/47104] loss: 1.2252\n",
      "  Training  | Loss:1.4510 \n",
      " Validation | Loss:1.5553 \n",
      "[Epoch 28 | 46976/47104] loss: 1.0189\n",
      "  Training  | Loss:1.4498 \n",
      " Validation | Loss:1.5549 \n",
      "saving model with loss 1.5549...\n",
      "\n",
      "[Epoch 29 | 46976/47104] loss: 0.9119\n",
      "  Training  | Loss:1.4491 \n",
      " Validation | Loss:1.5549 \n",
      "saving model with loss 1.5549...\n",
      "\n",
      "[Epoch 30 | 46976/47104] loss: 0.9694\n",
      "  Training  | Loss:1.4481 \n",
      " Validation | Loss:1.5507 \n",
      "saving model with loss 1.5507...\n",
      "\n",
      "[Epoch 31 | 46976/47104] loss: 1.1628\n",
      "  Training  | Loss:1.4467 \n",
      " Validation | Loss:1.5520 \n",
      "[Epoch 32 | 46976/47104] loss: 1.3125\n",
      "  Training  | Loss:1.4486 \n",
      " Validation | Loss:1.5529 \n",
      "[Epoch 33 | 46976/47104] loss: 1.0507\n",
      "  Training  | Loss:1.4514 \n",
      " Validation | Loss:1.5507 \n",
      "saving model with loss 1.5507...\n",
      "\n",
      "[Epoch 34 | 46976/47104] loss: 1.0058\n",
      "  Training  | Loss:1.4657 \n",
      " Validation | Loss:1.5493 \n",
      "saving model with loss 1.5493...\n",
      "\n",
      "[Epoch 35 | 46976/47104] loss: 1.0315\n",
      "  Training  | Loss:1.4611 \n",
      " Validation | Loss:1.5574 \n",
      "[Epoch 36 | 46976/47104] loss: 1.2188\n",
      "  Training  | Loss:1.4594 \n",
      " Validation | Loss:1.5560 \n",
      "[Epoch 37 | 46976/47104] loss: 1.1991\n",
      "  Training  | Loss:1.4581 \n",
      " Validation | Loss:1.5560 \n",
      "[Epoch 38 | 46976/47104] loss: 1.0242\n",
      "  Training  | Loss:1.4569 \n",
      " Validation | Loss:1.5533 \n",
      "[Epoch 39 | 46976/47104] loss: 1.2558\n",
      "  Training  | Loss:1.4511 \n",
      " Validation | Loss:1.5519 \n",
      "[Epoch 40 | 46976/47104] loss: 0.8494\n",
      "  Training  | Loss:1.4435 \n",
      " Validation | Loss:1.5519 \n",
      "[Epoch 41 | 46976/47104] loss: 1.1988\n",
      "  Training  | Loss:1.4424 \n",
      " Validation | Loss:1.5518 \n",
      "[Epoch 42 | 46976/47104] loss: 1.0740\n",
      "  Training  | Loss:1.4472 \n",
      " Validation | Loss:1.5409 \n",
      "saving model with loss 1.5409...\n",
      "\n",
      "[Epoch 43 | 46976/47104] loss: 1.0685\n",
      "  Training  | Loss:1.4476 \n",
      " Validation | Loss:1.5404 \n",
      "saving model with loss 1.5404...\n",
      "\n",
      "[Epoch 44 | 46976/47104] loss: 1.1430\n",
      "  Training  | Loss:1.4469 \n",
      " Validation | Loss:1.5370 \n",
      "saving model with loss 1.5370...\n",
      "\n",
      "[Epoch 45 | 46976/47104] loss: 1.2919\n",
      "  Training  | Loss:1.4460 \n",
      " Validation | Loss:1.5368 \n",
      "saving model with loss 1.5368...\n",
      "\n",
      "[Epoch 46 | 46976/47104] loss: 1.4276\n",
      "  Training  | Loss:1.4540 \n",
      " Validation | Loss:1.5313 \n",
      "saving model with loss 1.5313...\n",
      "\n",
      "[Epoch 47 | 46976/47104] loss: 0.8655\n",
      "  Training  | Loss:1.4530 \n",
      " Validation | Loss:1.5313 \n",
      "saving model with loss 1.5313...\n",
      "\n",
      "[Epoch 48 | 46976/47104] loss: 1.1766\n",
      "  Training  | Loss:1.4563 \n",
      " Validation | Loss:1.5313 \n",
      "[Epoch 49 | 46976/47104] loss: 1.0050\n",
      "  Training  | Loss:1.4513 \n",
      " Validation | Loss:1.5313 \n",
      "saving model with loss 1.5313...\n",
      "\n",
      "[Epoch 50 | 46976/47104] loss: 0.9902\n",
      "  Training  | Loss:1.4505 \n",
      " Validation | Loss:1.5301 \n",
      "saving model with loss 1.5301...\n",
      "\n",
      "[Epoch 51 | 46976/47104] loss: 0.8064\n",
      "  Training  | Loss:1.4495 \n",
      " Validation | Loss:1.5299 \n",
      "saving model with loss 1.5299...\n",
      "\n",
      "[Epoch 52 | 46976/47104] loss: 0.9211\n",
      "  Training  | Loss:1.4491 \n",
      " Validation | Loss:1.5298 \n",
      "saving model with loss 1.5298...\n",
      "\n",
      "[Epoch 53 | 46976/47104] loss: 1.0675\n",
      "  Training  | Loss:1.4486 \n",
      " Validation | Loss:1.5298 \n",
      "saving model with loss 1.5298...\n",
      "\n",
      "[Epoch 54 | 46976/47104] loss: 1.0986\n",
      "  Training  | Loss:1.4483 \n",
      " Validation | Loss:1.5298 \n",
      "saving model with loss 1.5298...\n",
      "\n",
      "[Epoch 55 | 46976/47104] loss: 0.9220\n",
      "  Training  | Loss:1.4486 \n",
      " Validation | Loss:1.5299 \n",
      "[Epoch 56 | 46976/47104] loss: 0.8438\n",
      "  Training  | Loss:1.4510 \n",
      " Validation | Loss:1.5257 \n",
      "saving model with loss 1.5257...\n",
      "\n",
      "[Epoch 57 | 46976/47104] loss: 1.3536\n",
      "  Training  | Loss:1.4541 \n",
      " Validation | Loss:1.5256 \n",
      "saving model with loss 1.5256...\n",
      "\n",
      "[Epoch 58 | 46976/47104] loss: 1.0452\n",
      "  Training  | Loss:1.4528 \n",
      " Validation | Loss:1.5311 \n",
      "[Epoch 59 | 46976/47104] loss: 1.1042\n",
      "  Training  | Loss:1.4464 \n",
      " Validation | Loss:1.5256 \n",
      "saving model with loss 1.5256...\n",
      "\n",
      "[Epoch 60 | 46976/47104] loss: 0.8527\n",
      "  Training  | Loss:1.4520 \n",
      " Validation | Loss:1.5256 \n",
      "saving model with loss 1.5256...\n",
      "\n",
      "[Epoch 61 | 46976/47104] loss: 1.0974\n",
      "  Training  | Loss:1.4589 \n",
      " Validation | Loss:1.5255 \n",
      "saving model with loss 1.5255...\n",
      "\n",
      "[Epoch 62 | 46976/47104] loss: 1.0011\n",
      "  Training  | Loss:1.4586 \n",
      " Validation | Loss:1.5160 \n",
      "saving model with loss 1.5160...\n",
      "\n",
      "[Epoch 63 | 46976/47104] loss: 1.2670\n",
      "  Training  | Loss:1.4593 \n",
      " Validation | Loss:1.5160 \n",
      "saving model with loss 1.5160...\n",
      "\n",
      "[Epoch 64 | 46976/47104] loss: 1.0443\n",
      "  Training  | Loss:1.4573 \n",
      " Validation | Loss:1.5160 \n",
      "saving model with loss 1.5160...\n",
      "\n",
      "[Epoch 65 | 46976/47104] loss: 1.0790\n",
      "  Training  | Loss:1.4568 \n",
      " Validation | Loss:1.5159 \n",
      "saving model with loss 1.5159...\n",
      "\n",
      "[Epoch 66 | 46976/47104] loss: 1.2584\n",
      "  Training  | Loss:1.4565 \n",
      " Validation | Loss:1.5159 \n",
      "saving model with loss 1.5159...\n",
      "\n",
      "[Epoch 67 | 46976/47104] loss: 1.0979\n",
      "  Training  | Loss:1.4814 \n",
      " Validation | Loss:1.5159 \n",
      "saving model with loss 1.5159...\n",
      "\n",
      "[Epoch 68 | 46976/47104] loss: 0.9560\n",
      "  Training  | Loss:1.4895 \n",
      " Validation | Loss:1.5158 \n",
      "saving model with loss 1.5158...\n",
      "\n",
      "[Epoch 69 | 46976/47104] loss: 0.7974\n",
      "  Training  | Loss:1.4893 \n",
      " Validation | Loss:1.5158 \n",
      "saving model with loss 1.5158...\n",
      "\n",
      "[Epoch 70 | 46976/47104] loss: 1.2188\n",
      "  Training  | Loss:1.4890 \n",
      " Validation | Loss:1.5158 \n",
      "saving model with loss 1.5158...\n",
      "\n",
      "[Epoch 71 | 46976/47104] loss: 1.1988\n",
      "  Training  | Loss:1.4898 \n",
      " Validation | Loss:1.5158 \n",
      "saving model with loss 1.5158...\n",
      "\n",
      "[Epoch 72 | 46976/47104] loss: 1.0976\n",
      "  Training  | Loss:1.4888 \n",
      " Validation | Loss:1.5158 \n",
      "saving model with loss 1.5158...\n",
      "\n",
      "[Epoch 73 | 46976/47104] loss: 1.1912\n",
      "  Training  | Loss:1.4884 \n",
      " Validation | Loss:1.5157 \n",
      "saving model with loss 1.5157...\n",
      "\n",
      "[Epoch 74 | 46976/47104] loss: 1.3539\n",
      "  Training  | Loss:1.4881 \n",
      " Validation | Loss:1.5157 \n",
      "saving model with loss 1.5157...\n",
      "\n",
      "[Epoch 75 | 46976/47104] loss: 1.1399\n",
      "  Training  | Loss:1.4885 \n",
      " Validation | Loss:1.5157 \n",
      "saving model with loss 1.5157...\n",
      "\n",
      "[Epoch 76 | 46976/47104] loss: 1.1991\n",
      "  Training  | Loss:1.4956 \n",
      " Validation | Loss:1.5157 \n",
      "saving model with loss 1.5157...\n",
      "\n",
      "[Epoch 77 | 46976/47104] loss: 1.1673\n",
      "  Training  | Loss:1.4871 \n",
      " Validation | Loss:1.5156 \n",
      "saving model with loss 1.5156...\n",
      "\n",
      "[Epoch 78 | 46976/47104] loss: 1.3258\n",
      "  Training  | Loss:1.4868 \n",
      " Validation | Loss:1.5156 \n",
      "saving model with loss 1.5156...\n",
      "\n",
      "[Epoch 79 | 46976/47104] loss: 1.0039\n",
      "  Training  | Loss:1.4866 \n",
      " Validation | Loss:1.5156 \n",
      "saving model with loss 1.5156...\n",
      "\n",
      "[Epoch 80 | 46976/47104] loss: 1.2222\n",
      "  Training  | Loss:1.4864 \n",
      " Validation | Loss:1.5156 \n",
      "saving model with loss 1.5156...\n",
      "\n",
      "[Epoch 81 | 46976/47104] loss: 1.1563\n",
      "  Training  | Loss:1.4862 \n",
      " Validation | Loss:1.5155 \n",
      "saving model with loss 1.5155...\n",
      "\n",
      "[Epoch 82 | 46976/47104] loss: 1.2594\n",
      "  Training  | Loss:1.4861 \n",
      " Validation | Loss:1.5155 \n",
      "saving model with loss 1.5155...\n",
      "\n",
      "[Epoch 83 | 46976/47104] loss: 0.9519\n",
      "  Training  | Loss:1.4858 \n",
      " Validation | Loss:1.5155 \n",
      "saving model with loss 1.5155...\n",
      "\n",
      "[Epoch 84 | 46976/47104] loss: 1.1593\n",
      "  Training  | Loss:1.4856 \n",
      " Validation | Loss:1.5155 \n",
      "saving model with loss 1.5155...\n",
      "\n",
      "[Epoch 85 | 46976/47104] loss: 1.1044\n",
      "  Training  | Loss:1.4854 \n",
      " Validation | Loss:1.5154 \n",
      "saving model with loss 1.5154...\n",
      "\n",
      "[Epoch 86 | 46976/47104] loss: 1.1615\n",
      "  Training  | Loss:1.4851 \n",
      " Validation | Loss:1.5154 \n",
      "saving model with loss 1.5154...\n",
      "\n",
      "[Epoch 87 | 46976/47104] loss: 1.0684\n",
      "  Training  | Loss:1.4848 \n",
      " Validation | Loss:1.5154 \n",
      "saving model with loss 1.5154...\n",
      "\n",
      "[Epoch 88 | 46976/47104] loss: 1.1906\n",
      "  Training  | Loss:1.4845 \n",
      " Validation | Loss:1.5153 \n",
      "saving model with loss 1.5153...\n",
      "\n",
      "[Epoch 89 | 46976/47104] loss: 1.1022\n",
      "  Training  | Loss:1.4844 \n",
      " Validation | Loss:1.5153 \n",
      "saving model with loss 1.5153...\n",
      "\n",
      "[Epoch 90 | 46976/47104] loss: 1.1280\n",
      "  Training  | Loss:1.4840 \n",
      " Validation | Loss:1.5153 \n",
      "saving model with loss 1.5153...\n",
      "\n",
      "[Epoch 91 | 46976/47104] loss: 1.0357\n",
      "  Training  | Loss:1.4835 \n",
      " Validation | Loss:1.5152 \n",
      "saving model with loss 1.5152...\n",
      "\n",
      "[Epoch 92 | 46976/47104] loss: 1.3463\n",
      "  Training  | Loss:1.4832 \n",
      " Validation | Loss:1.5138 \n",
      "saving model with loss 1.5138...\n",
      "\n",
      "[Epoch 93 | 46976/47104] loss: 1.2552\n",
      "  Training  | Loss:1.4828 \n",
      " Validation | Loss:1.5138 \n",
      "saving model with loss 1.5138...\n",
      "\n",
      "[Epoch 94 | 46976/47104] loss: 0.8125\n",
      "  Training  | Loss:1.4824 \n",
      " Validation | Loss:1.5138 \n",
      "saving model with loss 1.5138...\n",
      "\n",
      "[Epoch 95 | 46976/47104] loss: 0.9810\n",
      "  Training  | Loss:1.4825 \n",
      " Validation | Loss:1.5137 \n",
      "saving model with loss 1.5137...\n",
      "\n",
      "[Epoch 96 | 46976/47104] loss: 1.1595\n",
      "  Training  | Loss:1.4820 \n",
      " Validation | Loss:1.5137 \n",
      "saving model with loss 1.5137...\n",
      "\n",
      "[Epoch 97 | 46976/47104] loss: 1.1953\n",
      "  Training  | Loss:1.4821 \n",
      " Validation | Loss:1.5137 \n",
      "saving model with loss 1.5137...\n",
      "\n",
      "[Epoch 98 | 46976/47104] loss: 1.2524\n",
      "  Training  | Loss:1.4846 \n",
      " Validation | Loss:1.5109 \n",
      "saving model with loss 1.5109...\n",
      "\n",
      "[Epoch 99 | 46976/47104] loss: 1.1012\n",
      "  Training  | Loss:1.4892 \n",
      " Validation | Loss:1.5109 \n",
      "saving model with loss 1.5109...\n",
      "\n",
      "[Epoch 100 | 46976/47104] loss: 1.2258\n",
      "  Training  | Loss:1.4889 \n",
      " Validation | Loss:1.5109 \n",
      "saving model with loss 1.5109...\n",
      "\n",
      "[Epoch 101 | 46976/47104] loss: 1.0373\n",
      "  Training  | Loss:1.4887 \n",
      " Validation | Loss:1.5041 \n",
      "saving model with loss 1.5041...\n",
      "\n",
      "[Epoch 102 | 46976/47104] loss: 0.9796\n",
      "  Training  | Loss:1.4883 \n",
      " Validation | Loss:1.5040 \n",
      "saving model with loss 1.5040...\n",
      "\n",
      "[Epoch 103 | 46976/47104] loss: 0.9100\n",
      "  Training  | Loss:1.4882 \n",
      " Validation | Loss:1.5040 \n",
      "saving model with loss 1.5040...\n",
      "\n",
      "[Epoch 104 | 46976/47104] loss: 1.3438\n",
      "  Training  | Loss:1.4881 \n",
      " Validation | Loss:1.5040 \n",
      "saving model with loss 1.5040...\n",
      "\n",
      "[Epoch 105 | 46976/47104] loss: 1.0975\n",
      "  Training  | Loss:1.4879 \n",
      " Validation | Loss:1.5040 \n",
      "saving model with loss 1.5040...\n",
      "\n",
      "[Epoch 106 | 46976/47104] loss: 0.8816\n",
      "  Training  | Loss:1.4875 \n",
      " Validation | Loss:1.5040 \n",
      "saving model with loss 1.5040...\n",
      "\n",
      "[Epoch 107 | 46976/47104] loss: 0.7903\n",
      "  Training  | Loss:1.4874 \n",
      " Validation | Loss:1.5039 \n",
      "saving model with loss 1.5039...\n",
      "\n",
      "[Epoch 108 | 46976/47104] loss: 1.2585\n",
      "  Training  | Loss:1.4873 \n",
      " Validation | Loss:1.5039 \n",
      "saving model with loss 1.5039...\n",
      "\n",
      "[Epoch 109 | 46976/47104] loss: 1.0017\n",
      "  Training  | Loss:1.4877 \n",
      " Validation | Loss:1.5039 \n",
      "saving model with loss 1.5039...\n",
      "\n",
      "[Epoch 110 | 46976/47104] loss: 1.0641\n",
      "  Training  | Loss:1.4880 \n",
      " Validation | Loss:1.5039 \n",
      "saving model with loss 1.5039...\n",
      "\n",
      "[Epoch 111 | 46976/47104] loss: 1.1297\n",
      "  Training  | Loss:1.4873 \n",
      " Validation | Loss:1.5039 \n",
      "saving model with loss 1.5039...\n",
      "\n",
      "[Epoch 112 | 46976/47104] loss: 1.2214\n",
      "  Training  | Loss:1.4873 \n",
      " Validation | Loss:1.5039 \n",
      "saving model with loss 1.5039...\n",
      "\n",
      "[Epoch 113 | 46976/47104] loss: 0.9095\n",
      "  Training  | Loss:1.4870 \n",
      " Validation | Loss:1.5038 \n",
      "saving model with loss 1.5038...\n",
      "\n",
      "[Epoch 114 | 46976/47104] loss: 1.0374\n",
      "  Training  | Loss:1.4863 \n",
      " Validation | Loss:1.5038 \n",
      "saving model with loss 1.5038...\n",
      "\n",
      "[Epoch 115 | 46976/47104] loss: 1.0355\n",
      "  Training  | Loss:1.4861 \n",
      " Validation | Loss:1.5038 \n",
      "saving model with loss 1.5038...\n",
      "\n",
      "[Epoch 116 | 46976/47104] loss: 1.4089\n",
      "  Training  | Loss:1.4860 \n",
      " Validation | Loss:1.5038 \n",
      "saving model with loss 1.5038...\n",
      "\n",
      "[Epoch 117 | 46976/47104] loss: 1.1890\n",
      "  Training  | Loss:1.4859 \n",
      " Validation | Loss:1.5038 \n",
      "saving model with loss 1.5038...\n",
      "\n",
      "[Epoch 118 | 46976/47104] loss: 0.9104\n",
      "  Training  | Loss:1.4858 \n",
      " Validation | Loss:1.5038 \n",
      "saving model with loss 1.5038...\n",
      "\n",
      "[Epoch 119 | 46976/47104] loss: 1.0673\n",
      "  Training  | Loss:1.4858 \n",
      " Validation | Loss:1.5038 \n",
      "saving model with loss 1.5038...\n",
      "\n",
      "[Epoch 120 | 46976/47104] loss: 1.3462\n",
      "  Training  | Loss:1.4857 \n",
      " Validation | Loss:1.5037 \n",
      "saving model with loss 1.5037...\n",
      "\n",
      "[Epoch 121 | 46976/47104] loss: 1.1608\n",
      "  Training  | Loss:1.4856 \n",
      " Validation | Loss:1.5037 \n",
      "saving model with loss 1.5037...\n",
      "\n",
      "[Epoch 122 | 46976/47104] loss: 1.2200\n",
      "  Training  | Loss:1.4854 \n",
      " Validation | Loss:1.5037 \n",
      "saving model with loss 1.5037...\n",
      "\n",
      "[Epoch 123 | 46976/47104] loss: 0.8444\n",
      "  Training  | Loss:1.4853 \n",
      " Validation | Loss:1.5037 \n",
      "saving model with loss 1.5037...\n",
      "\n",
      "[Epoch 124 | 46976/47104] loss: 1.1262\n",
      "  Training  | Loss:1.4853 \n",
      " Validation | Loss:1.5037 \n",
      "saving model with loss 1.5037...\n",
      "\n",
      "[Epoch 125 | 46976/47104] loss: 1.1932\n",
      "  Training  | Loss:1.4853 \n",
      " Validation | Loss:1.5036 \n",
      "saving model with loss 1.5036...\n",
      "\n",
      "[Epoch 126 | 46976/47104] loss: 1.2834\n",
      "  Training  | Loss:1.4852 \n",
      " Validation | Loss:1.5036 \n",
      "saving model with loss 1.5036...\n",
      "\n",
      "[Epoch 127 | 46976/47104] loss: 1.1596\n",
      "  Training  | Loss:1.4855 \n",
      " Validation | Loss:1.5036 \n",
      "saving model with loss 1.5036...\n",
      "\n",
      "[Epoch 128 | 46976/47104] loss: 1.1604\n",
      "  Training  | Loss:1.4854 \n",
      " Validation | Loss:1.4954 \n",
      "saving model with loss 1.4954...\n",
      "\n",
      "[Epoch 129 | 46976/47104] loss: 0.9461\n",
      "  Training  | Loss:1.4848 \n",
      " Validation | Loss:1.4954 \n",
      "saving model with loss 1.4954...\n",
      "\n",
      "[Epoch 130 | 46976/47104] loss: 0.9091\n",
      "  Training  | Loss:1.4907 \n",
      " Validation | Loss:1.5090 \n",
      "[Epoch 131 | 46976/47104] loss: 1.0354\n",
      "  Training  | Loss:1.4849 \n",
      " Validation | Loss:1.5090 \n",
      "[Epoch 132 | 46976/47104] loss: 1.1256\n",
      "  Training  | Loss:1.4851 \n",
      " Validation | Loss:1.5117 \n",
      "[Epoch 133 | 46976/47104] loss: 1.4706\n",
      "  Training  | Loss:1.4845 \n",
      " Validation | Loss:1.5090 \n",
      "[Epoch 134 | 46976/47104] loss: 1.0029\n",
      "  Training  | Loss:1.4843 \n",
      " Validation | Loss:1.5116 \n",
      "[Epoch 135 | 46976/47104] loss: 1.1268\n",
      "  Training  | Loss:1.4842 \n",
      " Validation | Loss:1.5116 \n",
      "[Epoch 136 | 46976/47104] loss: 1.1258\n",
      "  Training  | Loss:1.4842 \n",
      " Validation | Loss:1.5116 \n",
      "[Epoch 137 | 46976/47104] loss: 1.1592\n",
      "  Training  | Loss:1.4884 \n",
      " Validation | Loss:1.5089 \n",
      "[Epoch 138 | 46976/47104] loss: 1.0637\n",
      "  Training  | Loss:1.4890 \n",
      " Validation | Loss:1.5089 \n",
      "[Epoch 139 | 46976/47104] loss: 0.9384\n",
      "  Training  | Loss:1.4834 \n",
      " Validation | Loss:1.5089 \n",
      "[Epoch 140 | 46976/47104] loss: 1.0330\n",
      "  Training  | Loss:1.4834 \n",
      " Validation | Loss:1.5089 \n",
      "[Epoch 141 | 46976/47104] loss: 1.0966\n",
      "  Training  | Loss:1.4832 \n",
      " Validation | Loss:1.5088 \n",
      "[Epoch 142 | 46976/47104] loss: 1.1916\n",
      "  Training  | Loss:1.4831 \n",
      " Validation | Loss:1.5088 \n",
      "[Epoch 143 | 46976/47104] loss: 1.1250\n",
      "  Training  | Loss:1.4831 \n",
      " Validation | Loss:1.5088 \n",
      "[Epoch 144 | 46976/47104] loss: 1.0324\n",
      "  Training  | Loss:1.4830 \n",
      " Validation | Loss:1.5088 \n",
      "[Epoch 145 | 46976/47104] loss: 1.2519\n",
      "  Training  | Loss:1.4829 \n",
      " Validation | Loss:1.5088 \n",
      "[Epoch 146 | 46976/47104] loss: 1.3440\n",
      "  Training  | Loss:1.4828 \n",
      " Validation | Loss:1.5088 \n",
      "[Epoch 147 | 46976/47104] loss: 0.9079\n",
      "  Training  | Loss:1.4829 \n",
      " Validation | Loss:1.5088 \n",
      "[Epoch 148 | 46976/47104] loss: 1.2503\n",
      "  Training  | Loss:1.4828 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 149 | 46976/47104] loss: 0.9415\n",
      "  Training  | Loss:1.4845 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 150 | 46976/47104] loss: 1.3138\n",
      "  Training  | Loss:1.4834 \n",
      " Validation | Loss:1.5114 \n",
      "[Epoch 151 | 46976/47104] loss: 1.0638\n",
      "  Training  | Loss:1.4909 \n",
      " Validation | Loss:1.5114 \n",
      "[Epoch 152 | 46976/47104] loss: 1.1887\n",
      "  Training  | Loss:1.4907 \n",
      " Validation | Loss:1.5114 \n",
      "[Epoch 153 | 46976/47104] loss: 1.0639\n",
      "  Training  | Loss:1.4985 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 154 | 46976/47104] loss: 1.0014\n",
      "  Training  | Loss:1.4987 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 155 | 46976/47104] loss: 1.2203\n",
      "  Training  | Loss:1.4987 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 156 | 46976/47104] loss: 1.1608\n",
      "  Training  | Loss:1.4986 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 157 | 46976/47104] loss: 0.9698\n",
      "  Training  | Loss:1.4986 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 158 | 46976/47104] loss: 1.2192\n",
      "  Training  | Loss:1.4985 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 159 | 46976/47104] loss: 0.8442\n",
      "  Training  | Loss:1.4985 \n",
      " Validation | Loss:1.5087 \n",
      "[Epoch 160 | 46976/47104] loss: 1.3129\n",
      "  Training  | Loss:1.4984 \n",
      " Validation | Loss:1.5128 \n",
      "[Epoch 161 | 46976/47104] loss: 1.2500\n",
      "  Training  | Loss:1.4984 \n",
      " Validation | Loss:1.5154 \n",
      "[Epoch 162 | 46976/47104] loss: 1.1576\n",
      "  Training  | Loss:1.4984 \n",
      " Validation | Loss:1.5154 \n",
      "[Epoch 163 | 46976/47104] loss: 1.4378\n",
      "  Training  | Loss:1.4983 \n",
      " Validation | Loss:1.5168 \n",
      "[Epoch 164 | 46976/47104] loss: 1.3442\n",
      "  Training  | Loss:1.4983 \n",
      " Validation | Loss:1.5168 \n",
      "[Epoch 165 | 46976/47104] loss: 1.2826\n",
      "  Training  | Loss:1.4982 \n",
      " Validation | Loss:1.5167 \n",
      "[Epoch 166 | 46976/47104] loss: 1.0006\n",
      "  Training  | Loss:1.4981 \n",
      " Validation | Loss:1.5167 \n",
      "[Epoch 167 | 46976/47104] loss: 1.3125\n",
      "  Training  | Loss:1.4980 \n",
      " Validation | Loss:1.5167 \n",
      "[Epoch 168 | 46976/47104] loss: 0.9688\n",
      "  Training  | Loss:1.4985 \n",
      " Validation | Loss:1.5167 \n",
      "[Epoch 169 | 46976/47104] loss: 1.2507\n",
      "  Training  | Loss:1.4981 \n",
      " Validation | Loss:1.5167 \n",
      "[Epoch 170 | 46976/47104] loss: 0.9704\n",
      "  Training  | Loss:1.4980 \n",
      " Validation | Loss:1.5153 \n",
      "[Epoch 171 | 46976/47104] loss: 1.3438\n",
      "  Training  | Loss:1.4979 \n",
      " Validation | Loss:1.5153 \n",
      "[Epoch 172 | 46976/47104] loss: 1.0318\n",
      "  Training  | Loss:1.4979 \n",
      " Validation | Loss:1.5017 \n",
      "[Epoch 173 | 46976/47104] loss: 1.0944\n",
      "  Training  | Loss:1.4978 \n",
      " Validation | Loss:1.5017 \n",
      "[Epoch 174 | 46976/47104] loss: 1.2839\n",
      "  Training  | Loss:1.4977 \n",
      " Validation | Loss:1.5017 \n",
      "[Epoch 175 | 46976/47104] loss: 1.0625\n",
      "  Training  | Loss:1.4975 \n",
      " Validation | Loss:1.5017 \n",
      "[Epoch 176 | 46976/47104] loss: 1.3757\n",
      "  Training  | Loss:1.4975 \n",
      " Validation | Loss:1.5017 \n",
      "[Epoch 177 | 46976/47104] loss: 1.2194\n",
      "  Training  | Loss:1.4974 \n",
      " Validation | Loss:1.5017 \n",
      "[Epoch 178 | 46976/47104] loss: 0.8450\n",
      "  Training  | Loss:1.5048 \n",
      " Validation | Loss:1.5030 \n",
      "[Epoch 179 | 46976/47104] loss: 1.1883\n",
      "  Training  | Loss:1.5143 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 180 | 46976/47104] loss: 1.2208\n",
      "  Training  | Loss:1.5067 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 181 | 46976/47104] loss: 1.1564\n",
      "  Training  | Loss:1.5058 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 182 | 46976/47104] loss: 1.3438\n",
      "  Training  | Loss:1.5058 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 183 | 46976/47104] loss: 1.3439\n",
      "  Training  | Loss:1.5057 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 184 | 46976/47104] loss: 1.4380\n",
      "  Training  | Loss:1.5055 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 185 | 46976/47104] loss: 1.0322\n",
      "  Training  | Loss:1.5033 \n",
      " Validation | Loss:1.5071 \n",
      "[Epoch 186 | 46976/47104] loss: 1.2197\n",
      "  Training  | Loss:1.4972 \n",
      " Validation | Loss:1.5058 \n",
      "[Epoch 187 | 46976/47104] loss: 1.2204\n",
      "  Training  | Loss:1.4970 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 188 | 46976/47104] loss: 1.4378\n",
      "  Training  | Loss:1.4970 \n",
      " Validation | Loss:1.5057 \n",
      "[Epoch 189 | 43264/47104] loss: 1.5003\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_356/870323459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_356/1691746710.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, val_data, model, n_epoch, batch, lr, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[Epoch %d | %d/%d] loss: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model = Net().to(device) \n",
    "model = train(train_dataloader, val_dataloader, model, n_epoch, batch, lr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f183c",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "269463ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31024155020713806\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "best_model = best_model.eval()\n",
    "\n",
    "testset = TestDataset()\n",
    "test_dataloader = DataLoader(testset, 1, False)\n",
    "result = []\n",
    "for x, _ in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    result.append(best_model(x).item())\n",
    "print(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3bcdf616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.5676300e+05 3.1024155e-01]\n",
      " [3.5821200e+05 3.1024155e-01]\n",
      " [3.5748500e+05 3.1008178e-01]\n",
      " ...\n",
      " [3.6057200e+05 0.0000000e+00]\n",
      " [3.6057500e+05 0.0000000e+00]\n",
      " [3.5224900e+05 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "keys_to_predict = sorted(ESun_public_y_answer['alert_key'].values.tolist())\n",
    "pairs = np.array(list(zip(keys_to_predict, result)))\n",
    "sorted_pairs = np.flip(pairs[pairs[:, 1].argsort()], 0)\n",
    "print(sorted_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "39f1e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "1497\n",
      "score:  0.006680026720106881\n"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "SAR_count = 0\n",
    "for key, flag in ESun_public_y_answer.values.tolist():\n",
    "    if flag == 1:\n",
    "        SAR_count += 1\n",
    "        for idx in range(len(sorted_pairs)):\n",
    "            if key == sorted_pairs[idx][0]:\n",
    "                index_list.append(idx + 1)\n",
    "                break\n",
    "print(len(index_list))\n",
    "print(SAR_count)\n",
    "index_list.sort()\n",
    "print(index_list[-2])\n",
    "print(\"score: \", str((SAR_count - 1) / index_list[-2]))\n",
    "\n",
    "# 0.01, 0.05, 0.1, 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9eafb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['alert_key','probability'])\n",
    "    for row in sorted_pairs:\n",
    "        writer.writerow([int(row[0]), row[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c4569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7695a47b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
