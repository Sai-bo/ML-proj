{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd168d4",
   "metadata": {},
   "source": [
    "# DNN\n",
    "1. 把all_keys.csv, ESun_public_y_answer.csv加到工作區\n",
    "2. 調整 # Main 下方的兩個block，第一個調參數，第二個建network\n",
    "3. 其他block應該不需要動\n",
    "4. 最後一個block會印成績"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a52fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c48c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db01d53",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6647343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 1vHDhZSPmhithLVRRzkNw0ak_kk7PhInu # V_trade\n",
    "# !gdown 145T8z3XXlsaISzWdrJgJVANGokG1XuFI # V_remit\n",
    "# !gdown 1AubrUmeNUgpgiOu4tay6Gwl8O3lBaokF # V_info\n",
    "# !gdown 1zZo9RLt3mMmJZxEETSY2g9ND31qkZIn0 # V_cred\n",
    "# !gdown 1uFCx21bqE3FnrdfvN_mwtw2-nvogTEex # V_cons\n",
    "# !gdown 1ZOXGT_rIdEGIliHGKEH3ha77ZlZyq1Gn # train_y\n",
    "# !gdown 1qjEwmi97OWdshSNdgQj2ccXnoM4UvT25 # V_trade_public\n",
    "# !gdown 1g8trBiC6OxuoTU94u_UMygVrA-fSASpB # V_remit_public\n",
    "# !gdown 14KTfY56Mz2xBXdP27GvGB2HVeb_4Ks4T # V_info_public\n",
    "# !gdown 1EaIWnjQxUl4KRgVCqYT7AB4PaSNvc_GL # V_cred_public\n",
    "# !gdown 1owf1urxHZywAxJfCgVXCpXEMQ6VZGhnO # V_cons_public\n",
    "# !gdown 1LbF8RTlCAuSm_78kA7oLaj91MxlZqhro # public_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf319e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cons = pd.read_csv('V_cons.csv').iloc[:, 1:]\n",
    "V_cred = pd.read_csv('V_cred.csv').iloc[:, 1:]\n",
    "V_info = pd.read_csv('V_info.csv').iloc[:, 1:]\n",
    "V_remit = pd.read_csv('V_remit.csv').iloc[:, 1:]\n",
    "V_trade = pd.read_csv('V_trade.csv').iloc[:, 1:]\n",
    "train_y = pd.read_csv('train_y.csv').iloc[:, 1:]\n",
    "\n",
    "V_cons_public = pd.read_csv('V_cons_public.csv').iloc[:, 1:]\n",
    "V_cred_public = pd.read_csv('V_cred_public.csv').iloc[:, 1:]\n",
    "V_info_public = pd.read_csv('V_info_public.csv').iloc[:, 1:]\n",
    "V_remit_public = pd.read_csv('V_remit_public.csv').iloc[:, 1:]\n",
    "V_trade_public = pd.read_csv('V_trade_public.csv').iloc[:, 1:]\n",
    "public_y = pd.read_csv('public_y.csv').iloc[:, 1:]\n",
    "\n",
    "all_keys = pd.read_csv('all_keys.csv')\n",
    "ESun_public_y_answer = pd.read_csv('ESun_public_y_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee62d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_overall = pd.concat([V_info, V_cred, V_cons, V_remit, V_trade], axis=1).fillna(0)\n",
    "V_overall_public = pd.concat([V_info_public, V_cred_public, V_cons_public, V_remit_public, V_trade_public], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fa34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23906, 4)\n",
      "(23906, 117)\n",
      "(23906, 1965)\n",
      "(23906, 1572)\n",
      "(23906, 3537)\n",
      "(23906, 7195)\n",
      "\n",
      "(1845, 4)\n",
      "(1845, 117)\n",
      "(1845, 1965)\n",
      "(1845, 1572)\n",
      "(1845, 3537)\n",
      "(1845, 7195)\n",
      "\n",
      "(23906, 1)\n",
      "(1845, 1)\n",
      "\n",
      "(25751, 1)\n",
      "(1845, 2)\n"
     ]
    }
   ],
   "source": [
    "print(V_info.shape)\n",
    "print(V_cred.shape)\n",
    "print(V_cons.shape)\n",
    "print(V_remit.shape)\n",
    "print(V_trade.shape)\n",
    "print(V_overall.shape)\n",
    "print()\n",
    "print(V_info_public.shape)\n",
    "print(V_cred_public.shape)\n",
    "print(V_cons_public.shape)\n",
    "print(V_remit_public.shape)\n",
    "print(V_trade_public.shape)\n",
    "print(V_overall_public.shape)\n",
    "print()\n",
    "print(train_y.shape)\n",
    "print(public_y.shape)\n",
    "print()\n",
    "print(all_keys.shape)\n",
    "print(ESun_public_y_answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c111eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = torch.tensor(V_overall.values).to(torch.float32)\n",
    "# print(torch.any(torch.isnan(instance)))\n",
    "# for row in range(len(instance)):\n",
    "#     for i in instance[row]:\n",
    "#         if torch.isnan(i):\n",
    "#             print(row, instance[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5548a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "1840  0\n",
      "1841  0\n",
      "1842  0\n",
      "1843  0\n",
      "1844  0\n",
      "\n",
      "[1845 rows x 1 columns]\n",
      "0    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(public_y)\n",
    "print(public_y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa743e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1845 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "1840  0\n",
       "1841  0\n",
       "1842  0\n",
       "1843  0\n",
       "1844  0\n",
       "\n",
       "[1845 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afac17c",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d526e",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "68991903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_epoch = 10000\n",
    "batch = 128 \n",
    "lr = 0.0000001 # 0.0000001\n",
    "w = 1\n",
    "d, d2 = 99, 165 #99 # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "fcd5b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.network = nn.Sequential( # 7195 -> 1\n",
    "            nn.Linear(7195, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid() # last one must be sigmoid \n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "73b71b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prob, ans):\n",
    "    #print(prob, ans)\n",
    "    return (w * (1 - prob) * ans + (prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c13139",
   "metadata": {},
   "source": [
    "### quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5b00dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set parameters\n",
    "# n_epoch = 500\n",
    "# batch = 128 \n",
    "# lr = 0.000001\n",
    "# w = 1\n",
    "# d = 99 # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "d64bc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define network\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.network = nn.Sequential( # 7195 -> 1\n",
    "#             nn.Linear(7195, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1024, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16, 1),\n",
    "#             nn.Sigmoid() # last one must be sigmoid   \n",
    "#         )\n",
    "                \n",
    "#     def forward(self, x):\n",
    "#         x = self.network(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ec767edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_function(prob, ans):\n",
    "#     #print(prob, ans)\n",
    "#     # a * x**n\n",
    "#     a = 4\n",
    "#     n = 2\n",
    "#     return (w * a * (1 - prob)**n * ans + a * (prob)**n * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972de33",
   "metadata": {},
   "source": [
    "### log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "6977cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob = torch.minimum(prob, torch.full((prob.size(dim=0), 1), 0.9999999).to(device))\n",
    "# prob = torch.maximum(prob, torch.full((prob.size(dim=0), 1), 0.0000001).to(device))\n",
    "# return (w * torch.log(1 - prob) * ans + torch.log(prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424a177",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "e3ad1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, val_data, model, n_epoch, batch, lr, device):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_loss = 1000000\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        idx = 0\n",
    "        for data, ans in train_data:\n",
    "            data, ans = data.to(device), ans.to(device)\n",
    "            prob = model(data)\n",
    "            loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += (loss.item() / len(train_data))\n",
    "            print('[Epoch %d | %d/%d] loss: %.4f' % ((epoch+1), idx*batch, len(train_data) * batch, loss.item()), end='\\r')\n",
    "            idx += 1\n",
    "        print(\"\\n  Training  | Loss:%.4f \" % total_loss)\n",
    "\n",
    "        # validation set\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        idx = 0 \n",
    "        with torch.no_grad():\n",
    "            for data, ans in val_data:\n",
    "                data, ans = data.to(device), ans.to(device)\n",
    "                prob = model(data)\n",
    "                loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "                total_loss += (loss.item() / len(val_data))\n",
    "                idx += 1\n",
    "            print(\" Validation | Loss:%.4f \" % total_loss)\n",
    "        # save model\n",
    "        if total_loss < best_loss:\n",
    "                best_loss = total_loss\n",
    "                print(\"saving model with loss %.4f...\\n\" % total_loss)\n",
    "                torch.save(model.state_dict(), \"%s\" % \"model.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "93609199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # oversampling\n",
    "        print(\"Train\")\n",
    "        V_overall_list = V_overall.values.tolist()\n",
    "        train_y_list = train_y.values.tolist()\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_list[i][0] == 1:\n",
    "                V_overall_list.extend([V_overall_list[i] for j in range(d)])\n",
    "                train_y_list.extend([train_y_list[i] for j in range(d)])\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_list).to(torch.float32)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        print(\"Val\")\n",
    "        V_overall_public_list = V_overall_public.values.tolist()\n",
    "        train_y_public_list = public_y.values.tolist()\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_public_list[i][0] == 1:\n",
    "                V_overall_public_list.extend([V_overall_public_list[i] for j in range(d2)])\n",
    "                train_y_public_list.extend([train_y_public_list[i] for j in range(d2)])\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_public_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_public_list).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.tensor(V_overall_public.values).to(torch.float32)\n",
    "        self.Y = torch.tensor(public_y.values).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5ba0c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Before: total=: 23906 flag=0: 23672 flag=1: 234 SAR_rate= 0.009788337655818623\n",
      "After: total=: 47072 flag=0: 23672 flag=1: 23400 SAR_rate= 0.4971108089734874\n",
      "Val\n",
      "Before: total=: 1845 flag=0: 1834 flag=1: 11 SAR_rate= 0.005962059620596206\n",
      "After: total=: 3660 flag=0: 1834 flag=1: 1826 SAR_rate= 0.4989071038251366\n"
     ]
    }
   ],
   "source": [
    "trainset = TrainDataset()\n",
    "valset = ValDataset()\n",
    "train_dataloader = DataLoader(trainset, batch, True)\n",
    "val_dataloader = DataLoader(valset, batch, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "9f226b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | 46976/47104] loss: 0.3648\n",
      "  Training  | Loss:0.4967 \n",
      " Validation | Loss:0.4324 \n",
      "saving model with loss 0.4324...\n",
      "\n",
      "[Epoch 2 | 46976/47104] loss: 0.3603\n",
      "  Training  | Loss:0.4865 \n",
      " Validation | Loss:0.4317 \n",
      "saving model with loss 0.4317...\n",
      "\n",
      "[Epoch 3 | 46976/47104] loss: 0.3884\n",
      "  Training  | Loss:0.4797 \n",
      " Validation | Loss:0.4303 \n",
      "saving model with loss 0.4303...\n",
      "\n",
      "[Epoch 4 | 46976/47104] loss: 0.3540\n",
      "  Training  | Loss:0.4752 \n",
      " Validation | Loss:0.4286 \n",
      "saving model with loss 0.4286...\n",
      "\n",
      "[Epoch 5 | 46976/47104] loss: 0.3842\n",
      "  Training  | Loss:0.4708 \n",
      " Validation | Loss:0.4265 \n",
      "saving model with loss 0.4265...\n",
      "\n",
      "[Epoch 6 | 46976/47104] loss: 0.3743\n",
      "  Training  | Loss:0.4662 \n",
      " Validation | Loss:0.4239 \n",
      "saving model with loss 0.4239...\n",
      "\n",
      "[Epoch 7 | 46976/47104] loss: 0.3614\n",
      "  Training  | Loss:0.4615 \n",
      " Validation | Loss:0.4210 \n",
      "saving model with loss 0.4210...\n",
      "\n",
      "[Epoch 8 | 46976/47104] loss: 0.3269\n",
      "  Training  | Loss:0.4568 \n",
      " Validation | Loss:0.4189 \n",
      "saving model with loss 0.4189...\n",
      "\n",
      "[Epoch 9 | 46976/47104] loss: 0.3522\n",
      "  Training  | Loss:0.4521 \n",
      " Validation | Loss:0.4167 \n",
      "saving model with loss 0.4167...\n",
      "\n",
      "[Epoch 10 | 46976/47104] loss: 0.3167\n",
      "  Training  | Loss:0.4475 \n",
      " Validation | Loss:0.4141 \n",
      "saving model with loss 0.4141...\n",
      "\n",
      "[Epoch 11 | 46976/47104] loss: 0.3688\n",
      "  Training  | Loss:0.4431 \n",
      " Validation | Loss:0.4115 \n",
      "saving model with loss 0.4115...\n",
      "\n",
      "[Epoch 12 | 46976/47104] loss: 0.3021\n",
      "  Training  | Loss:0.4389 \n",
      " Validation | Loss:0.4097 \n",
      "saving model with loss 0.4097...\n",
      "\n",
      "[Epoch 13 | 46976/47104] loss: 0.3354\n",
      "  Training  | Loss:0.4350 \n",
      " Validation | Loss:0.4075 \n",
      "saving model with loss 0.4075...\n",
      "\n",
      "[Epoch 14 | 46976/47104] loss: 0.3225\n",
      "  Training  | Loss:0.4309 \n",
      " Validation | Loss:0.4051 \n",
      "saving model with loss 0.4051...\n",
      "\n",
      "[Epoch 15 | 46976/47104] loss: 0.3596\n",
      "  Training  | Loss:0.4273 \n",
      " Validation | Loss:0.4029 \n",
      "saving model with loss 0.4029...\n",
      "\n",
      "[Epoch 16 | 46976/47104] loss: 0.2744\n",
      "  Training  | Loss:0.4232 \n",
      " Validation | Loss:0.4008 \n",
      "saving model with loss 0.4008...\n",
      "\n",
      "[Epoch 17 | 46976/47104] loss: 0.3425\n",
      "  Training  | Loss:0.4187 \n",
      " Validation | Loss:0.3975 \n",
      "saving model with loss 0.3975...\n",
      "\n",
      "[Epoch 18 | 46976/47104] loss: 0.2522\n",
      "  Training  | Loss:0.4142 \n",
      " Validation | Loss:0.3925 \n",
      "saving model with loss 0.3925...\n",
      "\n",
      "[Epoch 19 | 46976/47104] loss: 0.2719\n",
      "  Training  | Loss:0.4098 \n",
      " Validation | Loss:0.3889 \n",
      "saving model with loss 0.3889...\n",
      "\n",
      "[Epoch 20 | 46976/47104] loss: 0.3240\n",
      "  Training  | Loss:0.4055 \n",
      " Validation | Loss:0.3850 \n",
      "saving model with loss 0.3850...\n",
      "\n",
      "[Epoch 21 | 46976/47104] loss: 0.2477\n",
      "  Training  | Loss:0.4013 \n",
      " Validation | Loss:0.3818 \n",
      "saving model with loss 0.3818...\n",
      "\n",
      "[Epoch 22 | 46976/47104] loss: 0.2751\n",
      "  Training  | Loss:0.3979 \n",
      " Validation | Loss:0.3791 \n",
      "saving model with loss 0.3791...\n",
      "\n",
      "[Epoch 23 | 46976/47104] loss: 0.2970\n",
      "  Training  | Loss:0.3945 \n",
      " Validation | Loss:0.3769 \n",
      "saving model with loss 0.3769...\n",
      "\n",
      "[Epoch 24 | 46976/47104] loss: 0.3082\n",
      "  Training  | Loss:0.3911 \n",
      " Validation | Loss:0.3750 \n",
      "saving model with loss 0.3750...\n",
      "\n",
      "[Epoch 25 | 46976/47104] loss: 0.2941\n",
      "  Training  | Loss:0.3878 \n",
      " Validation | Loss:0.3731 \n",
      "saving model with loss 0.3731...\n",
      "\n",
      "[Epoch 26 | 46976/47104] loss: 0.2673\n",
      "  Training  | Loss:0.3847 \n",
      " Validation | Loss:0.3710 \n",
      "saving model with loss 0.3710...\n",
      "\n",
      "[Epoch 27 | 46976/47104] loss: 0.2663\n",
      "  Training  | Loss:0.3817 \n",
      " Validation | Loss:0.3688 \n",
      "saving model with loss 0.3688...\n",
      "\n",
      "[Epoch 28 | 46976/47104] loss: 0.2824\n",
      "  Training  | Loss:0.3788 \n",
      " Validation | Loss:0.3662 \n",
      "saving model with loss 0.3662...\n",
      "\n",
      "[Epoch 29 | 46976/47104] loss: 0.3263\n",
      "  Training  | Loss:0.3761 \n",
      " Validation | Loss:0.3638 \n",
      "saving model with loss 0.3638...\n",
      "\n",
      "[Epoch 30 | 46976/47104] loss: 0.2877\n",
      "  Training  | Loss:0.3734 \n",
      " Validation | Loss:0.3614 \n",
      "saving model with loss 0.3614...\n",
      "\n",
      "[Epoch 31 | 46976/47104] loss: 0.3077\n",
      "  Training  | Loss:0.3704 \n",
      " Validation | Loss:0.3593 \n",
      "saving model with loss 0.3593...\n",
      "\n",
      "[Epoch 32 | 46976/47104] loss: 0.2363\n",
      "  Training  | Loss:0.3675 \n",
      " Validation | Loss:0.3579 \n",
      "saving model with loss 0.3579...\n",
      "\n",
      "[Epoch 33 | 46976/47104] loss: 0.3342\n",
      "  Training  | Loss:0.3646 \n",
      " Validation | Loss:0.3563 \n",
      "saving model with loss 0.3563...\n",
      "\n",
      "[Epoch 34 | 46976/47104] loss: 0.2253\n",
      "  Training  | Loss:0.3618 \n",
      " Validation | Loss:0.3537 \n",
      "saving model with loss 0.3537...\n",
      "\n",
      "[Epoch 35 | 46976/47104] loss: 0.2525\n",
      "  Training  | Loss:0.3590 \n",
      " Validation | Loss:0.3522 \n",
      "saving model with loss 0.3522...\n",
      "\n",
      "[Epoch 36 | 46976/47104] loss: 0.2377\n",
      "  Training  | Loss:0.3565 \n",
      " Validation | Loss:0.3504 \n",
      "saving model with loss 0.3504...\n",
      "\n",
      "[Epoch 37 | 46976/47104] loss: 0.2459\n",
      "  Training  | Loss:0.3536 \n",
      " Validation | Loss:0.3487 \n",
      "saving model with loss 0.3487...\n",
      "\n",
      "[Epoch 38 | 46976/47104] loss: 0.2683\n",
      "  Training  | Loss:0.3508 \n",
      " Validation | Loss:0.3473 \n",
      "saving model with loss 0.3473...\n",
      "\n",
      "[Epoch 39 | 46976/47104] loss: 0.2677\n",
      "  Training  | Loss:0.3479 \n",
      " Validation | Loss:0.3456 \n",
      "saving model with loss 0.3456...\n",
      "\n",
      "[Epoch 40 | 46976/47104] loss: 0.2720\n",
      "  Training  | Loss:0.3451 \n",
      " Validation | Loss:0.3441 \n",
      "saving model with loss 0.3441...\n",
      "\n",
      "[Epoch 41 | 46976/47104] loss: 0.2442\n",
      "  Training  | Loss:0.3426 \n",
      " Validation | Loss:0.3426 \n",
      "saving model with loss 0.3426...\n",
      "\n",
      "[Epoch 42 | 46976/47104] loss: 0.2500\n",
      "  Training  | Loss:0.3404 \n",
      " Validation | Loss:0.3412 \n",
      "saving model with loss 0.3412...\n",
      "\n",
      "[Epoch 43 | 46976/47104] loss: 0.2163\n",
      "  Training  | Loss:0.3383 \n",
      " Validation | Loss:0.3395 \n",
      "saving model with loss 0.3395...\n",
      "\n",
      "[Epoch 44 | 46976/47104] loss: 0.2507\n",
      "  Training  | Loss:0.3365 \n",
      " Validation | Loss:0.3379 \n",
      "saving model with loss 0.3379...\n",
      "\n",
      "[Epoch 45 | 46976/47104] loss: 0.2443\n",
      "  Training  | Loss:0.3347 \n",
      " Validation | Loss:0.3363 \n",
      "saving model with loss 0.3363...\n",
      "\n",
      "[Epoch 46 | 46976/47104] loss: 0.2395\n",
      "  Training  | Loss:0.3329 \n",
      " Validation | Loss:0.3343 \n",
      "saving model with loss 0.3343...\n",
      "\n",
      "[Epoch 47 | 46976/47104] loss: 0.2361\n",
      "  Training  | Loss:0.3309 \n",
      " Validation | Loss:0.3324 \n",
      "saving model with loss 0.3324...\n",
      "\n",
      "[Epoch 48 | 46976/47104] loss: 0.2139\n",
      "  Training  | Loss:0.3292 \n",
      " Validation | Loss:0.3300 \n",
      "saving model with loss 0.3300...\n",
      "\n",
      "[Epoch 49 | 46976/47104] loss: 0.1967\n",
      "  Training  | Loss:0.3270 \n",
      " Validation | Loss:0.3275 \n",
      "saving model with loss 0.3275...\n",
      "\n",
      "[Epoch 50 | 46976/47104] loss: 0.1827\n",
      "  Training  | Loss:0.3250 \n",
      " Validation | Loss:0.3247 \n",
      "saving model with loss 0.3247...\n",
      "\n",
      "[Epoch 51 | 46976/47104] loss: 0.2458\n",
      "  Training  | Loss:0.3230 \n",
      " Validation | Loss:0.3217 \n",
      "saving model with loss 0.3217...\n",
      "\n",
      "[Epoch 52 | 46976/47104] loss: 0.2456\n",
      "  Training  | Loss:0.3211 \n",
      " Validation | Loss:0.3188 \n",
      "saving model with loss 0.3188...\n",
      "\n",
      "[Epoch 53 | 46976/47104] loss: 0.2126\n",
      "  Training  | Loss:0.3193 \n",
      " Validation | Loss:0.3164 \n",
      "saving model with loss 0.3164...\n",
      "\n",
      "[Epoch 54 | 46976/47104] loss: 0.2600\n",
      "  Training  | Loss:0.3175 \n",
      " Validation | Loss:0.3133 \n",
      "saving model with loss 0.3133...\n",
      "\n",
      "[Epoch 55 | 46976/47104] loss: 0.2459\n",
      "  Training  | Loss:0.3154 \n",
      " Validation | Loss:0.3099 \n",
      "saving model with loss 0.3099...\n",
      "\n",
      "[Epoch 56 | 46976/47104] loss: 0.1876\n",
      "  Training  | Loss:0.3133 \n",
      " Validation | Loss:0.3072 \n",
      "saving model with loss 0.3072...\n",
      "\n",
      "[Epoch 57 | 46976/47104] loss: 0.1853\n",
      "  Training  | Loss:0.3108 \n",
      " Validation | Loss:0.3039 \n",
      "saving model with loss 0.3039...\n",
      "\n",
      "[Epoch 58 | 46976/47104] loss: 0.2534\n",
      "  Training  | Loss:0.3085 \n",
      " Validation | Loss:0.3022 \n",
      "saving model with loss 0.3022...\n",
      "\n",
      "[Epoch 59 | 46976/47104] loss: 0.2384\n",
      "  Training  | Loss:0.3065 \n",
      " Validation | Loss:0.2991 \n",
      "saving model with loss 0.2991...\n",
      "\n",
      "[Epoch 60 | 46976/47104] loss: 0.2027\n",
      "  Training  | Loss:0.3048 \n",
      " Validation | Loss:0.2975 \n",
      "saving model with loss 0.2975...\n",
      "\n",
      "[Epoch 61 | 46976/47104] loss: 0.1780\n",
      "  Training  | Loss:0.3029 \n",
      " Validation | Loss:0.2933 \n",
      "saving model with loss 0.2933...\n",
      "\n",
      "[Epoch 62 | 46976/47104] loss: 0.2488\n",
      "  Training  | Loss:0.3009 \n",
      " Validation | Loss:0.2917 \n",
      "saving model with loss 0.2917...\n",
      "\n",
      "[Epoch 63 | 46976/47104] loss: 0.2100\n",
      "  Training  | Loss:0.2990 \n",
      " Validation | Loss:0.2901 \n",
      "saving model with loss 0.2901...\n",
      "\n",
      "[Epoch 64 | 46976/47104] loss: 0.2615\n",
      "  Training  | Loss:0.2969 \n",
      " Validation | Loss:0.2882 \n",
      "saving model with loss 0.2882...\n",
      "\n",
      "[Epoch 65 | 46976/47104] loss: 0.2406\n",
      "  Training  | Loss:0.2950 \n",
      " Validation | Loss:0.2866 \n",
      "saving model with loss 0.2866...\n",
      "\n",
      "[Epoch 66 | 46976/47104] loss: 0.2154\n",
      "  Training  | Loss:0.2933 \n",
      " Validation | Loss:0.2850 \n",
      "saving model with loss 0.2850...\n",
      "\n",
      "[Epoch 67 | 46976/47104] loss: 0.2216\n",
      "  Training  | Loss:0.2918 \n",
      " Validation | Loss:0.2831 \n",
      "saving model with loss 0.2831...\n",
      "\n",
      "[Epoch 68 | 46976/47104] loss: 0.2146\n",
      "  Training  | Loss:0.2902 \n",
      " Validation | Loss:0.2816 \n",
      "saving model with loss 0.2816...\n",
      "\n",
      "[Epoch 69 | 46976/47104] loss: 0.2213\n",
      "  Training  | Loss:0.2884 \n",
      " Validation | Loss:0.2805 \n",
      "saving model with loss 0.2805...\n",
      "\n",
      "[Epoch 70 | 46976/47104] loss: 0.1946\n",
      "  Training  | Loss:0.2867 \n",
      " Validation | Loss:0.2799 \n",
      "saving model with loss 0.2799...\n",
      "\n",
      "[Epoch 71 | 46976/47104] loss: 0.1783\n",
      "  Training  | Loss:0.2854 \n",
      " Validation | Loss:0.2797 \n",
      "saving model with loss 0.2797...\n",
      "\n",
      "[Epoch 72 | 46976/47104] loss: 0.2760\n",
      "  Training  | Loss:0.2840 \n",
      " Validation | Loss:0.2792 \n",
      "saving model with loss 0.2792...\n",
      "\n",
      "[Epoch 73 | 46976/47104] loss: 0.2058\n",
      "  Training  | Loss:0.2821 \n",
      " Validation | Loss:0.2789 \n",
      "saving model with loss 0.2789...\n",
      "\n",
      "[Epoch 74 | 46976/47104] loss: 0.1709\n",
      "  Training  | Loss:0.2805 \n",
      " Validation | Loss:0.2781 \n",
      "saving model with loss 0.2781...\n",
      "\n",
      "[Epoch 75 | 46976/47104] loss: 0.1727\n",
      "  Training  | Loss:0.2790 \n",
      " Validation | Loss:0.2771 \n",
      "saving model with loss 0.2771...\n",
      "\n",
      "[Epoch 76 | 46976/47104] loss: 0.1887\n",
      "  Training  | Loss:0.2774 \n",
      " Validation | Loss:0.2760 \n",
      "saving model with loss 0.2760...\n",
      "\n",
      "[Epoch 77 | 46976/47104] loss: 0.2141\n",
      "  Training  | Loss:0.2758 \n",
      " Validation | Loss:0.2756 \n",
      "saving model with loss 0.2756...\n",
      "\n",
      "[Epoch 78 | 46976/47104] loss: 0.1887\n",
      "  Training  | Loss:0.2744 \n",
      " Validation | Loss:0.2753 \n",
      "saving model with loss 0.2753...\n",
      "\n",
      "[Epoch 79 | 46976/47104] loss: 0.2346\n",
      "  Training  | Loss:0.2730 \n",
      " Validation | Loss:0.2747 \n",
      "saving model with loss 0.2747...\n",
      "\n",
      "[Epoch 80 | 46976/47104] loss: 0.2135\n",
      "  Training  | Loss:0.2718 \n",
      " Validation | Loss:0.2741 \n",
      "saving model with loss 0.2741...\n",
      "\n",
      "[Epoch 81 | 46976/47104] loss: 0.2789\n",
      "  Training  | Loss:0.2705 \n",
      " Validation | Loss:0.2738 \n",
      "saving model with loss 0.2738...\n",
      "\n",
      "[Epoch 82 | 46976/47104] loss: 0.2403\n",
      "  Training  | Loss:0.2692 \n",
      " Validation | Loss:0.2740 \n",
      "[Epoch 83 | 46976/47104] loss: 0.1803\n",
      "  Training  | Loss:0.2678 \n",
      " Validation | Loss:0.2741 \n",
      "[Epoch 84 | 46976/47104] loss: 0.1797\n",
      "  Training  | Loss:0.2663 \n",
      " Validation | Loss:0.2745 \n",
      "[Epoch 85 | 46976/47104] loss: 0.1723\n",
      "  Training  | Loss:0.2648 \n",
      " Validation | Loss:0.2752 \n",
      "[Epoch 86 | 46976/47104] loss: 0.2113\n",
      "  Training  | Loss:0.2635 \n",
      " Validation | Loss:0.2760 \n",
      "[Epoch 87 | 46976/47104] loss: 0.1846\n",
      "  Training  | Loss:0.2620 \n",
      " Validation | Loss:0.2751 \n",
      "[Epoch 88 | 46976/47104] loss: 0.1671\n",
      "  Training  | Loss:0.2603 \n",
      " Validation | Loss:0.2773 \n",
      "[Epoch 89 | 46976/47104] loss: 0.1872\n",
      "  Training  | Loss:0.2584 \n",
      " Validation | Loss:0.2802 \n",
      "[Epoch 90 | 46976/47104] loss: 0.1947\n",
      "  Training  | Loss:0.2566 \n",
      " Validation | Loss:0.2835 \n",
      "[Epoch 91 | 46976/47104] loss: 0.1681\n",
      "  Training  | Loss:0.2550 \n",
      " Validation | Loss:0.2871 \n",
      "[Epoch 92 | 46976/47104] loss: 0.1893\n",
      "  Training  | Loss:0.2537 \n",
      " Validation | Loss:0.2901 \n",
      "[Epoch 93 | 46976/47104] loss: 0.2008\n",
      "  Training  | Loss:0.2524 \n",
      " Validation | Loss:0.2933 \n",
      "[Epoch 94 | 46976/47104] loss: 0.1663\n",
      "  Training  | Loss:0.2508 \n",
      " Validation | Loss:0.2954 \n",
      "[Epoch 95 | 46976/47104] loss: 0.1683\n",
      "  Training  | Loss:0.2491 \n",
      " Validation | Loss:0.2954 \n",
      "[Epoch 96 | 46976/47104] loss: 0.2080\n",
      "  Training  | Loss:0.2474 \n",
      " Validation | Loss:0.2952 \n",
      "[Epoch 97 | 46976/47104] loss: 0.2005\n",
      "  Training  | Loss:0.2462 \n",
      " Validation | Loss:0.2954 \n",
      "[Epoch 98 | 46976/47104] loss: 0.1861\n",
      "  Training  | Loss:0.2450 \n",
      " Validation | Loss:0.2954 \n",
      "[Epoch 99 | 46976/47104] loss: 0.1589\n",
      "  Training  | Loss:0.2437 \n",
      " Validation | Loss:0.2952 \n",
      "[Epoch 100 | 46976/47104] loss: 0.1380\n",
      "  Training  | Loss:0.2423 \n",
      " Validation | Loss:0.2947 \n",
      "[Epoch 101 | 46976/47104] loss: 0.1755\n",
      "  Training  | Loss:0.2409 \n",
      " Validation | Loss:0.2942 \n",
      "[Epoch 102 | 46976/47104] loss: 0.1719\n",
      "  Training  | Loss:0.2397 \n",
      " Validation | Loss:0.2937 \n",
      "[Epoch 103 | 46976/47104] loss: 0.1863\n",
      "  Training  | Loss:0.2385 \n",
      " Validation | Loss:0.2932 \n",
      "[Epoch 104 | 46976/47104] loss: 0.1353\n",
      "  Training  | Loss:0.2371 \n",
      " Validation | Loss:0.2932 \n",
      "[Epoch 105 | 46976/47104] loss: 0.1820\n",
      "  Training  | Loss:0.2359 \n",
      " Validation | Loss:0.2980 \n",
      "[Epoch 106 | 46976/47104] loss: 0.1717\n",
      "  Training  | Loss:0.2347 \n",
      " Validation | Loss:0.3102 \n",
      "[Epoch 107 | 46976/47104] loss: 0.1731\n",
      "  Training  | Loss:0.2337 \n",
      " Validation | Loss:0.3267 \n",
      "[Epoch 108 | 46976/47104] loss: 0.1811\n",
      "  Training  | Loss:0.2326 \n",
      " Validation | Loss:0.3313 \n",
      "[Epoch 109 | 46976/47104] loss: 0.1535\n",
      "  Training  | Loss:0.2315 \n",
      " Validation | Loss:0.3305 \n",
      "[Epoch 110 | 46976/47104] loss: 0.0942\n",
      "  Training  | Loss:0.2304 \n",
      " Validation | Loss:0.3292 \n",
      "[Epoch 111 | 46976/47104] loss: 0.1468\n",
      "  Training  | Loss:0.2294 \n",
      " Validation | Loss:0.3275 \n",
      "[Epoch 112 | 46976/47104] loss: 0.1940\n",
      "  Training  | Loss:0.2284 \n",
      " Validation | Loss:0.3259 \n",
      "[Epoch 113 | 46976/47104] loss: 0.1658\n",
      "  Training  | Loss:0.2273 \n",
      " Validation | Loss:0.3245 \n",
      "[Epoch 114 | 46976/47104] loss: 0.1908\n",
      "  Training  | Loss:0.2262 \n",
      " Validation | Loss:0.3232 \n",
      "[Epoch 115 | 46976/47104] loss: 0.2283\n",
      "  Training  | Loss:0.2251 \n",
      " Validation | Loss:0.3216 \n",
      "[Epoch 116 | 46976/47104] loss: 0.1436\n",
      "  Training  | Loss:0.2241 \n",
      " Validation | Loss:0.3205 \n",
      "[Epoch 117 | 46976/47104] loss: 0.1290\n",
      "  Training  | Loss:0.2231 \n",
      " Validation | Loss:0.3191 \n",
      "[Epoch 118 | 46976/47104] loss: 0.1488\n",
      "  Training  | Loss:0.2219 \n",
      " Validation | Loss:0.3180 \n",
      "[Epoch 119 | 46976/47104] loss: 0.2098\n",
      "  Training  | Loss:0.2210 \n",
      " Validation | Loss:0.3162 \n",
      "[Epoch 120 | 46976/47104] loss: 0.1070\n",
      "  Training  | Loss:0.2201 \n",
      " Validation | Loss:0.3145 \n",
      "[Epoch 121 | 46976/47104] loss: 0.1288\n",
      "  Training  | Loss:0.2192 \n",
      " Validation | Loss:0.3133 \n",
      "[Epoch 122 | 46976/47104] loss: 0.1805\n",
      "  Training  | Loss:0.2182 \n",
      " Validation | Loss:0.3121 \n",
      "[Epoch 123 | 46976/47104] loss: 0.1464\n",
      "  Training  | Loss:0.2171 \n",
      " Validation | Loss:0.3113 \n",
      "[Epoch 124 | 46976/47104] loss: 0.2065\n",
      "  Training  | Loss:0.2160 \n",
      " Validation | Loss:0.3105 \n",
      "[Epoch 125 | 46976/47104] loss: 0.1866\n",
      "  Training  | Loss:0.2142 \n",
      " Validation | Loss:0.3097 \n",
      "[Epoch 126 | 46976/47104] loss: 0.1534\n",
      "  Training  | Loss:0.2131 \n",
      " Validation | Loss:0.3091 \n",
      "[Epoch 127 | 46976/47104] loss: 0.1380\n",
      "  Training  | Loss:0.2122 \n",
      " Validation | Loss:0.3086 \n",
      "[Epoch 128 | 46976/47104] loss: 0.1557\n",
      "  Training  | Loss:0.2114 \n",
      " Validation | Loss:0.3081 \n",
      "[Epoch 129 | 46976/47104] loss: 0.1512\n",
      "  Training  | Loss:0.2106 \n",
      " Validation | Loss:0.3074 \n",
      "[Epoch 130 | 46976/47104] loss: 0.1932\n",
      "  Training  | Loss:0.2099 \n",
      " Validation | Loss:0.3066 \n",
      "[Epoch 131 | 46976/47104] loss: 0.1781\n",
      "  Training  | Loss:0.2090 \n",
      " Validation | Loss:0.3058 \n",
      "[Epoch 132 | 46976/47104] loss: 0.1549\n",
      "  Training  | Loss:0.2084 \n",
      " Validation | Loss:0.3052 \n",
      "[Epoch 133 | 46976/47104] loss: 0.1395\n",
      "  Training  | Loss:0.2076 \n",
      " Validation | Loss:0.3048 \n",
      "[Epoch 134 | 46976/47104] loss: 0.1543\n",
      "  Training  | Loss:0.2068 \n",
      " Validation | Loss:0.3053 \n",
      "[Epoch 135 | 46976/47104] loss: 0.1135\n",
      "  Training  | Loss:0.2061 \n",
      " Validation | Loss:0.3069 \n",
      "[Epoch 136 | 46976/47104] loss: 0.1484\n",
      "  Training  | Loss:0.2054 \n",
      " Validation | Loss:0.3096 \n",
      "[Epoch 137 | 46976/47104] loss: 0.1476\n",
      "  Training  | Loss:0.2046 \n",
      " Validation | Loss:0.3140 \n",
      "[Epoch 138 | 46976/47104] loss: 0.1266\n",
      "  Training  | Loss:0.2038 \n",
      " Validation | Loss:0.3200 \n",
      "[Epoch 139 | 46976/47104] loss: 0.1485\n",
      "  Training  | Loss:0.2028 \n",
      " Validation | Loss:0.3264 \n",
      "[Epoch 140 | 46976/47104] loss: 0.1603\n",
      "  Training  | Loss:0.2020 \n",
      " Validation | Loss:0.3308 \n",
      "[Epoch 141 | 46976/47104] loss: 0.1842\n",
      "  Training  | Loss:0.2012 \n",
      " Validation | Loss:0.3337 \n",
      "[Epoch 142 | 46976/47104] loss: 0.1230\n",
      "  Training  | Loss:0.2002 \n",
      " Validation | Loss:0.3343 \n",
      "[Epoch 143 | 46976/47104] loss: 0.1227\n",
      "  Training  | Loss:0.1993 \n",
      " Validation | Loss:0.3342 \n",
      "[Epoch 144 | 46976/47104] loss: 0.1203\n",
      "  Training  | Loss:0.1986 \n",
      " Validation | Loss:0.3338 \n",
      "[Epoch 145 | 46976/47104] loss: 0.1634\n",
      "  Training  | Loss:0.1978 \n",
      " Validation | Loss:0.3333 \n",
      "[Epoch 146 | 20096/47104] loss: 0.1708\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_442/870323459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_442/1691746710.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, val_data, model, n_epoch, batch, lr, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model = Net().to(device) \n",
    "model = train(train_dataloader, val_dataloader, model, n_epoch, batch, lr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f183c",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "269463ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "best_model = best_model.eval()\n",
    "\n",
    "testset = TestDataset()\n",
    "test_dataloader = DataLoader(testset, 1, False)\n",
    "result = []\n",
    "for x, _ in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    result.append(best_model(x).item())\n",
    "print(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3bcdf616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.65073e+05 1.00000e+00]\n",
      " [3.58457e+05 1.00000e+00]\n",
      " [3.58451e+05 1.00000e+00]\n",
      " ...\n",
      " [3.64703e+05 0.00000e+00]\n",
      " [3.58977e+05 0.00000e+00]\n",
      " [3.55188e+05 0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "keys_to_predict = sorted(ESun_public_y_answer['alert_key'].values.tolist())\n",
    "pairs = np.array(list(zip(keys_to_predict, result)))\n",
    "sorted_pairs = np.flip(pairs[pairs[:, 1].argsort()], 0)\n",
    "print(sorted_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "39f1e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "737\n",
      "score:  0.013568521031207599\n"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "SAR_count = 0\n",
    "for key, flag in ESun_public_y_answer.values.tolist():\n",
    "    if flag == 1:\n",
    "        SAR_count += 1\n",
    "        for idx in range(len(sorted_pairs)):\n",
    "            if key == sorted_pairs[idx][0]:\n",
    "                index_list.append(idx + 1)\n",
    "                break\n",
    "print(len(index_list))\n",
    "print(SAR_count)\n",
    "index_list.sort()\n",
    "print(index_list[-2])\n",
    "print(\"score: \", str((SAR_count - 1) / index_list[-2]))\n",
    "\n",
    "# 0.01, 0.05, 0.1, 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "de85f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_keys = []\n",
    "with open('example.csv', newline='') as example:\n",
    "    rows = csv.reader(example)\n",
    "    headers = next(rows)\n",
    "    for row in rows:\n",
    "        example_keys.append(int(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "9eafb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['alert_key','probability'])\n",
    "    for row in sorted_pairs:\n",
    "        writer.writerow([int(row[0]), row[1]])\n",
    "    for key in example_keys:\n",
    "        if key not in keys_to_predict:\n",
    "            writer.writerow([key, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c4569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, flag in ESun_public_y_answer.values.tolist():\n",
    "#     if flag == 1:\n",
    "#         print(key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
