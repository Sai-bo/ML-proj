{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd168d4",
   "metadata": {},
   "source": [
    "# DNN\n",
    "1. 把all_keys.csv, ESun_public_y_answer.csv加到工作區\n",
    "2. 調整 # Main 下方的兩個block，第一個調參數，第二個建network\n",
    "3. 其他block應該不需要動\n",
    "4. 最後一個block會印成績"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "3c48c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db01d53",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b6647343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1vHDhZSPmhithLVRRzkNw0ak_kk7PhInu\n",
      "To: /workspace/project/V_trade.csv\n",
      "100%|█████████████████████████████████████████| 230M/230M [00:01<00:00, 200MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=145T8z3XXlsaISzWdrJgJVANGokG1XuFI\n",
      "To: /workspace/project/V_remit.csv\n",
      "100%|███████████████████████████████████████| 90.4M/90.4M [00:00<00:00, 219MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1AubrUmeNUgpgiOu4tay6Gwl8O3lBaokF\n",
      "To: /workspace/project/V_info.csv\n",
      "100%|████████████████████████████████████████| 557k/557k [00:00<00:00, 27.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zZo9RLt3mMmJZxEETSY2g9ND31qkZIn0\n",
      "To: /workspace/project/V_cred.csv\n",
      "100%|███████████████████████████████████████| 12.3M/12.3M [00:00<00:00, 115MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1uFCx21bqE3FnrdfvN_mwtw2-nvogTEex\n",
      "To: /workspace/project/V_cons.csv\n",
      "100%|█████████████████████████████████████████| 105M/105M [00:00<00:00, 205MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZOXGT_rIdEGIliHGKEH3ha77ZlZyq1Gn\n",
      "To: /workspace/project/train_y.csv\n",
      "100%|████████████████████████████████████████| 204k/204k [00:00<00:00, 17.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qjEwmi97OWdshSNdgQj2ccXnoM4UvT25\n",
      "To: /workspace/project/V_trade_public.csv\n",
      "100%|███████████████████████████████████████| 19.0M/19.0M [00:00<00:00, 129MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1g8trBiC6OxuoTU94u_UMygVrA-fSASpB\n",
      "To: /workspace/project/V_remit_public.csv\n",
      "100%|██████████████████████████████████████| 7.35M/7.35M [00:00<00:00, 65.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14KTfY56Mz2xBXdP27GvGB2HVeb_4Ks4T\n",
      "To: /workspace/project/V_info_public.csv\n",
      "100%|██████████████████████████████████████| 41.7k/41.7k [00:00<00:00, 33.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1EaIWnjQxUl4KRgVCqYT7AB4PaSNvc_GL\n",
      "To: /workspace/project/V_cred_public.csv\n",
      "100%|██████████████████████████████████████| 1.08M/1.08M [00:00<00:00, 41.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1owf1urxHZywAxJfCgVXCpXEMQ6VZGhnO\n",
      "To: /workspace/project/V_cons_public.csv\n",
      "100%|███████████████████████████████████████| 10.2M/10.2M [00:00<00:00, 127MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1LbF8RTlCAuSm_78kA7oLaj91MxlZqhro\n",
      "To: /workspace/project/public_y.csv\n",
      "100%|██████████████████████████████████████| 13.7k/13.7k [00:00<00:00, 15.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1vHDhZSPmhithLVRRzkNw0ak_kk7PhInu # V_trade\n",
    "!gdown 145T8z3XXlsaISzWdrJgJVANGokG1XuFI # V_remit\n",
    "!gdown 1AubrUmeNUgpgiOu4tay6Gwl8O3lBaokF # V_info\n",
    "!gdown 1zZo9RLt3mMmJZxEETSY2g9ND31qkZIn0 # V_cred\n",
    "!gdown 1uFCx21bqE3FnrdfvN_mwtw2-nvogTEex # V_cons\n",
    "!gdown 1ZOXGT_rIdEGIliHGKEH3ha77ZlZyq1Gn # train_y\n",
    "!gdown 1qjEwmi97OWdshSNdgQj2ccXnoM4UvT25 # V_trade_public\n",
    "!gdown 1g8trBiC6OxuoTU94u_UMygVrA-fSASpB # V_remit_public\n",
    "!gdown 14KTfY56Mz2xBXdP27GvGB2HVeb_4Ks4T # V_info_public\n",
    "!gdown 1EaIWnjQxUl4KRgVCqYT7AB4PaSNvc_GL # V_cred_public\n",
    "!gdown 1owf1urxHZywAxJfCgVXCpXEMQ6VZGhnO # V_cons_public\n",
    "!gdown 1LbF8RTlCAuSm_78kA7oLaj91MxlZqhro # public_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "cf319e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cons = pd.read_csv('V_cons.csv').iloc[:, 1:]\n",
    "V_cred = pd.read_csv('V_cred.csv').iloc[:, 1:]\n",
    "V_info = pd.read_csv('V_info.csv').iloc[:, 1:]\n",
    "V_remit = pd.read_csv('V_remit.csv').iloc[:, 1:]\n",
    "V_trade = pd.read_csv('V_trade.csv').iloc[:, 1:]\n",
    "train_y = pd.read_csv('train_y.csv').iloc[:, 1:]\n",
    "\n",
    "V_cons_public = pd.read_csv('V_cons_public.csv').iloc[:, 1:]\n",
    "V_cred_public = pd.read_csv('V_cred_public.csv').iloc[:, 1:]\n",
    "V_info_public = pd.read_csv('V_info_public.csv').iloc[:, 1:]\n",
    "V_remit_public = pd.read_csv('V_remit_public.csv').iloc[:, 1:]\n",
    "V_trade_public = pd.read_csv('V_trade_public.csv').iloc[:, 1:]\n",
    "public_y = pd.read_csv('public_y.csv').iloc[:, 1:]\n",
    "\n",
    "all_keys = pd.read_csv('all_keys.csv')\n",
    "ESun_public_y_answer = pd.read_csv('ESun_public_y_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ee62d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_overall = pd.concat([V_info, V_cred, V_cons, V_remit, V_trade], axis=1).fillna(0)\n",
    "V_overall_public = pd.concat([V_info_public, V_cred_public, V_cons_public, V_remit_public, V_trade_public], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "00fa34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23906, 4)\n",
      "(23906, 117)\n",
      "(23906, 1965)\n",
      "(23906, 1572)\n",
      "(23906, 3537)\n",
      "(23906, 7195)\n",
      "\n",
      "(1845, 4)\n",
      "(1845, 117)\n",
      "(1845, 1965)\n",
      "(1845, 1572)\n",
      "(1845, 3537)\n",
      "(1845, 7195)\n",
      "\n",
      "(23906, 1)\n",
      "(1845, 1)\n",
      "\n",
      "(25751, 1)\n",
      "(1845, 2)\n"
     ]
    }
   ],
   "source": [
    "print(V_info.shape)\n",
    "print(V_cred.shape)\n",
    "print(V_cons.shape)\n",
    "print(V_remit.shape)\n",
    "print(V_trade.shape)\n",
    "print(V_overall.shape)\n",
    "print()\n",
    "print(V_info_public.shape)\n",
    "print(V_cred_public.shape)\n",
    "print(V_cons_public.shape)\n",
    "print(V_remit_public.shape)\n",
    "print(V_trade_public.shape)\n",
    "print(V_overall_public.shape)\n",
    "print()\n",
    "print(train_y.shape)\n",
    "print(public_y.shape)\n",
    "print()\n",
    "print(all_keys.shape)\n",
    "print(ESun_public_y_answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c111eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = torch.tensor(V_overall.values).to(torch.float32)\n",
    "# print(torch.any(torch.isnan(instance)))\n",
    "# for row in range(len(instance)):\n",
    "#     for i in instance[row]:\n",
    "#         if torch.isnan(i):\n",
    "#             print(row, instance[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "cc5548a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "1840  0\n",
      "1841  0\n",
      "1842  0\n",
      "1843  0\n",
      "1844  0\n",
      "\n",
      "[1845 rows x 1 columns]\n",
      "0    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(public_y)\n",
    "print(public_y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "aa743e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1845 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "1840  0\n",
       "1841  0\n",
       "1842  0\n",
       "1843  0\n",
       "1844  0\n",
       "\n",
       "[1845 rows x 1 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424a177",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "f65b89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_epoch = 20\n",
    "batch = 32 #\n",
    "lr = 0.01\n",
    "w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "72ca6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.network = nn.Sequential( # 7195 -> 1\n",
    "            nn.Linear(7195, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid() # last one must be sigmoid \n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "d43d74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prob, ans):\n",
    "    #print(prob, ans)\n",
    "    return (w * (1 - prob) * ans + (prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "e3ad1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, val_data, model, n_epoch, batch, lr, device):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_loss = 1000000\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        idx = 0\n",
    "        for data, ans in train_data:\n",
    "            data, ans = data.to(device), ans.to(device)\n",
    "            prob = model(data)\n",
    "            loss = torch.sum(loss_function(prob, ans))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += (loss.item() / len(train_data))\n",
    "            print('[Epoch %d | %d/%d] loss: %.4f' % ((epoch+1), idx*batch, len(train_data) * batch, loss.item()), end='\\r')\n",
    "            idx += 1\n",
    "        print(\"\\n  Training  | Loss:%.4f \" % total_loss)\n",
    "\n",
    "        # validation set\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        idx = 0 \n",
    "        with torch.no_grad():\n",
    "            for data, ans in val_data:\n",
    "                data, ans = data.to(device), ans.to(device)\n",
    "                prob = model(data)\n",
    "                loss = torch.sum(loss_function(prob, ans))\n",
    "                total_loss += (loss.item() / len(val_data))\n",
    "                idx += 1\n",
    "            print(\" Validation | Loss:%.4f \" % total_loss)\n",
    "        # save model\n",
    "        if total_loss < best_loss:\n",
    "                best_loss = total_loss\n",
    "                print(\"saving model with loss %.4f...\\n\" % total_loss)\n",
    "                torch.save(model.state_dict(), \"%s\" % \"model.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "93609199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.tensor(V_overall.values).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y.values).to(torch.float32)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.tensor(V_overall_public.values).to(torch.float32)\n",
    "        self.Y = torch.tensor(public_y.values).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "5ba0c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TrainDataset()\n",
    "valset = ValDataset()\n",
    "train_dataloader = DataLoader(trainset, batch, True)\n",
    "val_dataloader = DataLoader(valset, batch, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "9f226b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3360 \n",
      " Validation | Loss:0.1897 \n",
      "saving model with loss 0.1897...\n",
      "\n",
      "[Epoch 2 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 3 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 4 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 5 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 6 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 7 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 8 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 9 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 10 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 11 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 12 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 13 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 14 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 15 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 16 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 17 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 18 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 19 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n",
      "[Epoch 20 | 23904/23936] loss: 0.0000\n",
      "  Training  | Loss:0.3128 \n",
      " Validation | Loss:0.1897 \n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model = Net().to(device) \n",
    "model = train(train_dataloader, val_dataloader, model, n_epoch, batch, lr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f183c",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "269463ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "best_model = best_model.eval()\n",
    "\n",
    "test_dataloader = DataLoader(valset, 1, False)\n",
    "result = []\n",
    "for x, _ in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    result.append(best_model(x).item())\n",
    "print(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "3bcdf616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[365073.      0.]\n",
      " [356630.      0.]\n",
      " [356634.      0.]\n",
      " ...\n",
      " [360600.      0.]\n",
      " [360601.      0.]\n",
      " [352249.      0.]]\n"
     ]
    }
   ],
   "source": [
    "keys_to_predict = sorted(ESun_public_y_answer['alert_key'].values.tolist())\n",
    "pairs = np.array(list(zip(keys_to_predict, result)))\n",
    "sorted_pairs = np.flip(pairs[pairs[:, 1].argsort()], 0)\n",
    "print(sorted_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "39f1e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "1384\n",
      "score:  0.0072254335260115606\n"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "SAR_count = 0\n",
    "for key, flag in ESun_public_y_answer.values.tolist():\n",
    "    if flag == 1:\n",
    "        SAR_count += 1\n",
    "        for idx in range(len(sorted_pairs)):\n",
    "            if key == sorted_pairs[idx][0]:\n",
    "                index_list.append(idx + 1)\n",
    "                break\n",
    "print(len(index_list))\n",
    "print(SAR_count)\n",
    "index_list.sort()\n",
    "print(index_list[-2])\n",
    "print(\"score: \", str((SAR_count - 1) / index_list[-2]))\n",
    "\n",
    "# 0.01, 0.05, 0.1, 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafb3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c4569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
