{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd168d4",
   "metadata": {},
   "source": [
    "# DNN\n",
    "1. 把all_keys.csv, ESun_public_y_answer.csv加到工作區\n",
    "2. 調整 # Main 下方的兩個block，第一個調參數，第二個建network\n",
    "3. 其他block應該不需要動\n",
    "4. 最後一個block會印成績"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a52fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c48c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db01d53",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6647343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 1vHDhZSPmhithLVRRzkNw0ak_kk7PhInu # V_trade\n",
    "# !gdown 145T8z3XXlsaISzWdrJgJVANGokG1XuFI # V_remit\n",
    "# !gdown 1AubrUmeNUgpgiOu4tay6Gwl8O3lBaokF # V_info\n",
    "# !gdown 1zZo9RLt3mMmJZxEETSY2g9ND31qkZIn0 # V_cred\n",
    "# !gdown 1uFCx21bqE3FnrdfvN_mwtw2-nvogTEex # V_cons\n",
    "# !gdown 1ZOXGT_rIdEGIliHGKEH3ha77ZlZyq1Gn # train_y\n",
    "# !gdown 1qjEwmi97OWdshSNdgQj2ccXnoM4UvT25 # V_trade_public\n",
    "# !gdown 1g8trBiC6OxuoTU94u_UMygVrA-fSASpB # V_remit_public\n",
    "# !gdown 14KTfY56Mz2xBXdP27GvGB2HVeb_4Ks4T # V_info_public\n",
    "# !gdown 1EaIWnjQxUl4KRgVCqYT7AB4PaSNvc_GL # V_cred_public\n",
    "# !gdown 1owf1urxHZywAxJfCgVXCpXEMQ6VZGhnO # V_cons_public\n",
    "# !gdown 1LbF8RTlCAuSm_78kA7oLaj91MxlZqhro # public_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf319e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cons = pd.read_csv('V_cons.csv').iloc[:, 1:]\n",
    "V_cred = pd.read_csv('V_cred.csv').iloc[:, 1:]\n",
    "V_info = pd.read_csv('V_info.csv').iloc[:, 1:]\n",
    "V_remit = pd.read_csv('V_remit.csv').iloc[:, 1:]\n",
    "V_trade = pd.read_csv('V_trade.csv').iloc[:, 1:]\n",
    "train_y = pd.read_csv('train_y.csv').iloc[:, 1:]\n",
    "\n",
    "V_cons_public = pd.read_csv('V_cons_public.csv').iloc[:, 1:]\n",
    "V_cred_public = pd.read_csv('V_cred_public.csv').iloc[:, 1:]\n",
    "V_info_public = pd.read_csv('V_info_public.csv').iloc[:, 1:]\n",
    "V_remit_public = pd.read_csv('V_remit_public.csv').iloc[:, 1:]\n",
    "V_trade_public = pd.read_csv('V_trade_public.csv').iloc[:, 1:]\n",
    "public_y = pd.read_csv('public_y.csv').iloc[:, 1:]\n",
    "\n",
    "all_keys = pd.read_csv('all_keys.csv')\n",
    "ESun_public_y_answer = pd.read_csv('ESun_public_y_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee62d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_overall = pd.concat([V_info, V_cred, V_cons, V_remit, V_trade], axis=1).fillna(0)\n",
    "V_overall_public = pd.concat([V_info_public, V_cred_public, V_cons_public, V_remit_public, V_trade_public], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00fa34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23906, 4)\n",
      "(23906, 117)\n",
      "(23906, 1965)\n",
      "(23906, 1572)\n",
      "(23906, 3537)\n",
      "(23906, 7195)\n",
      "\n",
      "(1845, 4)\n",
      "(1845, 117)\n",
      "(1845, 1965)\n",
      "(1845, 1572)\n",
      "(1845, 3537)\n",
      "(1845, 7195)\n",
      "\n",
      "(23906, 1)\n",
      "(1845, 1)\n",
      "\n",
      "(25751, 1)\n",
      "(1845, 2)\n"
     ]
    }
   ],
   "source": [
    "print(V_info.shape)\n",
    "print(V_cred.shape)\n",
    "print(V_cons.shape)\n",
    "print(V_remit.shape)\n",
    "print(V_trade.shape)\n",
    "print(V_overall.shape)\n",
    "print()\n",
    "print(V_info_public.shape)\n",
    "print(V_cred_public.shape)\n",
    "print(V_cons_public.shape)\n",
    "print(V_remit_public.shape)\n",
    "print(V_trade_public.shape)\n",
    "print(V_overall_public.shape)\n",
    "print()\n",
    "print(train_y.shape)\n",
    "print(public_y.shape)\n",
    "print()\n",
    "print(all_keys.shape)\n",
    "print(ESun_public_y_answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c111eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance = torch.tensor(V_overall.values).to(torch.float32)\n",
    "# print(torch.any(torch.isnan(instance)))\n",
    "# for row in range(len(instance)):\n",
    "#     for i in instance[row]:\n",
    "#         if torch.isnan(i):\n",
    "#             print(row, instance[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc5548a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "...  ..\n",
      "1840  0\n",
      "1841  0\n",
      "1842  0\n",
      "1843  0\n",
      "1844  0\n",
      "\n",
      "[1845 rows x 1 columns]\n",
      "0    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(public_y)\n",
    "print(public_y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa743e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1845 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "1840  0\n",
       "1841  0\n",
       "1842  0\n",
       "1843  0\n",
       "1844  0\n",
       "\n",
       "[1845 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afac17c",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d526e",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "68991903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "n_epoch = 10000\n",
    "batch = 128 \n",
    "lr = 0.0000001 # 0.0000001\n",
    "w = 1\n",
    "d, d2 = 99, 165 #99 # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "fcd5b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.network = nn.Sequential( # 7195 -> 1\n",
    "            nn.Linear(7195, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid() # last one must be sigmoid \n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "73b71b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prob, ans):\n",
    "    #print(prob, ans)\n",
    "    return (w * (1 - prob) * ans + (prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c13139",
   "metadata": {},
   "source": [
    "### quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "5b00dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set parameters\n",
    "# n_epoch = 10000\n",
    "# batch = 128 \n",
    "# lr = 0.0000001 # 0.0000001\n",
    "# w = 1\n",
    "# d, d2 = 99, 165 #99 # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "d64bc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define network\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.network = nn.Sequential( # 7195 -> 1\n",
    "#             nn.Linear(7195, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 1),\n",
    "#             nn.Sigmoid() # last one must be sigmoid \n",
    "#         )\n",
    "                \n",
    "#     def forward(self, x):\n",
    "#         x = self.network(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "ec767edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_function(prob, ans):\n",
    "#     #print(prob, ans)\n",
    "#     # a * x**n\n",
    "#     a = 2\n",
    "#     n = 2\n",
    "#     return (w * a * (1 - prob)**n * ans + a * (prob)**n * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972de33",
   "metadata": {},
   "source": [
    "### log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "6977cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob = torch.minimum(prob, torch.full((prob.size(dim=0), 1), 0.9999999).to(device))\n",
    "# prob = torch.maximum(prob, torch.full((prob.size(dim=0), 1), 0.0000001).to(device))\n",
    "# return (w * torch.log(1 - prob) * ans + torch.log(prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424a177",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "f9735999",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 22222\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "e3ad1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, val_data, model, n_epoch, batch, lr, device):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_loss = 1000000\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        idx = 0\n",
    "        for data, ans in train_data:\n",
    "            data, ans = data.to(device), ans.to(device)\n",
    "            prob = model(data)\n",
    "            loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += (loss.item() / len(train_data))\n",
    "            print('[Epoch %d | %d/%d] loss: %.4f' % ((epoch+1), idx*batch, len(train_data) * batch, loss.item()), end='\\r')\n",
    "            idx += 1\n",
    "        print(\"\\n  Training  | Loss:%.4f \" % total_loss)\n",
    "\n",
    "        # validation set\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        idx = 0 \n",
    "        with torch.no_grad():\n",
    "            for data, ans in val_data:\n",
    "                data, ans = data.to(device), ans.to(device)\n",
    "                prob = model(data)\n",
    "                loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "                total_loss += (loss.item() / len(val_data))\n",
    "                idx += 1\n",
    "            print(\" Validation | Loss:%.4f \" % total_loss)\n",
    "        # save model\n",
    "        if total_loss < best_loss:\n",
    "                best_loss = total_loss\n",
    "                print(\"saving model with loss %.4f...\\n\" % total_loss)\n",
    "                torch.save(model.state_dict(), \"%s\" % \"model.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "93609199",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # oversampling\n",
    "        print(\"Train\")\n",
    "        V_overall_list = V_overall.values.tolist()\n",
    "        train_y_list = train_y.values.tolist()\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_list[i][0] == 1:\n",
    "                V_overall_list.extend([V_overall_list[i] for j in range(d)])\n",
    "                train_y_list.extend([train_y_list[i] for j in range(d)])\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_list).to(torch.float32)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        print(\"Val\")\n",
    "        V_overall_public_list = V_overall_public.values.tolist()\n",
    "        train_y_public_list = public_y.values.tolist()\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"Before: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_public_list[i][0] == 1:\n",
    "                V_overall_public_list.extend([V_overall_public_list[i] for j in range(d2)])\n",
    "                train_y_public_list.extend([train_y_public_list[i] for j in range(d2)])\n",
    "        l = len(train_y_public_list)\n",
    "        s = sum(sum(train_y_public_list,[]))\n",
    "        print(\"After: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_public_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_public_list).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.tensor(V_overall_public.values).to(torch.float32)\n",
    "        self.Y = torch.tensor(public_y.values).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "5ba0c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Before: total=: 23906 flag=0: 23672 flag=1: 234 SAR_rate= 0.009788337655818623\n",
      "After: total=: 47072 flag=0: 23672 flag=1: 23400 SAR_rate= 0.4971108089734874\n",
      "Val\n",
      "Before: total=: 1845 flag=0: 1834 flag=1: 11 SAR_rate= 0.005962059620596206\n",
      "After: total=: 3660 flag=0: 1834 flag=1: 1826 SAR_rate= 0.4989071038251366\n"
     ]
    }
   ],
   "source": [
    "trainset = TrainDataset()\n",
    "valset = ValDataset()\n",
    "train_dataloader = DataLoader(trainset, batch, True)\n",
    "val_dataloader = DataLoader(valset, batch, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "9f226b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | 46976/47104] loss: 0.3290\n",
      "  Training  | Loss:0.4652 \n",
      " Validation | Loss:0.4726 \n",
      "saving model with loss 0.4726...\n",
      "\n",
      "[Epoch 2 | 46976/47104] loss: 0.4006\n",
      "  Training  | Loss:0.4614 \n",
      " Validation | Loss:0.4713 \n",
      "saving model with loss 0.4713...\n",
      "\n",
      "[Epoch 3 | 46976/47104] loss: 0.3359\n",
      "  Training  | Loss:0.4583 \n",
      " Validation | Loss:0.4702 \n",
      "saving model with loss 0.4702...\n",
      "\n",
      "[Epoch 4 | 46976/47104] loss: 0.3789\n",
      "  Training  | Loss:0.4555 \n",
      " Validation | Loss:0.4696 \n",
      "saving model with loss 0.4696...\n",
      "\n",
      "[Epoch 5 | 46976/47104] loss: 0.3162\n",
      "  Training  | Loss:0.4532 \n",
      " Validation | Loss:0.4686 \n",
      "saving model with loss 0.4686...\n",
      "\n",
      "[Epoch 6 | 46976/47104] loss: 0.3334\n",
      "  Training  | Loss:0.4500 \n",
      " Validation | Loss:0.4659 \n",
      "saving model with loss 0.4659...\n",
      "\n",
      "[Epoch 7 | 46976/47104] loss: 0.3427\n",
      "  Training  | Loss:0.4463 \n",
      " Validation | Loss:0.4592 \n",
      "saving model with loss 0.4592...\n",
      "\n",
      "[Epoch 8 | 46976/47104] loss: 0.3115\n",
      "  Training  | Loss:0.4405 \n",
      " Validation | Loss:0.4554 \n",
      "saving model with loss 0.4554...\n",
      "\n",
      "[Epoch 9 | 46976/47104] loss: 0.3153\n",
      "  Training  | Loss:0.4372 \n",
      " Validation | Loss:0.4533 \n",
      "saving model with loss 0.4533...\n",
      "\n",
      "[Epoch 10 | 46976/47104] loss: 0.2745\n",
      "  Training  | Loss:0.4346 \n",
      " Validation | Loss:0.4506 \n",
      "saving model with loss 0.4506...\n",
      "\n",
      "[Epoch 11 | 46976/47104] loss: 0.3795\n",
      "  Training  | Loss:0.4316 \n",
      " Validation | Loss:0.4481 \n",
      "saving model with loss 0.4481...\n",
      "\n",
      "[Epoch 12 | 46976/47104] loss: 0.3564\n",
      "  Training  | Loss:0.4285 \n",
      " Validation | Loss:0.4461 \n",
      "saving model with loss 0.4461...\n",
      "\n",
      "[Epoch 13 | 46976/47104] loss: 0.2710\n",
      "  Training  | Loss:0.4249 \n",
      " Validation | Loss:0.4442 \n",
      "saving model with loss 0.4442...\n",
      "\n",
      "[Epoch 14 | 46976/47104] loss: 0.3732\n",
      "  Training  | Loss:0.4219 \n",
      " Validation | Loss:0.4428 \n",
      "saving model with loss 0.4428...\n",
      "\n",
      "[Epoch 15 | 46976/47104] loss: 0.2879\n",
      "  Training  | Loss:0.4191 \n",
      " Validation | Loss:0.4408 \n",
      "saving model with loss 0.4408...\n",
      "\n",
      "[Epoch 16 | 46976/47104] loss: 0.2936\n",
      "  Training  | Loss:0.4159 \n",
      " Validation | Loss:0.4390 \n",
      "saving model with loss 0.4390...\n",
      "\n",
      "[Epoch 17 | 46976/47104] loss: 0.3010\n",
      "  Training  | Loss:0.4129 \n",
      " Validation | Loss:0.4371 \n",
      "saving model with loss 0.4371...\n",
      "\n",
      "[Epoch 18 | 46976/47104] loss: 0.3280\n",
      "  Training  | Loss:0.4098 \n",
      " Validation | Loss:0.4337 \n",
      "saving model with loss 0.4337...\n",
      "\n",
      "[Epoch 19 | 46976/47104] loss: 0.3024\n",
      "  Training  | Loss:0.4060 \n",
      " Validation | Loss:0.4265 \n",
      "saving model with loss 0.4265...\n",
      "\n",
      "[Epoch 20 | 46976/47104] loss: 0.3345\n",
      "  Training  | Loss:0.4019 \n",
      " Validation | Loss:0.4231 \n",
      "saving model with loss 0.4231...\n",
      "\n",
      "[Epoch 21 | 46976/47104] loss: 0.2716\n",
      "  Training  | Loss:0.3981 \n",
      " Validation | Loss:0.4204 \n",
      "saving model with loss 0.4204...\n",
      "\n",
      "[Epoch 22 | 46976/47104] loss: 0.2885\n",
      "  Training  | Loss:0.3950 \n",
      " Validation | Loss:0.4216 \n",
      "[Epoch 23 | 46976/47104] loss: 0.2446\n",
      "  Training  | Loss:0.3915 \n",
      " Validation | Loss:0.4329 \n",
      "[Epoch 24 | 46976/47104] loss: 0.2997\n",
      "  Training  | Loss:0.3874 \n",
      " Validation | Loss:0.4544 \n",
      "[Epoch 25 | 46976/47104] loss: 0.2411\n",
      "  Training  | Loss:0.3835 \n",
      " Validation | Loss:0.4543 \n",
      "[Epoch 26 | 46976/47104] loss: 0.2661\n",
      "  Training  | Loss:0.3797 \n",
      " Validation | Loss:0.4511 \n",
      "[Epoch 27 | 46976/47104] loss: 0.2845\n",
      "  Training  | Loss:0.3754 \n",
      " Validation | Loss:0.4460 \n",
      "[Epoch 28 | 46976/47104] loss: 0.2302\n",
      "  Training  | Loss:0.3710 \n",
      " Validation | Loss:0.4418 \n",
      "[Epoch 29 | 46976/47104] loss: 0.3182\n",
      "  Training  | Loss:0.3671 \n",
      " Validation | Loss:0.4383 \n",
      "[Epoch 30 | 46976/47104] loss: 0.2746\n",
      "  Training  | Loss:0.3632 \n",
      " Validation | Loss:0.4350 \n",
      "[Epoch 31 | 46976/47104] loss: 0.2398\n",
      "  Training  | Loss:0.3597 \n",
      " Validation | Loss:0.4322 \n",
      "[Epoch 32 | 46976/47104] loss: 0.3199\n",
      "  Training  | Loss:0.3563 \n",
      " Validation | Loss:0.4289 \n",
      "[Epoch 33 | 46976/47104] loss: 0.2332\n",
      "  Training  | Loss:0.3527 \n",
      " Validation | Loss:0.4256 \n",
      "[Epoch 34 | 46976/47104] loss: 0.2313\n",
      "  Training  | Loss:0.3493 \n",
      " Validation | Loss:0.4227 \n",
      "[Epoch 35 | 46976/47104] loss: 0.2356\n",
      "  Training  | Loss:0.3455 \n",
      " Validation | Loss:0.4187 \n",
      "saving model with loss 0.4187...\n",
      "\n",
      "[Epoch 36 | 46976/47104] loss: 0.2545\n",
      "  Training  | Loss:0.3422 \n",
      " Validation | Loss:0.4150 \n",
      "saving model with loss 0.4150...\n",
      "\n",
      "[Epoch 37 | 46976/47104] loss: 0.2764\n",
      "  Training  | Loss:0.3389 \n",
      " Validation | Loss:0.4116 \n",
      "saving model with loss 0.4116...\n",
      "\n",
      "[Epoch 38 | 46976/47104] loss: 0.2778\n",
      "  Training  | Loss:0.3351 \n",
      " Validation | Loss:0.4079 \n",
      "saving model with loss 0.4079...\n",
      "\n",
      "[Epoch 39 | 46976/47104] loss: 0.2568\n",
      "  Training  | Loss:0.3310 \n",
      " Validation | Loss:0.4044 \n",
      "saving model with loss 0.4044...\n",
      "\n",
      "[Epoch 40 | 46976/47104] loss: 0.2367\n",
      "  Training  | Loss:0.3258 \n",
      " Validation | Loss:0.4001 \n",
      "saving model with loss 0.4001...\n",
      "\n",
      "[Epoch 41 | 46976/47104] loss: 0.2551\n",
      "  Training  | Loss:0.3213 \n",
      " Validation | Loss:0.3978 \n",
      "saving model with loss 0.3978...\n",
      "\n",
      "[Epoch 42 | 46976/47104] loss: 0.2297\n",
      "  Training  | Loss:0.3173 \n",
      " Validation | Loss:0.3992 \n",
      "[Epoch 43 | 46976/47104] loss: 0.1721\n",
      "  Training  | Loss:0.3135 \n",
      " Validation | Loss:0.4361 \n",
      "[Epoch 44 | 46976/47104] loss: 0.1994\n",
      "  Training  | Loss:0.3096 \n",
      " Validation | Loss:0.4508 \n",
      "[Epoch 45 | 38272/47104] loss: 0.2908\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60/870323459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_60/1691746710.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, val_data, model, n_epoch, batch, lr, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[Epoch %d | %d/%d] loss: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "model = Net().to(device) \n",
    "model = train(train_dataloader, val_dataloader, model, n_epoch, batch, lr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f183c",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "269463ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "best_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "best_model = best_model.eval()\n",
    "\n",
    "testset = TestDataset()\n",
    "test_dataloader = DataLoader(testset, 1, False)\n",
    "result = []\n",
    "for x, _ in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    result.append(best_model(x).item())\n",
    "print(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "3bcdf616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.65073e+05 1.00000e+00]\n",
      " [3.58006e+05 1.00000e+00]\n",
      " [3.57871e+05 1.00000e+00]\n",
      " ...\n",
      " [3.61849e+05 0.00000e+00]\n",
      " [3.58481e+05 0.00000e+00]\n",
      " [3.63755e+05 0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "keys_to_predict = sorted(ESun_public_y_answer['alert_key'].values.tolist())\n",
    "pairs = np.array(list(zip(keys_to_predict, result)))\n",
    "sorted_pairs = np.flip(pairs[pairs[:, 1].argsort()], 0)\n",
    "print(sorted_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "39f1e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "1267\n",
      "score:  0.007892659826361484\n"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "SAR_count = 0\n",
    "for key, flag in ESun_public_y_answer.values.tolist():\n",
    "    if flag == 1:\n",
    "        SAR_count += 1\n",
    "        for idx in range(len(sorted_pairs)):\n",
    "            if key == sorted_pairs[idx][0]:\n",
    "                index_list.append(idx + 1)\n",
    "                break\n",
    "print(len(index_list))\n",
    "print(SAR_count)\n",
    "index_list.sort()\n",
    "print(index_list[-2])\n",
    "print(\"score: \", str((SAR_count - 1) / index_list[-2]))\n",
    "\n",
    "# 0.01, 0.05, 0.1, 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "de85f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_keys = []\n",
    "with open('example.csv', newline='') as example:\n",
    "    rows = csv.reader(example)\n",
    "    headers = next(rows)\n",
    "    for row in rows:\n",
    "        example_keys.append(int(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "9eafb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['alert_key','probability'])\n",
    "    for row in sorted_pairs:\n",
    "        writer.writerow([int(row[0]), row[1]])\n",
    "    for key in example_keys:\n",
    "        if key not in keys_to_predict:\n",
    "            writer.writerow([key, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "0d15ccc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[263, 484, 489, 499, 766, 787, 792, 865, 993, 1267, 1662]"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "20f03050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354939\n",
      "355091\n",
      "355152\n",
      "355724\n",
      "359668\n",
      "356602\n",
      "363320\n",
      "358453\n",
      "363896\n",
      "361617\n",
      "363033\n"
     ]
    }
   ],
   "source": [
    "for key, flag in ESun_public_y_answer.values.tolist():\n",
    "    if flag == 1:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a188216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
