{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd168d4",
   "metadata": {},
   "source": [
    "# DNN\n",
    "Our best result is generated by this script. The first line of each block briefly explain the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65479534",
   "metadata": {},
   "source": [
    "### Install and import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a52fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c48c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db01d53",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6647343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download processed data\n",
    "\n",
    "!gdown 1vHDhZSPmhithLVRRzkNw0ak_kk7PhInu # V_trade\n",
    "!gdown 145T8z3XXlsaISzWdrJgJVANGokG1XuFI # V_remit\n",
    "!gdown 1AubrUmeNUgpgiOu4tay6Gwl8O3lBaokF # V_info\n",
    "!gdown 1zZo9RLt3mMmJZxEETSY2g9ND31qkZIn0 # V_cred\n",
    "!gdown 1uFCx21bqE3FnrdfvN_mwtw2-nvogTEex # V_cons\n",
    "!gdown 1ZOXGT_rIdEGIliHGKEH3ha77ZlZyq1Gn # train_y\n",
    "!gdown 1qjEwmi97OWdshSNdgQj2ccXnoM4UvT25 # V_trade_public\n",
    "!gdown 1g8trBiC6OxuoTU94u_UMygVrA-fSASpB # V_remit_public\n",
    "!gdown 14KTfY56Mz2xBXdP27GvGB2HVeb_4Ks4T # V_info_public\n",
    "!gdown 1EaIWnjQxUl4KRgVCqYT7AB4PaSNvc_GL # V_cred_public\n",
    "!gdown 1owf1urxHZywAxJfCgVXCpXEMQ6VZGhnO # V_cons_public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf319e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data as csv\n",
    "\n",
    "V_cons = pd.read_csv('V_cons.csv').iloc[:, 1:]\n",
    "V_cred = pd.read_csv('V_cred.csv').iloc[:, 1:]\n",
    "V_info = pd.read_csv('V_info.csv').iloc[:, 1:]\n",
    "V_remit = pd.read_csv('V_remit.csv').iloc[:, 1:]\n",
    "V_trade = pd.read_csv('V_trade.csv').iloc[:, 1:]\n",
    "train_y = pd.read_csv('train_y.csv').iloc[:, 1:]\n",
    "\n",
    "V_cons_public = pd.read_csv('V_cons_public.csv').iloc[:, 1:]\n",
    "V_cred_public = pd.read_csv('V_cred_public.csv').iloc[:, 1:]\n",
    "V_info_public = pd.read_csv('V_info_public.csv').iloc[:, 1:]\n",
    "V_remit_public = pd.read_csv('V_remit_public.csv').iloc[:, 1:]\n",
    "V_trade_public = pd.read_csv('V_trade_public.csv').iloc[:, 1:]\n",
    "\n",
    "public_x_alert_date = pd.read_csv('public_x_alert_date.csv')\n",
    "all_keys = pd.read_csv('all_keys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee62d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes to get the entire training/testing data\n",
    "# some values are missing, fill them with 0\n",
    "\n",
    "V_overall = pd.concat([V_info, V_cred, V_cons, V_remit, V_trade], axis=1).fillna(0)\n",
    "V_overall_public = pd.concat([V_info_public, V_cred_public, V_cons_public, V_remit_public, V_trade_public], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fa34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23906, 4)\n",
      "(23906, 117)\n",
      "(23906, 1965)\n",
      "(23906, 1572)\n",
      "(23906, 3537)\n",
      "(23906, 7195)\n",
      "\n",
      "(1845, 4)\n",
      "(1845, 117)\n",
      "(1845, 1965)\n",
      "(1845, 1572)\n",
      "(1845, 3537)\n",
      "(1845, 7195)\n",
      "\n",
      "(23906, 1)\n",
      "\n",
      "(1845, 2)\n",
      "(25751, 1)\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of dataframes\n",
    "\n",
    "print(V_info.shape)\n",
    "print(V_cred.shape)\n",
    "print(V_cons.shape)\n",
    "print(V_remit.shape)\n",
    "print(V_trade.shape)\n",
    "print(V_overall.shape)\n",
    "print()\n",
    "print(V_info_public.shape)\n",
    "print(V_cred_public.shape)\n",
    "print(V_cons_public.shape)\n",
    "print(V_remit_public.shape)\n",
    "print(V_trade_public.shape)\n",
    "print(V_overall_public.shape)\n",
    "print()\n",
    "print(train_y.shape)\n",
    "print()\n",
    "print(public_x_alert_date.shape)\n",
    "print(all_keys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afac17c",
   "metadata": {},
   "source": [
    "### Settings\n",
    "There are three choice of cost function. The best result is generated by \"linear\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68991903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "n_epoch = 500  # number of epochs\n",
    "batch = 128  # batch size\n",
    "lr = 0.0000001  # learning rate\n",
    "w = 1  # penalty weight for false negative\n",
    "d = 99  # duplicate d times for SAR_flag == 1 (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd5b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.network = nn.Sequential( # 7195 -> 1\n",
    "            nn.Linear(7195, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid() # last one must be sigmoid \n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b71b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function (linear)\n",
    "\n",
    "def loss_function(prob, ans):\n",
    "    return (w * (1 - prob) * ans + (prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec767edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function (quadratic)\n",
    "\n",
    "# def loss_function(prob, ans):\n",
    "#     # a * x**n\n",
    "#     a = 2\n",
    "#     n = 2\n",
    "#     return (w * a * (1 - prob)**n * ans + a * (prob)**n * (1 - ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6977cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function (log)\n",
    "\n",
    "# prob = torch.minimum(prob, torch.full((prob.size(dim=0), 1), 0.9999999).to(device))\n",
    "# prob = torch.maximum(prob, torch.full((prob.size(dim=0), 1), 0.0000001).to(device))\n",
    "# return (w * torch.log(1 - prob) * ans + torch.log(prob) * (1 - ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424a177",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3ad1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process\n",
    "\n",
    "def train(train_data, val_data, model, n_epoch, batch, lr, device):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_loss = 1000000\n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        idx = 0\n",
    "        for data, ans in train_data:\n",
    "            data, ans = data.to(device), ans.to(device)\n",
    "            prob = model(data)\n",
    "            loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += (loss.item() / len(train_data))\n",
    "            print('[Epoch %d | %d/%d] loss: %.4f' % ((epoch+1), idx*batch, len(train_data) * batch, loss.item()), end='\\r')\n",
    "            idx += 1\n",
    "        print(\"\\n  Training  | Loss:%.4f \" % total_loss)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        idx = 0 \n",
    "        with torch.no_grad():\n",
    "            for data, ans in val_data:\n",
    "                data, ans = data.to(device), ans.to(device)\n",
    "                prob = model(data)\n",
    "                loss = torch.sum(loss_function(prob, ans)) / batch\n",
    "                total_loss += (loss.item() / len(val_data))\n",
    "                idx += 1\n",
    "            print(\" Validation | Loss:%.4f \" % total_loss)\n",
    "            \n",
    "        # save model\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            print(\"saving model with loss %.4f...\\n\" % total_loss)\n",
    "            torch.save(model.state_dict(), \"%s\" % \"model.pth\")\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93609199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the whole dataset\n",
    "# Oversampling: we duplicate the samples with SAR_flag=1 for d times\n",
    "# d=99 let the number of samples of flag=0 and flag=1 matches (SAR_rate = 0.5)\n",
    "\n",
    "class TrainValDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # oversampling\n",
    "        V_overall_list = V_overall.values.tolist()\n",
    "        train_y_list = train_y.values.tolist()\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"Before oversampling: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)        \n",
    "        for i in range(l):\n",
    "            if train_y_list[i][0] == 1:\n",
    "                V_overall_list.extend([V_overall_list[i] for j in range(d)])\n",
    "                train_y_list.extend([train_y_list[i] for j in range(d)])\n",
    "        l = len(train_y_list)\n",
    "        s = sum(sum(train_y_list,[]))\n",
    "        print(\"After oversampling: total=:\", l, \"flag=0:\", l - s, \"flag=1:\", s, \"SAR_rate=\", s / l)    \n",
    "        \n",
    "        self.X = torch.tensor(V_overall_list).to(torch.float32)\n",
    "        self.Y = torch.tensor(train_y_list).to(torch.float32)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114fac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define testing dataset\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.tensor(V_overall_public.values).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba0c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling: total=: 23906 flag=0: 23672 flag=1: 234 SAR_rate= 0.009788337655818623\n",
      "After oversampling: total=: 47072 flag=0: 23672 flag=1: 23400 SAR_rate= 0.4971108089734874\n"
     ]
    }
   ],
   "source": [
    "# split the whole dataset into training and validation set\n",
    "\n",
    "dataset = TrainValDataset()\n",
    "trainset, valset = random_split(dataset, [int(len(dataset) * 0.9), len(dataset) - int(len(dataset) * 0.9)])\n",
    "train_dataloader = DataLoader(trainset, batch, True)\n",
    "val_dataloader = DataLoader(valset, batch, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f226b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | 42240/42368] loss: 0.5176\n",
      "  Training  | Loss:0.5134 \n",
      " Validation | Loss:0.5140 \n",
      "saving model with loss 0.5140...\n",
      "\n",
      "[Epoch 2 | 42240/42368] loss: 0.4742\n",
      "  Training  | Loss:0.5132 \n",
      " Validation | Loss:0.5138 \n",
      "saving model with loss 0.5138...\n",
      "\n",
      "[Epoch 3 | 42240/42368] loss: 0.5084\n",
      "  Training  | Loss:0.5131 \n",
      " Validation | Loss:0.5137 \n",
      "saving model with loss 0.5137...\n",
      "\n",
      "[Epoch 4 | 42240/42368] loss: 0.5341\n",
      "  Training  | Loss:0.5129 \n",
      " Validation | Loss:0.5135 \n",
      "saving model with loss 0.5135...\n",
      "\n",
      "[Epoch 5 | 42240/42368] loss: 0.5659\n",
      "  Training  | Loss:0.5127 \n",
      " Validation | Loss:0.5133 \n",
      "saving model with loss 0.5133...\n",
      "\n",
      "[Epoch 6 | 42240/42368] loss: 0.3732\n",
      "  Training  | Loss:0.5125 \n",
      " Validation | Loss:0.5131 \n",
      "saving model with loss 0.5131...\n",
      "\n",
      "[Epoch 7 | 42240/42368] loss: 0.4864\n",
      "  Training  | Loss:0.5124 \n",
      " Validation | Loss:0.5129 \n",
      "saving model with loss 0.5129...\n",
      "\n",
      "[Epoch 8 | 42240/42368] loss: 0.5431\n",
      "  Training  | Loss:0.5122 \n",
      " Validation | Loss:0.5127 \n",
      "saving model with loss 0.5127...\n",
      "\n",
      "[Epoch 9 | 42240/42368] loss: 0.4985\n",
      "  Training  | Loss:0.5120 \n",
      " Validation | Loss:0.5125 \n",
      "saving model with loss 0.5125...\n",
      "\n",
      "[Epoch 10 | 42240/42368] loss: 0.4931\n",
      "  Training  | Loss:0.5118 \n",
      " Validation | Loss:0.5123 \n",
      "saving model with loss 0.5123...\n",
      "\n",
      "[Epoch 11 | 42240/42368] loss: 0.4970\n",
      "  Training  | Loss:0.5116 \n",
      " Validation | Loss:0.5121 \n",
      "saving model with loss 0.5121...\n",
      "\n",
      "[Epoch 12 | 42240/42368] loss: 0.5119\n",
      "  Training  | Loss:0.5113 \n",
      " Validation | Loss:0.5118 \n",
      "saving model with loss 0.5118...\n",
      "\n",
      "[Epoch 13 | 42240/42368] loss: 0.4451\n",
      "  Training  | Loss:0.5111 \n",
      " Validation | Loss:0.5115 \n",
      "saving model with loss 0.5115...\n",
      "\n",
      "[Epoch 14 | 42240/42368] loss: 0.4729\n",
      "  Training  | Loss:0.5108 \n",
      " Validation | Loss:0.5112 \n",
      "saving model with loss 0.5112...\n",
      "\n",
      "[Epoch 15 | 42240/42368] loss: 0.4626\n",
      "  Training  | Loss:0.5104 \n",
      " Validation | Loss:0.5107 \n",
      "saving model with loss 0.5107...\n",
      "\n",
      "[Epoch 16 | 42240/42368] loss: 0.4672\n",
      "  Training  | Loss:0.5099 \n",
      " Validation | Loss:0.5100 \n",
      "saving model with loss 0.5100...\n",
      "\n",
      "[Epoch 17 | 42240/42368] loss: 0.5702\n",
      "  Training  | Loss:0.5091 \n",
      " Validation | Loss:0.5089 \n",
      "saving model with loss 0.5089...\n",
      "\n",
      "[Epoch 18 | 42240/42368] loss: 0.5664\n",
      "  Training  | Loss:0.5082 \n",
      " Validation | Loss:0.5079 \n",
      "saving model with loss 0.5079...\n",
      "\n",
      "[Epoch 19 | 42240/42368] loss: 0.5046\n",
      "  Training  | Loss:0.5074 \n",
      " Validation | Loss:0.5072 \n",
      "saving model with loss 0.5072...\n",
      "\n",
      "[Epoch 20 | 42240/42368] loss: 0.3660\n",
      "  Training  | Loss:0.5059 \n",
      " Validation | Loss:0.5043 \n",
      "saving model with loss 0.5043...\n",
      "\n",
      "[Epoch 21 | 42240/42368] loss: 0.4465\n",
      "  Training  | Loss:0.5042 \n",
      " Validation | Loss:0.5038 \n",
      "saving model with loss 0.5038...\n",
      "\n",
      "[Epoch 22 | 42240/42368] loss: 0.4852\n",
      "  Training  | Loss:0.5038 \n",
      " Validation | Loss:0.5034 \n",
      "saving model with loss 0.5034...\n",
      "\n",
      "[Epoch 23 | 42240/42368] loss: 0.4918\n",
      "  Training  | Loss:0.5034 \n",
      " Validation | Loss:0.5031 \n",
      "saving model with loss 0.5031...\n",
      "\n",
      "[Epoch 24 | 42240/42368] loss: 0.4655\n",
      "  Training  | Loss:0.5031 \n",
      " Validation | Loss:0.5028 \n",
      "saving model with loss 0.5028...\n",
      "\n",
      "[Epoch 25 | 42240/42368] loss: 0.5761\n",
      "  Training  | Loss:0.5028 \n",
      " Validation | Loss:0.5024 \n",
      "saving model with loss 0.5024...\n",
      "\n",
      "[Epoch 26 | 42240/42368] loss: 0.4638\n",
      "  Training  | Loss:0.5023 \n",
      " Validation | Loss:0.5016 \n",
      "saving model with loss 0.5016...\n",
      "\n",
      "[Epoch 27 | 42240/42368] loss: 0.4666\n",
      "  Training  | Loss:0.5012 \n",
      " Validation | Loss:0.5004 \n",
      "saving model with loss 0.5004...\n",
      "\n",
      "[Epoch 28 | 42240/42368] loss: 0.4918\n",
      "  Training  | Loss:0.5003 \n",
      " Validation | Loss:0.4997 \n",
      "saving model with loss 0.4997...\n",
      "\n",
      "[Epoch 29 | 42240/42368] loss: 0.5091\n",
      "  Training  | Loss:0.4999 \n",
      " Validation | Loss:0.4993 \n",
      "saving model with loss 0.4993...\n",
      "\n",
      "[Epoch 30 | 42240/42368] loss: 0.4856\n",
      "  Training  | Loss:0.4995 \n",
      " Validation | Loss:0.4990 \n",
      "saving model with loss 0.4990...\n",
      "\n",
      "[Epoch 31 | 42240/42368] loss: 0.4321\n",
      "  Training  | Loss:0.4992 \n",
      " Validation | Loss:0.4987 \n",
      "saving model with loss 0.4987...\n",
      "\n",
      "[Epoch 32 | 42240/42368] loss: 0.4492\n",
      "  Training  | Loss:0.4990 \n",
      " Validation | Loss:0.4984 \n",
      "saving model with loss 0.4984...\n",
      "\n",
      "[Epoch 33 | 42240/42368] loss: 0.5003\n",
      "  Training  | Loss:0.4987 \n",
      " Validation | Loss:0.4981 \n",
      "saving model with loss 0.4981...\n",
      "\n",
      "[Epoch 34 | 42240/42368] loss: 0.5175\n",
      "  Training  | Loss:0.4984 \n",
      " Validation | Loss:0.4978 \n",
      "saving model with loss 0.4978...\n",
      "\n",
      "[Epoch 35 | 42240/42368] loss: 0.4477\n",
      "  Training  | Loss:0.4981 \n",
      " Validation | Loss:0.4975 \n",
      "saving model with loss 0.4975...\n",
      "\n",
      "[Epoch 36 | 42240/42368] loss: 0.4339\n",
      "  Training  | Loss:0.4979 \n",
      " Validation | Loss:0.4972 \n",
      "saving model with loss 0.4972...\n",
      "\n",
      "[Epoch 37 | 42240/42368] loss: 0.5575\n",
      "  Training  | Loss:0.4976 \n",
      " Validation | Loss:0.4969 \n",
      "saving model with loss 0.4969...\n",
      "\n",
      "[Epoch 38 | 42240/42368] loss: 0.4583\n",
      "  Training  | Loss:0.4973 \n",
      " Validation | Loss:0.4966 \n",
      "saving model with loss 0.4966...\n",
      "\n",
      "[Epoch 39 | 42240/42368] loss: 0.5166\n",
      "  Training  | Loss:0.4970 \n",
      " Validation | Loss:0.4963 \n",
      "saving model with loss 0.4963...\n",
      "\n",
      "[Epoch 40 | 42240/42368] loss: 0.4718\n",
      "  Training  | Loss:0.4967 \n",
      " Validation | Loss:0.4959 \n",
      "saving model with loss 0.4959...\n",
      "\n",
      "[Epoch 41 | 42240/42368] loss: 0.4727\n",
      "  Training  | Loss:0.4964 \n",
      " Validation | Loss:0.4956 \n",
      "saving model with loss 0.4956...\n",
      "\n",
      "[Epoch 42 | 42240/42368] loss: 0.4628\n",
      "  Training  | Loss:0.4961 \n",
      " Validation | Loss:0.4952 \n",
      "saving model with loss 0.4952...\n",
      "\n",
      "[Epoch 43 | 42240/42368] loss: 0.4428\n",
      "  Training  | Loss:0.4958 \n",
      " Validation | Loss:0.4948 \n",
      "saving model with loss 0.4948...\n",
      "\n",
      "[Epoch 44 | 42240/42368] loss: 0.4874\n",
      "  Training  | Loss:0.4955 \n",
      " Validation | Loss:0.4945 \n",
      "saving model with loss 0.4945...\n",
      "\n",
      "[Epoch 45 | 42240/42368] loss: 0.4580\n",
      "  Training  | Loss:0.4952 \n",
      " Validation | Loss:0.4941 \n",
      "saving model with loss 0.4941...\n",
      "\n",
      "[Epoch 46 | 42240/42368] loss: 0.4569\n",
      "  Training  | Loss:0.4949 \n",
      " Validation | Loss:0.4937 \n",
      "saving model with loss 0.4937...\n",
      "\n",
      "[Epoch 47 | 42240/42368] loss: 0.4687\n",
      "  Training  | Loss:0.4945 \n",
      " Validation | Loss:0.4934 \n",
      "saving model with loss 0.4934...\n",
      "\n",
      "[Epoch 48 | 42240/42368] loss: 0.5429\n",
      "  Training  | Loss:0.4943 \n",
      " Validation | Loss:0.4930 \n",
      "saving model with loss 0.4930...\n",
      "\n",
      "[Epoch 49 | 42240/42368] loss: 0.4203\n",
      "  Training  | Loss:0.4940 \n",
      " Validation | Loss:0.4927 \n",
      "saving model with loss 0.4927...\n",
      "\n",
      "[Epoch 50 | 42240/42368] loss: 0.4874\n",
      "  Training  | Loss:0.4937 \n",
      " Validation | Loss:0.4923 \n",
      "saving model with loss 0.4923...\n",
      "\n",
      "[Epoch 51 | 42240/42368] loss: 0.4705\n",
      "  Training  | Loss:0.4934 \n",
      " Validation | Loss:0.4920 \n",
      "saving model with loss 0.4920...\n",
      "\n",
      "[Epoch 52 | 42240/42368] loss: 0.5268\n",
      "  Training  | Loss:0.4931 \n",
      " Validation | Loss:0.4917 \n",
      "saving model with loss 0.4917...\n",
      "\n",
      "[Epoch 53 | 42240/42368] loss: 0.5264\n",
      "  Training  | Loss:0.4929 \n",
      " Validation | Loss:0.4914 \n",
      "saving model with loss 0.4914...\n",
      "\n",
      "[Epoch 54 | 42240/42368] loss: 0.5311\n",
      "  Training  | Loss:0.4926 \n",
      " Validation | Loss:0.4911 \n",
      "saving model with loss 0.4911...\n",
      "\n",
      "[Epoch 55 | 42240/42368] loss: 0.4627\n",
      "  Training  | Loss:0.4924 \n",
      " Validation | Loss:0.4908 \n",
      "saving model with loss 0.4908...\n",
      "\n",
      "[Epoch 56 | 42240/42368] loss: 0.5173\n",
      "  Training  | Loss:0.4921 \n",
      " Validation | Loss:0.4905 \n",
      "saving model with loss 0.4905...\n",
      "\n",
      "[Epoch 57 | 42240/42368] loss: 0.4911\n",
      "  Training  | Loss:0.4919 \n",
      " Validation | Loss:0.4902 \n",
      "saving model with loss 0.4902...\n",
      "\n",
      "[Epoch 58 | 42240/42368] loss: 0.5186\n",
      "  Training  | Loss:0.4916 \n",
      " Validation | Loss:0.4899 \n",
      "saving model with loss 0.4899...\n",
      "\n",
      "[Epoch 59 | 42240/42368] loss: 0.4067\n",
      "  Training  | Loss:0.4914 \n",
      " Validation | Loss:0.4896 \n",
      "saving model with loss 0.4896...\n",
      "\n",
      "[Epoch 60 | 42240/42368] loss: 0.4479\n",
      "  Training  | Loss:0.4911 \n",
      " Validation | Loss:0.4894 \n",
      "saving model with loss 0.4894...\n",
      "\n",
      "[Epoch 61 | 42240/42368] loss: 0.5799\n",
      "  Training  | Loss:0.4909 \n",
      " Validation | Loss:0.4891 \n",
      "saving model with loss 0.4891...\n",
      "\n",
      "[Epoch 62 | 42240/42368] loss: 0.4314\n",
      "  Training  | Loss:0.4906 \n",
      " Validation | Loss:0.4887 \n",
      "saving model with loss 0.4887...\n",
      "\n",
      "[Epoch 63 | 42240/42368] loss: 0.5075\n",
      "  Training  | Loss:0.4901 \n",
      " Validation | Loss:0.4881 \n",
      "saving model with loss 0.4881...\n",
      "\n",
      "[Epoch 64 | 42240/42368] loss: 0.4547\n",
      "  Training  | Loss:0.4895 \n",
      " Validation | Loss:0.4873 \n",
      "saving model with loss 0.4873...\n",
      "\n",
      "[Epoch 65 | 42240/42368] loss: 0.4596\n",
      "  Training  | Loss:0.4888 \n",
      " Validation | Loss:0.4867 \n",
      "saving model with loss 0.4867...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66 | 42240/42368] loss: 0.3920\n",
      "  Training  | Loss:0.4883 \n",
      " Validation | Loss:0.4862 \n",
      "saving model with loss 0.4862...\n",
      "\n",
      "[Epoch 67 | 42240/42368] loss: 0.4559\n",
      "  Training  | Loss:0.4879 \n",
      " Validation | Loss:0.4857 \n",
      "saving model with loss 0.4857...\n",
      "\n",
      "[Epoch 68 | 42240/42368] loss: 0.4475\n",
      "  Training  | Loss:0.4874 \n",
      " Validation | Loss:0.4850 \n",
      "saving model with loss 0.4850...\n",
      "\n",
      "[Epoch 69 | 42240/42368] loss: 0.5114\n",
      "  Training  | Loss:0.4868 \n",
      " Validation | Loss:0.4841 \n",
      "saving model with loss 0.4841...\n",
      "\n",
      "[Epoch 70 | 42240/42368] loss: 0.4614\n",
      "  Training  | Loss:0.4863 \n",
      " Validation | Loss:0.4834 \n",
      "saving model with loss 0.4834...\n",
      "\n",
      "[Epoch 71 | 42240/42368] loss: 0.5656\n",
      "  Training  | Loss:0.4858 \n",
      " Validation | Loss:0.4827 \n",
      "saving model with loss 0.4827...\n",
      "\n",
      "[Epoch 72 | 42240/42368] loss: 0.4577\n",
      "  Training  | Loss:0.4854 \n",
      " Validation | Loss:0.4822 \n",
      "saving model with loss 0.4822...\n",
      "\n",
      "[Epoch 73 | 42240/42368] loss: 0.4466\n",
      "  Training  | Loss:0.4850 \n",
      " Validation | Loss:0.4818 \n",
      "saving model with loss 0.4818...\n",
      "\n",
      "[Epoch 74 | 42240/42368] loss: 0.4850\n",
      "  Training  | Loss:0.4847 \n",
      " Validation | Loss:0.4814 \n",
      "saving model with loss 0.4814...\n",
      "\n",
      "[Epoch 75 | 42240/42368] loss: 0.4435\n",
      "  Training  | Loss:0.4844 \n",
      " Validation | Loss:0.4810 \n",
      "saving model with loss 0.4810...\n",
      "\n",
      "[Epoch 76 | 42240/42368] loss: 0.4561\n",
      "  Training  | Loss:0.4840 \n",
      " Validation | Loss:0.4806 \n",
      "saving model with loss 0.4806...\n",
      "\n",
      "[Epoch 77 | 42240/42368] loss: 0.4681\n",
      "  Training  | Loss:0.4837 \n",
      " Validation | Loss:0.4802 \n",
      "saving model with loss 0.4802...\n",
      "\n",
      "[Epoch 78 | 42240/42368] loss: 0.4976\n",
      "  Training  | Loss:0.4833 \n",
      " Validation | Loss:0.4797 \n",
      "saving model with loss 0.4797...\n",
      "\n",
      "[Epoch 79 | 42240/42368] loss: 0.4695\n",
      "  Training  | Loss:0.4829 \n",
      " Validation | Loss:0.4792 \n",
      "saving model with loss 0.4792...\n",
      "\n",
      "[Epoch 80 | 42240/42368] loss: 0.5180\n",
      "  Training  | Loss:0.4825 \n",
      " Validation | Loss:0.4787 \n",
      "saving model with loss 0.4787...\n",
      "\n",
      "[Epoch 81 | 42240/42368] loss: 0.4883\n",
      "  Training  | Loss:0.4820 \n",
      " Validation | Loss:0.4781 \n",
      "saving model with loss 0.4781...\n",
      "\n",
      "[Epoch 82 | 42240/42368] loss: 0.4434\n",
      "  Training  | Loss:0.4814 \n",
      " Validation | Loss:0.4772 \n",
      "saving model with loss 0.4772...\n",
      "\n",
      "[Epoch 83 | 42240/42368] loss: 0.5782\n",
      "  Training  | Loss:0.4804 \n",
      " Validation | Loss:0.4757 \n",
      "saving model with loss 0.4757...\n",
      "\n",
      "[Epoch 84 | 42240/42368] loss: 0.4409\n",
      "  Training  | Loss:0.4791 \n",
      " Validation | Loss:0.4737 \n",
      "saving model with loss 0.4737...\n",
      "\n",
      "[Epoch 85 | 42240/42368] loss: 0.4487\n",
      "  Training  | Loss:0.4761 \n",
      " Validation | Loss:0.4714 \n",
      "saving model with loss 0.4714...\n",
      "\n",
      "[Epoch 86 | 42240/42368] loss: 0.5154\n",
      "  Training  | Loss:0.4754 \n",
      " Validation | Loss:0.4708 \n",
      "saving model with loss 0.4708...\n",
      "\n",
      "[Epoch 87 | 42240/42368] loss: 0.4427\n",
      "  Training  | Loss:0.4749 \n",
      " Validation | Loss:0.4703 \n",
      "saving model with loss 0.4703...\n",
      "\n",
      "[Epoch 88 | 42240/42368] loss: 0.4842\n",
      "  Training  | Loss:0.4745 \n",
      " Validation | Loss:0.4699 \n",
      "saving model with loss 0.4699...\n",
      "\n",
      "[Epoch 89 | 42240/42368] loss: 0.4504\n",
      "  Training  | Loss:0.4741 \n",
      " Validation | Loss:0.4696 \n",
      "saving model with loss 0.4696...\n",
      "\n",
      "[Epoch 90 | 42240/42368] loss: 0.4992\n",
      "  Training  | Loss:0.4737 \n",
      " Validation | Loss:0.4693 \n",
      "saving model with loss 0.4693...\n",
      "\n",
      "[Epoch 91 | 42240/42368] loss: 0.4601\n",
      "  Training  | Loss:0.4734 \n",
      " Validation | Loss:0.4690 \n",
      "saving model with loss 0.4690...\n",
      "\n",
      "[Epoch 92 | 42240/42368] loss: 0.4470\n",
      "  Training  | Loss:0.4730 \n",
      " Validation | Loss:0.4687 \n",
      "saving model with loss 0.4687...\n",
      "\n",
      "[Epoch 93 | 42240/42368] loss: 0.3680\n",
      "  Training  | Loss:0.4727 \n",
      " Validation | Loss:0.4684 \n",
      "saving model with loss 0.4684...\n",
      "\n",
      "[Epoch 94 | 42240/42368] loss: 0.4485\n",
      "  Training  | Loss:0.4724 \n",
      " Validation | Loss:0.4682 \n",
      "saving model with loss 0.4682...\n",
      "\n",
      "[Epoch 95 | 42240/42368] loss: 0.4602\n",
      "  Training  | Loss:0.4720 \n",
      " Validation | Loss:0.4679 \n",
      "saving model with loss 0.4679...\n",
      "\n",
      "[Epoch 96 | 42240/42368] loss: 0.4596\n",
      "  Training  | Loss:0.4717 \n",
      " Validation | Loss:0.4676 \n",
      "saving model with loss 0.4676...\n",
      "\n",
      "[Epoch 97 | 42240/42368] loss: 0.4041\n",
      "  Training  | Loss:0.4713 \n",
      " Validation | Loss:0.4673 \n",
      "saving model with loss 0.4673...\n",
      "\n",
      "[Epoch 98 | 42240/42368] loss: 0.4638\n",
      "  Training  | Loss:0.4710 \n",
      " Validation | Loss:0.4670 \n",
      "saving model with loss 0.4670...\n",
      "\n",
      "[Epoch 99 | 42240/42368] loss: 0.5057\n",
      "  Training  | Loss:0.4706 \n",
      " Validation | Loss:0.4667 \n",
      "saving model with loss 0.4667...\n",
      "\n",
      "[Epoch 100 | 42240/42368] loss: 0.4661\n",
      "  Training  | Loss:0.4702 \n",
      " Validation | Loss:0.4664 \n",
      "saving model with loss 0.4664...\n",
      "\n",
      "[Epoch 101 | 42240/42368] loss: 0.4532\n",
      "  Training  | Loss:0.4698 \n",
      " Validation | Loss:0.4661 \n",
      "saving model with loss 0.4661...\n",
      "\n",
      "[Epoch 102 | 42240/42368] loss: 0.4254\n",
      "  Training  | Loss:0.4695 \n",
      " Validation | Loss:0.4658 \n",
      "saving model with loss 0.4658...\n",
      "\n",
      "[Epoch 103 | 42240/42368] loss: 0.4559\n",
      "  Training  | Loss:0.4691 \n",
      " Validation | Loss:0.4655 \n",
      "saving model with loss 0.4655...\n",
      "\n",
      "[Epoch 104 | 42240/42368] loss: 0.4874\n",
      "  Training  | Loss:0.4688 \n",
      " Validation | Loss:0.4652 \n",
      "saving model with loss 0.4652...\n",
      "\n",
      "[Epoch 105 | 42240/42368] loss: 0.4000\n",
      "  Training  | Loss:0.4684 \n",
      " Validation | Loss:0.4649 \n",
      "saving model with loss 0.4649...\n",
      "\n",
      "[Epoch 106 | 42240/42368] loss: 0.4635\n",
      "  Training  | Loss:0.4681 \n",
      " Validation | Loss:0.4646 \n",
      "saving model with loss 0.4646...\n",
      "\n",
      "[Epoch 107 | 42240/42368] loss: 0.4868\n",
      "  Training  | Loss:0.4677 \n",
      " Validation | Loss:0.4643 \n",
      "saving model with loss 0.4643...\n",
      "\n",
      "[Epoch 108 | 42240/42368] loss: 0.4514\n",
      "  Training  | Loss:0.4674 \n",
      " Validation | Loss:0.4640 \n",
      "saving model with loss 0.4640...\n",
      "\n",
      "[Epoch 109 | 42240/42368] loss: 0.4580\n",
      "  Training  | Loss:0.4670 \n",
      " Validation | Loss:0.4637 \n",
      "saving model with loss 0.4637...\n",
      "\n",
      "[Epoch 110 | 42240/42368] loss: 0.5191\n",
      "  Training  | Loss:0.4667 \n",
      " Validation | Loss:0.4634 \n",
      "saving model with loss 0.4634...\n",
      "\n",
      "[Epoch 111 | 42240/42368] loss: 0.5069\n",
      "  Training  | Loss:0.4664 \n",
      " Validation | Loss:0.4631 \n",
      "saving model with loss 0.4631...\n",
      "\n",
      "[Epoch 112 | 42240/42368] loss: 0.4504\n",
      "  Training  | Loss:0.4661 \n",
      " Validation | Loss:0.4629 \n",
      "saving model with loss 0.4629...\n",
      "\n",
      "[Epoch 113 | 42240/42368] loss: 0.4671\n",
      "  Training  | Loss:0.4657 \n",
      " Validation | Loss:0.4626 \n",
      "saving model with loss 0.4626...\n",
      "\n",
      "[Epoch 114 | 42240/42368] loss: 0.4470\n",
      "  Training  | Loss:0.4650 \n",
      " Validation | Loss:0.4596 \n",
      "saving model with loss 0.4596...\n",
      "\n",
      "[Epoch 115 | 42240/42368] loss: 0.4907\n",
      "  Training  | Loss:0.4629 \n",
      " Validation | Loss:0.4592 \n",
      "saving model with loss 0.4592...\n",
      "\n",
      "[Epoch 116 | 42240/42368] loss: 0.4805\n",
      "  Training  | Loss:0.4623 \n",
      " Validation | Loss:0.4563 \n",
      "saving model with loss 0.4563...\n",
      "\n",
      "[Epoch 117 | 42240/42368] loss: 0.4183\n",
      "  Training  | Loss:0.4602 \n",
      " Validation | Loss:0.4551 \n",
      "saving model with loss 0.4551...\n",
      "\n",
      "[Epoch 118 | 42240/42368] loss: 0.4214\n",
      "  Training  | Loss:0.4596 \n",
      " Validation | Loss:0.4547 \n",
      "saving model with loss 0.4547...\n",
      "\n",
      "[Epoch 119 | 42240/42368] loss: 0.4593\n",
      "  Training  | Loss:0.4591 \n",
      " Validation | Loss:0.4544 \n",
      "saving model with loss 0.4544...\n",
      "\n",
      "[Epoch 120 | 42240/42368] loss: 0.4636\n",
      "  Training  | Loss:0.4587 \n",
      " Validation | Loss:0.4540 \n",
      "saving model with loss 0.4540...\n",
      "\n",
      "[Epoch 121 | 42240/42368] loss: 0.4571\n",
      "  Training  | Loss:0.4583 \n",
      " Validation | Loss:0.4537 \n",
      "saving model with loss 0.4537...\n",
      "\n",
      "[Epoch 122 | 42240/42368] loss: 0.4896\n",
      "  Training  | Loss:0.4580 \n",
      " Validation | Loss:0.4534 \n",
      "saving model with loss 0.4534...\n",
      "\n",
      "[Epoch 123 | 42240/42368] loss: 0.4647\n",
      "  Training  | Loss:0.4577 \n",
      " Validation | Loss:0.4531 \n",
      "saving model with loss 0.4531...\n",
      "\n",
      "[Epoch 124 | 42240/42368] loss: 0.4263\n",
      "  Training  | Loss:0.4574 \n",
      " Validation | Loss:0.4529 \n",
      "saving model with loss 0.4529...\n",
      "\n",
      "[Epoch 125 | 42240/42368] loss: 0.4651\n",
      "  Training  | Loss:0.4571 \n",
      " Validation | Loss:0.4526 \n",
      "saving model with loss 0.4526...\n",
      "\n",
      "[Epoch 126 | 42240/42368] loss: 0.4045\n",
      "  Training  | Loss:0.4568 \n",
      " Validation | Loss:0.4522 \n",
      "saving model with loss 0.4522...\n",
      "\n",
      "[Epoch 127 | 42240/42368] loss: 0.4344\n",
      "  Training  | Loss:0.4565 \n",
      " Validation | Loss:0.4518 \n",
      "saving model with loss 0.4518...\n",
      "\n",
      "[Epoch 128 | 42240/42368] loss: 0.3495\n",
      "  Training  | Loss:0.4559 \n",
      " Validation | Loss:0.4509 \n",
      "saving model with loss 0.4509...\n",
      "\n",
      "[Epoch 129 | 42240/42368] loss: 0.4419\n",
      "  Training  | Loss:0.4552 \n",
      " Validation | Loss:0.4500 \n",
      "saving model with loss 0.4500...\n",
      "\n",
      "[Epoch 130 | 42240/42368] loss: 0.4757\n",
      "  Training  | Loss:0.4546 \n",
      " Validation | Loss:0.4494 \n",
      "saving model with loss 0.4494...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 131 | 42240/42368] loss: 0.4267\n",
      "  Training  | Loss:0.4542 \n",
      " Validation | Loss:0.4490 \n",
      "saving model with loss 0.4490...\n",
      "\n",
      "[Epoch 132 | 42240/42368] loss: 0.4110\n",
      "  Training  | Loss:0.4539 \n",
      " Validation | Loss:0.4487 \n",
      "saving model with loss 0.4487...\n",
      "\n",
      "[Epoch 133 | 42240/42368] loss: 0.4872\n",
      "  Training  | Loss:0.4536 \n",
      " Validation | Loss:0.4484 \n",
      "saving model with loss 0.4484...\n",
      "\n",
      "[Epoch 134 | 42240/42368] loss: 0.4408\n",
      "  Training  | Loss:0.4534 \n",
      " Validation | Loss:0.4482 \n",
      "saving model with loss 0.4482...\n",
      "\n",
      "[Epoch 135 | 42240/42368] loss: 0.4241\n",
      "  Training  | Loss:0.4531 \n",
      " Validation | Loss:0.4480 \n",
      "saving model with loss 0.4480...\n",
      "\n",
      "[Epoch 136 | 42240/42368] loss: 0.4770\n",
      "  Training  | Loss:0.4529 \n",
      " Validation | Loss:0.4478 \n",
      "saving model with loss 0.4478...\n",
      "\n",
      "[Epoch 137 | 42240/42368] loss: 0.5340\n",
      "  Training  | Loss:0.4527 \n",
      " Validation | Loss:0.4476 \n",
      "saving model with loss 0.4476...\n",
      "\n",
      "[Epoch 138 | 42240/42368] loss: 0.4428\n",
      "  Training  | Loss:0.4526 \n",
      " Validation | Loss:0.4474 \n",
      "saving model with loss 0.4474...\n",
      "\n",
      "[Epoch 139 | 42240/42368] loss: 0.4880\n",
      "  Training  | Loss:0.4524 \n",
      " Validation | Loss:0.4473 \n",
      "saving model with loss 0.4473...\n",
      "\n",
      "[Epoch 140 | 42240/42368] loss: 0.4880\n",
      "  Training  | Loss:0.4522 \n",
      " Validation | Loss:0.4471 \n",
      "saving model with loss 0.4471...\n",
      "\n",
      "[Epoch 141 | 42240/42368] loss: 0.3722\n",
      "  Training  | Loss:0.4520 \n",
      " Validation | Loss:0.4469 \n",
      "saving model with loss 0.4469...\n",
      "\n",
      "[Epoch 142 | 42240/42368] loss: 0.4281\n",
      "  Training  | Loss:0.4519 \n",
      " Validation | Loss:0.4468 \n",
      "saving model with loss 0.4468...\n",
      "\n",
      "[Epoch 143 | 42240/42368] loss: 0.4128\n",
      "  Training  | Loss:0.4517 \n",
      " Validation | Loss:0.4466 \n",
      "saving model with loss 0.4466...\n",
      "\n",
      "[Epoch 144 | 42240/42368] loss: 0.4405\n",
      "  Training  | Loss:0.4509 \n",
      " Validation | Loss:0.4442 \n",
      "saving model with loss 0.4442...\n",
      "\n",
      "[Epoch 145 | 42240/42368] loss: 0.4632\n",
      "  Training  | Loss:0.4496 \n",
      " Validation | Loss:0.4438 \n",
      "saving model with loss 0.4438...\n",
      "\n",
      "[Epoch 146 | 42240/42368] loss: 0.3908\n",
      "  Training  | Loss:0.4494 \n",
      " Validation | Loss:0.4436 \n",
      "saving model with loss 0.4436...\n",
      "\n",
      "[Epoch 147 | 42240/42368] loss: 0.3969\n",
      "  Training  | Loss:0.4492 \n",
      " Validation | Loss:0.4435 \n",
      "saving model with loss 0.4435...\n",
      "\n",
      "[Epoch 148 | 42240/42368] loss: 0.4758\n",
      "  Training  | Loss:0.4491 \n",
      " Validation | Loss:0.4434 \n",
      "saving model with loss 0.4434...\n",
      "\n",
      "[Epoch 149 | 42240/42368] loss: 0.4461\n",
      "  Training  | Loss:0.4489 \n",
      " Validation | Loss:0.4433 \n",
      "saving model with loss 0.4433...\n",
      "\n",
      "[Epoch 150 | 42240/42368] loss: 0.4059\n",
      "  Training  | Loss:0.4488 \n",
      " Validation | Loss:0.4432 \n",
      "saving model with loss 0.4432...\n",
      "\n",
      "[Epoch 151 | 42240/42368] loss: 0.5240\n",
      "  Training  | Loss:0.4487 \n",
      " Validation | Loss:0.4430 \n",
      "saving model with loss 0.4430...\n",
      "\n",
      "[Epoch 152 | 42240/42368] loss: 0.4507\n",
      "  Training  | Loss:0.4486 \n",
      " Validation | Loss:0.4429 \n",
      "saving model with loss 0.4429...\n",
      "\n",
      "[Epoch 153 | 42240/42368] loss: 0.4841\n",
      "  Training  | Loss:0.4484 \n",
      " Validation | Loss:0.4428 \n",
      "saving model with loss 0.4428...\n",
      "\n",
      "[Epoch 154 | 42240/42368] loss: 0.4401\n",
      "  Training  | Loss:0.4483 \n",
      " Validation | Loss:0.4426 \n",
      "saving model with loss 0.4426...\n",
      "\n",
      "[Epoch 155 | 42240/42368] loss: 0.3936\n",
      "  Training  | Loss:0.4482 \n",
      " Validation | Loss:0.4425 \n",
      "saving model with loss 0.4425...\n",
      "\n",
      "[Epoch 156 | 42240/42368] loss: 0.4041\n",
      "  Training  | Loss:0.4481 \n",
      " Validation | Loss:0.4424 \n",
      "saving model with loss 0.4424...\n",
      "\n",
      "[Epoch 157 | 42240/42368] loss: 0.4394\n",
      "  Training  | Loss:0.4480 \n",
      " Validation | Loss:0.4423 \n",
      "saving model with loss 0.4423...\n",
      "\n",
      "[Epoch 158 | 42240/42368] loss: 0.4364\n",
      "  Training  | Loss:0.4479 \n",
      " Validation | Loss:0.4421 \n",
      "saving model with loss 0.4421...\n",
      "\n",
      "[Epoch 159 | 42240/42368] loss: 0.4259\n",
      "  Training  | Loss:0.4477 \n",
      " Validation | Loss:0.4420 \n",
      "saving model with loss 0.4420...\n",
      "\n",
      "[Epoch 160 | 42240/42368] loss: 0.4447\n",
      "  Training  | Loss:0.4476 \n",
      " Validation | Loss:0.4419 \n",
      "saving model with loss 0.4419...\n",
      "\n",
      "[Epoch 161 | 42240/42368] loss: 0.4558\n",
      "  Training  | Loss:0.4475 \n",
      " Validation | Loss:0.4418 \n",
      "saving model with loss 0.4418...\n",
      "\n",
      "[Epoch 162 | 42240/42368] loss: 0.4461\n",
      "  Training  | Loss:0.4474 \n",
      " Validation | Loss:0.4416 \n",
      "saving model with loss 0.4416...\n",
      "\n",
      "[Epoch 163 | 42240/42368] loss: 0.4519\n",
      "  Training  | Loss:0.4473 \n",
      " Validation | Loss:0.4415 \n",
      "saving model with loss 0.4415...\n",
      "\n",
      "[Epoch 164 | 42240/42368] loss: 0.5068\n",
      "  Training  | Loss:0.4472 \n",
      " Validation | Loss:0.4414 \n",
      "saving model with loss 0.4414...\n",
      "\n",
      "[Epoch 165 | 42240/42368] loss: 0.3723\n",
      "  Training  | Loss:0.4471 \n",
      " Validation | Loss:0.4413 \n",
      "saving model with loss 0.4413...\n",
      "\n",
      "[Epoch 166 | 42240/42368] loss: 0.4630\n",
      "  Training  | Loss:0.4470 \n",
      " Validation | Loss:0.4412 \n",
      "saving model with loss 0.4412...\n",
      "\n",
      "[Epoch 167 | 42240/42368] loss: 0.5005\n",
      "  Training  | Loss:0.4469 \n",
      " Validation | Loss:0.4411 \n",
      "saving model with loss 0.4411...\n",
      "\n",
      "[Epoch 168 | 42240/42368] loss: 0.4407\n",
      "  Training  | Loss:0.4468 \n",
      " Validation | Loss:0.4409 \n",
      "saving model with loss 0.4409...\n",
      "\n",
      "[Epoch 169 | 42240/42368] loss: 0.3656\n",
      "  Training  | Loss:0.4467 \n",
      " Validation | Loss:0.4408 \n",
      "saving model with loss 0.4408...\n",
      "\n",
      "[Epoch 170 | 42240/42368] loss: 0.3924\n",
      "  Training  | Loss:0.4466 \n",
      " Validation | Loss:0.4407 \n",
      "saving model with loss 0.4407...\n",
      "\n",
      "[Epoch 171 | 42240/42368] loss: 0.5060\n",
      "  Training  | Loss:0.4465 \n",
      " Validation | Loss:0.4406 \n",
      "saving model with loss 0.4406...\n",
      "\n",
      "[Epoch 172 | 42240/42368] loss: 0.4747\n",
      "  Training  | Loss:0.4464 \n",
      " Validation | Loss:0.4405 \n",
      "saving model with loss 0.4405...\n",
      "\n",
      "[Epoch 173 | 42240/42368] loss: 0.4346\n",
      "  Training  | Loss:0.4463 \n",
      " Validation | Loss:0.4404 \n",
      "saving model with loss 0.4404...\n",
      "\n",
      "[Epoch 174 | 42240/42368] loss: 0.3745\n",
      "  Training  | Loss:0.4463 \n",
      " Validation | Loss:0.4403 \n",
      "saving model with loss 0.4403...\n",
      "\n",
      "[Epoch 175 | 42240/42368] loss: 0.4361\n",
      "  Training  | Loss:0.4462 \n",
      " Validation | Loss:0.4402 \n",
      "saving model with loss 0.4402...\n",
      "\n",
      "[Epoch 176 | 42240/42368] loss: 0.3879\n",
      "  Training  | Loss:0.4461 \n",
      " Validation | Loss:0.4400 \n",
      "saving model with loss 0.4400...\n",
      "\n",
      "[Epoch 177 | 42240/42368] loss: 0.4251\n",
      "  Training  | Loss:0.4460 \n",
      " Validation | Loss:0.4399 \n",
      "saving model with loss 0.4399...\n",
      "\n",
      "[Epoch 178 | 42240/42368] loss: 0.3919\n",
      "  Training  | Loss:0.4459 \n",
      " Validation | Loss:0.4398 \n",
      "saving model with loss 0.4398...\n",
      "\n",
      "[Epoch 179 | 42240/42368] loss: 0.4453\n",
      "  Training  | Loss:0.4458 \n",
      " Validation | Loss:0.4397 \n",
      "saving model with loss 0.4397...\n",
      "\n",
      "[Epoch 180 | 42240/42368] loss: 0.4744\n",
      "  Training  | Loss:0.4457 \n",
      " Validation | Loss:0.4396 \n",
      "saving model with loss 0.4396...\n",
      "\n",
      "[Epoch 181 | 42240/42368] loss: 0.4024\n",
      "  Training  | Loss:0.4449 \n",
      " Validation | Loss:0.4372 \n",
      "saving model with loss 0.4372...\n",
      "\n",
      "[Epoch 182 | 42240/42368] loss: 0.3947\n",
      "  Training  | Loss:0.4434 \n",
      " Validation | Loss:0.4370 \n",
      "saving model with loss 0.4370...\n",
      "\n",
      "[Epoch 183 | 42240/42368] loss: 0.4571\n",
      "  Training  | Loss:0.4433 \n",
      " Validation | Loss:0.4369 \n",
      "saving model with loss 0.4369...\n",
      "\n",
      "[Epoch 184 | 42240/42368] loss: 0.4063\n",
      "  Training  | Loss:0.4433 \n",
      " Validation | Loss:0.4368 \n",
      "saving model with loss 0.4368...\n",
      "\n",
      "[Epoch 185 | 42240/42368] loss: 0.4466\n",
      "  Training  | Loss:0.4432 \n",
      " Validation | Loss:0.4367 \n",
      "saving model with loss 0.4367...\n",
      "\n",
      "[Epoch 186 | 42240/42368] loss: 0.4629\n",
      "  Training  | Loss:0.4431 \n",
      " Validation | Loss:0.4366 \n",
      "saving model with loss 0.4366...\n",
      "\n",
      "[Epoch 187 | 42240/42368] loss: 0.4374\n",
      "  Training  | Loss:0.4430 \n",
      " Validation | Loss:0.4365 \n",
      "saving model with loss 0.4365...\n",
      "\n",
      "[Epoch 188 | 42240/42368] loss: 0.3775\n",
      "  Training  | Loss:0.4429 \n",
      " Validation | Loss:0.4364 \n",
      "saving model with loss 0.4364...\n",
      "\n",
      "[Epoch 189 | 42240/42368] loss: 0.4614\n",
      "  Training  | Loss:0.4429 \n",
      " Validation | Loss:0.4363 \n",
      "saving model with loss 0.4363...\n",
      "\n",
      "[Epoch 190 | 42240/42368] loss: 0.4850\n",
      "  Training  | Loss:0.4428 \n",
      " Validation | Loss:0.4362 \n",
      "saving model with loss 0.4362...\n",
      "\n",
      "[Epoch 191 | 42240/42368] loss: 0.4534\n",
      "  Training  | Loss:0.4427 \n",
      " Validation | Loss:0.4361 \n",
      "saving model with loss 0.4361...\n",
      "\n",
      "[Epoch 192 | 42240/42368] loss: 0.4172\n",
      "  Training  | Loss:0.4426 \n",
      " Validation | Loss:0.4360 \n",
      "saving model with loss 0.4360...\n",
      "\n",
      "[Epoch 193 | 42240/42368] loss: 0.4206\n",
      "  Training  | Loss:0.4425 \n",
      " Validation | Loss:0.4359 \n",
      "saving model with loss 0.4359...\n",
      "\n",
      "[Epoch 194 | 42240/42368] loss: 0.3855\n",
      "  Training  | Loss:0.4424 \n",
      " Validation | Loss:0.4358 \n",
      "saving model with loss 0.4358...\n",
      "\n",
      "[Epoch 195 | 42240/42368] loss: 0.3823\n",
      "  Training  | Loss:0.4423 \n",
      " Validation | Loss:0.4356 \n",
      "saving model with loss 0.4356...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 196 | 42240/42368] loss: 0.3794\n",
      "  Training  | Loss:0.4418 \n",
      " Validation | Loss:0.4350 \n",
      "saving model with loss 0.4350...\n",
      "\n",
      "[Epoch 197 | 42240/42368] loss: 0.3973\n",
      "  Training  | Loss:0.4406 \n",
      " Validation | Loss:0.4347 \n",
      "saving model with loss 0.4347...\n",
      "\n",
      "[Epoch 198 | 42240/42368] loss: 0.4387\n",
      "  Training  | Loss:0.4402 \n",
      " Validation | Loss:0.4345 \n",
      "saving model with loss 0.4345...\n",
      "\n",
      "[Epoch 199 | 42240/42368] loss: 0.4748\n",
      "  Training  | Loss:0.4400 \n",
      " Validation | Loss:0.4345 \n",
      "saving model with loss 0.4345...\n",
      "\n",
      "[Epoch 200 | 42240/42368] loss: 0.4366\n",
      "  Training  | Loss:0.4399 \n",
      " Validation | Loss:0.4344 \n",
      "saving model with loss 0.4344...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start training! \n",
    "\n",
    "device = 'cuda:0'\n",
    "model = Net().to(device) \n",
    "model = train(train_dataloader, val_dataloader, model, n_epoch, batch, lr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f183c",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "269463ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and predict testing data\n",
    "\n",
    "best_model = model\n",
    "best_model.load_state_dict(torch.load(\"model.pth\"))\n",
    "best_model = best_model.eval()\n",
    "\n",
    "testset = TestDataset()\n",
    "test_dataloader = DataLoader(testset, 1, False)\n",
    "result = []\n",
    "for x in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    result.append(best_model(x).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bcdf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate (key, probability) pairs\n",
    "\n",
    "keys_to_predict = sorted(public_x_alert_date['alert_key'].values.tolist())\n",
    "pairs = np.array(list(zip(keys_to_predict, result)))\n",
    "sorted_pairs = np.flip(pairs[pairs[:, 1].argsort()], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eafb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate output file \n",
    "\n",
    "example_keys = []\n",
    "with open('example.csv', newline='') as example:\n",
    "    rows = csv.reader(example)\n",
    "    headers = next(rows)\n",
    "    for row in rows:\n",
    "        example_keys.append(int(row[0]))\n",
    "        \n",
    "with open('predict.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['alert_key','probability'])\n",
    "    for row in sorted_pairs:\n",
    "        writer.writerow([int(row[0]), row[1]])\n",
    "    for key in example_keys:\n",
    "        if key not in keys_to_predict:\n",
    "            writer.writerow([key, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
