{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path          = './train_data_first/'\n",
    "data_file_name          = 'public_train_x_{fname}_full_hashed.csv'\n",
    "information_file_name   = 'custinfo'\n",
    "credit_file_name        = 'ccba'\n",
    "consumption_file_name   = 'cdtx0001'\n",
    "remit_file_name         = 'remit1'\n",
    "trading_file_name       = 'dp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_data    = pd.read_csv(data_file_path + data_file_name.format(fname = information_file_name))\n",
    "credit_data         = pd.read_csv(data_file_path + data_file_name.format(fname = credit_file_name), index_col='cust_id')\n",
    "consumption_data    = pd.read_csv(data_file_path + data_file_name.format(fname = consumption_file_name), index_col = 'cust_id')\n",
    "remit_data          = pd.read_csv(data_file_path + data_file_name.format(fname = remit_file_name), index_col = 'cust_id')\n",
    "trading_data        = pd.read_csv(data_file_path + data_file_name.format(fname = trading_file_name), index_col = 'cust_id')\n",
    "train_x = pd.read_csv(data_file_path + 'train_x_alert_date.csv')\n",
    "train_y = pd.read_csv(data_file_path + 'train_y_answer.csv')\n",
    "public_x = pd.read_csv(data_file_path + 'public_x_alert_date.csv')\n",
    "public_y = pd.read_csv('./24_ESun_public_y_answer.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_alert_key = []\n",
    "train_x_alert_date = []\n",
    "train_x_cust_id = []\n",
    "train_x_size = len(train_x)\n",
    "for i in range(train_x_size):\n",
    "    train_x_alert_key.append(train_x['alert_key'][i])\n",
    "    train_x_alert_date.append(train_x['date'][i])\n",
    "    train_x_cust_id.append(information_data['cust_id'][i + 1845])\n",
    "train_x_alert_date = [x for _, x in sorted(zip(train_x_alert_key, train_x_alert_date))]\n",
    "train_x_alert_key.sort()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_alert_key = []\n",
    "train_y_sar_flag = []\n",
    "train_y_size = len(train_y)\n",
    "for i in range(train_y_size):\n",
    "    train_y_alert_key.append(train_y['alert_key'][i])\n",
    "    train_y_sar_flag.append(train_y['sar_flag'][i])\n",
    "train_y_sar_flag = [y for _, y in sorted(zip(train_y_alert_key, train_y_sar_flag))]\n",
    "train_y_alert_key.sort()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $V_{info}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_info = []\n",
    "for i in range(train_x_size):\n",
    "    risk_rank       = information_data['risk_rank'][i + 1845]\n",
    "    occupation_code = information_data['occupation_code'][i + 1845]\n",
    "    total_asset     = information_data['total_asset'][i + 1845]\n",
    "    AGE             = information_data['AGE'][i + 1845]\n",
    "    V_info.append([risk_rank, occupation_code, total_asset, AGE])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $V_{cred}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cred = []\n",
    "month = [0, 30, 61, 91, 122, 153, 183, 214, 244, 275, 306, 334, 365]\n",
    "for i in range(train_x_size):\n",
    "    V_cred_i = []\n",
    "    if train_x_cust_id[i] not in credit_data.index:\n",
    "        V_cred_i = [0] * 117\n",
    "    # search_cust = credit_data[credit_data['cust_id'] == train_x_cust_id[i]]\n",
    "    else:\n",
    "        search_cust = credit_data.loc[[train_x_cust_id[i]]]\n",
    "        for m in month:\n",
    "            search_month = search_cust[search_cust['byymm'] == m]\n",
    "            if len(search_month.to_numpy()) == 0:\n",
    "                V_cred_i.extend([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            elif m > train_x_alert_date[i]:\n",
    "                V_cred_i.extend([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            else:\n",
    "                lupay = search_month['lupay'].to_numpy()[0]\n",
    "                cycam = search_month['cycam'].to_numpy()[0]\n",
    "                usgam = search_month['usgam'].to_numpy()[0]\n",
    "                clamt = search_month['clamt'].to_numpy()[0]\n",
    "                csamt = search_month['csamt'].to_numpy()[0]\n",
    "                inamt = search_month['inamt'].to_numpy()[0]\n",
    "                cucsm = search_month['cucsm'].to_numpy()[0]\n",
    "                cucah = search_month['cucah'].to_numpy()[0]\n",
    "                V_cred_i.extend([m, lupay, cycam, usgam, clamt, csamt, inamt, cucsm, cucah])\n",
    "            \n",
    "    V_cred.append(V_cred_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $V_{cons}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cons = []\n",
    "day = range(1, 394)\n",
    "for i in range(train_x_size):\n",
    "    V_cons_i = []\n",
    "    if train_x_cust_id[i] not in consumption_data.index:\n",
    "        V_cons_i = [0] * 5 * 393\n",
    "    else:\n",
    "        search_cust = consumption_data.loc[[train_x_cust_id[i]]]\n",
    "        for d in day:\n",
    "            search_day = search_cust[search_cust['date'] == d]\n",
    "            n = len(search_day.to_numpy())\n",
    "            if d > train_x_alert_date[i]:\n",
    "                V_cons_i.extend([0, 0, 0, 0, 0])\n",
    "            elif n == 0:\n",
    "                V_cons_i.extend([d, 0, 0, 0, 0])\n",
    "            else:\n",
    "                country = sum(search_day['country'].to_numpy())\n",
    "                cur_type = sum(search_day['cur_type'].to_numpy())\n",
    "                amt = sum(search_day['amt'].to_numpy())\n",
    "                V_cons_i.extend([d, n, country, cur_type, amt])\n",
    "            \n",
    "    V_cons.append(V_cons_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $V_{remit}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_remit = []\n",
    "day = range(1, 394)\n",
    "for i in range(train_x_size):\n",
    "    V_remit_i = []\n",
    "    if train_x_cust_id[i] not in remit_data.index:\n",
    "        V_remit_i = [0] * 4 * 393\n",
    "    else:\n",
    "        search_cust = remit_data.loc[[train_x_cust_id[i]]]\n",
    "        for d in day:\n",
    "            search_day = search_cust[search_cust['trans_date'] == d]\n",
    "            n = len(search_day.to_numpy())\n",
    "            if d > train_x_alert_date[i]:\n",
    "                V_remit_i.extend([0, 0, 0, 0])\n",
    "            elif n == 0:\n",
    "                V_remit_i.extend([d, 0, 0, 0])\n",
    "            else:\n",
    "                trans_no = sum(search_day['trans_no'].to_numpy())\n",
    "                trade_amount_usd = sum(search_day['trade_amount_usd'].to_numpy())\n",
    "                V_remit_i.extend([d, n, trans_no, trade_amount_usd])\n",
    "        \n",
    "    V_remit.append(V_remit_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $V_{trade}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_trade = []\n",
    "day = range(1, 394)\n",
    "for i in range(train_x_size):\n",
    "    V_trade_i = []\n",
    "    if train_x_cust_id[i] not in trading_data.index:\n",
    "        V_trade_i = [0] * 9 * 393\n",
    "    else:\n",
    "        search_cust = trading_data.loc[[train_x_cust_id[i]]]\n",
    "        for d in day:\n",
    "            search_day = search_cust[search_cust['tx_date'] == d]\n",
    "            n = len(search_day.to_numpy())\n",
    "            if d > train_x_alert_date[i]:\n",
    "                V_trade_i.extend([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            elif n == 0:\n",
    "                V_trade_i.extend([d, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            else:\n",
    "                # debit_credit = sum(search_day['debit_credit'].to_numpy())\n",
    "                tx_type = sum(search_day['tx_type'].to_numpy())\n",
    "                tx_amt = sum(search_day['tx_amt'].to_numpy())\n",
    "                info_asset_code = sum(search_day['info_asset_code'].to_numpy())\n",
    "                fiscTxId = sum(search_day['fiscTxId'].to_numpy())\n",
    "                txbranch = sum(search_day['txbranch'].to_numpy())\n",
    "                cross_bank = sum(search_day['cross_bank'].to_numpy())\n",
    "                ATM = sum(search_day['ATM'].to_numpy())\n",
    "                V_trade_i.extend([d, n, tx_type, tx_amt, info_asset_code, fiscTxId, txbranch, cross_bank, ATM])\n",
    "        \n",
    "    V_trade.append(V_trade_i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(V_info).to_csv('./train_data_processed/V_info.csv')\n",
    "pd.DataFrame(V_cred).to_csv('./train_data_processed/V_cred.csv')\n",
    "pd.DataFrame(V_cons).to_csv('./train_data_processed/V_cons.csv')\n",
    "pd.DataFrame(V_remit).to_csv('./train_data_processed/V_remit.csv')\n",
    "pd.DataFrame(V_trade).to_csv('./train_data_processed/V_trade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_y_sar_flag).to_csv('./train_data_processed/train_y.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_x_alert_key = []\n",
    "public_x_alert_date = []\n",
    "public_x_cust_id = []\n",
    "public_x_size = len(public_x)\n",
    "for i in range(public_x_size):\n",
    "    public_x_alert_key.append(public_x['alert_key'][i])\n",
    "    public_x_alert_date.append(public_x['date'][i])\n",
    "    public_x_cust_id.append(information_data['cust_id'][i])\n",
    "public_x_alert_date = [x for _, x in sorted(zip(public_x_alert_key, public_x_alert_date))]\n",
    "public_x_alert_key.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_y_alert_key = []\n",
    "public_y_sar_flag = []\n",
    "public_y_size = len(public_y)\n",
    "for i in range(public_y_size):\n",
    "    public_y_alert_key.append(public_y['alert_key'][i])\n",
    "    public_y_sar_flag.append(public_y['sar_flag'][i])\n",
    "public_y_sar_flag = [y for _, y in sorted(zip(public_y_alert_key, public_y_sar_flag))]\n",
    "public_y_alert_key.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_info_public = []\n",
    "for i in range(public_x_size):\n",
    "    risk_rank       = information_data['risk_rank'][i]\n",
    "    occupation_code = information_data['occupation_code'][i]\n",
    "    total_asset     = information_data['total_asset'][i]\n",
    "    AGE             = information_data['AGE'][i]\n",
    "    V_info_public.append([risk_rank, occupation_code, total_asset, AGE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cred_public = []\n",
    "month = [0, 30, 61, 91, 122, 153, 183, 214, 244, 275, 306, 334, 365]\n",
    "for i in range(public_x_size):\n",
    "    V_cred_public_i = []\n",
    "    if public_x_cust_id[i] not in credit_data.index:\n",
    "        V_cred_public_i = [0] * 117\n",
    "    # search_cust = credit_data[credit_data['cust_id'] == train_x_cust_id[i]]\n",
    "    else:\n",
    "        search_cust = credit_data.loc[[public_x_cust_id[i]]]\n",
    "        for m in month:\n",
    "            search_month = search_cust[search_cust['byymm'] == m]\n",
    "            if len(search_month.to_numpy()) == 0:\n",
    "                V_cred_public_i.extend([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            elif m > public_x_alert_date[i]:\n",
    "                V_cred_public_i.extend([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            else:\n",
    "                lupay = search_month['lupay'].to_numpy()[0]\n",
    "                cycam = search_month['cycam'].to_numpy()[0]\n",
    "                usgam = search_month['usgam'].to_numpy()[0]\n",
    "                clamt = search_month['clamt'].to_numpy()[0]\n",
    "                csamt = search_month['csamt'].to_numpy()[0]\n",
    "                inamt = search_month['inamt'].to_numpy()[0]\n",
    "                cucsm = search_month['cucsm'].to_numpy()[0]\n",
    "                cucah = search_month['cucah'].to_numpy()[0]\n",
    "                V_cred_public_i.extend([m, lupay, cycam, usgam, clamt, csamt, inamt, cucsm, cucah])\n",
    "            \n",
    "    V_cred_public.append(V_cred_public_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_cons_public = []\n",
    "day = range(1, 394)\n",
    "for i in range(public_x_size):\n",
    "    V_cons_public_i = []\n",
    "    if public_x_cust_id[i] not in consumption_data.index:\n",
    "        V_cons_public_i = [0] * 5 * 393\n",
    "    else:\n",
    "        search_cust = consumption_data.loc[[public_x_cust_id[i]]]\n",
    "        for d in day:\n",
    "            search_day = search_cust[search_cust['date'] == d]\n",
    "            n = len(search_day.to_numpy())\n",
    "            if d > public_x_alert_date[i]:\n",
    "                V_cons_public_i.extend([0, 0, 0, 0, 0])\n",
    "            elif n == 0:\n",
    "                V_cons_public_i.extend([d, 0, 0, 0, 0])\n",
    "            else:\n",
    "                country = sum(search_day['country'].to_numpy())\n",
    "                cur_type = sum(search_day['cur_type'].to_numpy())\n",
    "                amt = sum(search_day['amt'].to_numpy())\n",
    "                V_cons_public_i.extend([d, n, country, cur_type, amt])\n",
    "            \n",
    "    V_cons_public.append(V_cons_public_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_remit_public = []\n",
    "day = range(1, 394)\n",
    "for i in range(public_x_size):\n",
    "    V_remit_public_i = []\n",
    "    if public_x_cust_id[i] not in remit_data.index:\n",
    "        V_remit_public_i = [0] * 4 * 393\n",
    "    else:\n",
    "        search_cust = remit_data.loc[[public_x_cust_id[i]]]\n",
    "        for d in day:\n",
    "            search_day = search_cust[search_cust['trans_date'] == d]\n",
    "            n = len(search_day.to_numpy())\n",
    "            if d > public_x_alert_date[i]:\n",
    "                V_remit_public_i.extend([0, 0, 0, 0])\n",
    "            elif n == 0:\n",
    "                V_remit_public_i.extend([d, 0, 0, 0])\n",
    "            else:\n",
    "                trans_no = sum(search_day['trans_no'].to_numpy())\n",
    "                trade_amount_usd = sum(search_day['trade_amount_usd'].to_numpy())\n",
    "                V_remit_public_i.extend([d, n, trans_no, trade_amount_usd])\n",
    "        \n",
    "    V_remit_public.append(V_remit_public_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_trade_public = []\n",
    "day = range(1, 394)\n",
    "for i in range(public_x_size):\n",
    "    V_trade_public_i = []\n",
    "    if public_x_cust_id[i] not in trading_data.index:\n",
    "        V_trade_public_i = [0] * 9 * 393\n",
    "    else:\n",
    "        search_cust = trading_data.loc[[public_x_cust_id[i]]]\n",
    "        for d in day:\n",
    "            search_day = search_cust[search_cust['tx_date'] == d]\n",
    "            n = len(search_day.to_numpy())\n",
    "            if d > public_x_alert_date[i]:\n",
    "                V_trade_public_i.extend([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            elif n == 0:\n",
    "                V_trade_public_i.extend([d, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            else:\n",
    "                # debit_credit = sum(search_day['debit_credit'].to_numpy())\n",
    "                tx_type = sum(search_day['tx_type'].to_numpy())\n",
    "                tx_amt = sum(search_day['tx_amt'].to_numpy())\n",
    "                info_asset_code = sum(search_day['info_asset_code'].to_numpy())\n",
    "                fiscTxId = sum(search_day['fiscTxId'].to_numpy())\n",
    "                txbranch = sum(search_day['txbranch'].to_numpy())\n",
    "                cross_bank = sum(search_day['cross_bank'].to_numpy())\n",
    "                ATM = sum(search_day['ATM'].to_numpy())\n",
    "                V_trade_public_i.extend([d, n, tx_type, tx_amt, info_asset_code, fiscTxId, txbranch, cross_bank, ATM])\n",
    "        \n",
    "    V_trade_public.append(V_trade_public_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(V_info_public).to_csv('./public_data_processed/V_info_public.csv')\n",
    "pd.DataFrame(V_cred_public).to_csv('./public_data_processed/V_cred_public.csv')\n",
    "pd.DataFrame(V_cons_public).to_csv('./public_data_processed/V_cons_public.csv')\n",
    "pd.DataFrame(V_remit_public).to_csv('./public_data_processed/V_remit_public.csv')\n",
    "pd.DataFrame(V_trade_public).to_csv('./public_data_processed/V_trade_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(public_y_sar_flag).to_csv('./public_data_processed/public_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "search_cust1 = credit_data.loc['55e6688f0acbaa20739fe919ba0ac9d7a00430272779c36c9bdde188aea37682']\n",
    "search_cust2 = credit_data.loc['3f97df758617152c9ebda71bfb4922c038a3a274db5faa0b570a07f02672aedc']\n",
    "\n",
    "month = [0]\n",
    "print(type(search_cust1))\n",
    "print(type(search_cust2))\n",
    "# for m in month:\n",
    "#     search_month = search_cust[search_cust['byymm'] == 365]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f383826fdc8333ec187623b360f2bf06d0a39c6f212e1c3c3029be4dd2cc4a75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
