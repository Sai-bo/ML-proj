{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "cbvN_zhuFCbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages."
      ],
      "metadata": {
        "id": "DD__8ohVBhjx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybs7iymbWbER"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset and unzip it."
      ],
      "metadata": {
        "id": "6FrO0GquBkN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1wdlmKyBxd3_UdwOaNgfwx6mt6DMas6uS\n",
        "!gdown 1E22shQHUmSvqkLPe6qGji4TIYArtOAKf\n",
        "!gdown 141AattP4xJ3fm2n9ZWFh1wvSfwVOl7cT\n",
        "!gdown 1XUa6TMZ_ytk3I_jQRJ0iC7tHQWUAZghw\n",
        "!gdown 1FIMWCzeRN9C6NurXyq4NnnUc5W1DeMDk\n",
        "!gdown 1n4haJzeyPJxPm2ukVBg1sM84CSmJimV8\n",
        "\n",
        "\n",
        "!gdown 1RKM_eyCjuUPG50Kl6azWnkOaPkHObBld\n",
        "!gdown 1IncHTNbn7GJ69tCHzKDRpNPTYKzX7Ias\n",
        "!gdown 1dq2zpR9N0OXtqR-qhQE0ny5H1RT4oOG7\n",
        "!gdown 16Ll_Q041wFe1PSGULeLph3oQSKH6_yNg\n",
        "!gdown 1qhkb3-__1Ubl47Sicsfniy1JtDUXE0Zf\n",
        "!gdown 1P6LT9FnLx3vuXcD7402dBhQIJQw5EwBo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRjym0iYOoPN",
        "outputId": "6519bc87-f77e-4f94-be7b-764d37244160"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wdlmKyBxd3_UdwOaNgfwx6mt6DMas6uS\n",
            "To: /content/train_y.csv\n",
            "100% 180k/180k [00:00<00:00, 82.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1E22shQHUmSvqkLPe6qGji4TIYArtOAKf\n",
            "To: /content/V_trade.csv\n",
            "100% 7.28M/7.28M [00:00<00:00, 135MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=141AattP4xJ3fm2n9ZWFh1wvSfwVOl7cT\n",
            "To: /content/V_remit.csv\n",
            "100% 2.80M/2.80M [00:00<00:00, 154MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XUa6TMZ_ytk3I_jQRJ0iC7tHQWUAZghw\n",
            "To: /content/V_info.csv\n",
            "100% 533k/533k [00:00<00:00, 118MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FIMWCzeRN9C6NurXyq4NnnUc5W1DeMDk\n",
            "To: /content/V_cons.csv\n",
            "100% 4.96M/4.96M [00:00<00:00, 25.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n4haJzeyPJxPm2ukVBg1sM84CSmJimV8\n",
            "To: /content/V_cred.csv\n",
            "100% 13.5M/13.5M [00:00<00:00, 198MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RKM_eyCjuUPG50Kl6azWnkOaPkHObBld\n",
            "To: /content/V_trade_public.csv\n",
            "100% 564k/564k [00:00<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IncHTNbn7GJ69tCHzKDRpNPTYKzX7Ias\n",
            "To: /content/V_remit_public.csv\n",
            "100% 216k/216k [00:00<00:00, 86.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dq2zpR9N0OXtqR-qhQE0ny5H1RT4oOG7\n",
            "To: /content/V_info_public.csv\n",
            "100% 39.8k/39.8k [00:00<00:00, 42.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16Ll_Q041wFe1PSGULeLph3oQSKH6_yNg\n",
            "To: /content/V_cred_public.csv\n",
            "100% 1.00M/1.00M [00:00<00:00, 91.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qhkb3-__1Ubl47Sicsfniy1JtDUXE0Zf\n",
            "To: /content/V_cons_public.csv\n",
            "100% 369k/369k [00:00<00:00, 103MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1P6LT9FnLx3vuXcD7402dBhQIJQw5EwBo\n",
            "To: /content/public_y.csv\n",
            "100% 11.8k/11.8k [00:00<00:00, 14.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic setup of hyperparameters"
      ],
      "metadata": {
        "id": "uNA6q0rnBwHP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VX5NXp4WbEi"
      },
      "source": [
        "'''\n",
        "BATCH_SIZE = 256\n",
        "EPOCH_NUM = 50\n",
        "MAX_POSITIONS_LEN = 100\n",
        "SEED = 97562246875 % (2**32-1) # Set your lucky number as the random seed\n",
        "MODEL_DIR = 'model.pth'\n",
        "lr = 5 * 1e-4\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "w2v_config = {'path': 'w2v.model', 'dim': 128}\n",
        "net_config = {'hidden_dim': 64, 'num_layers': 3, 'bidirectional': False, 'fix_embedding': True}\n",
        "header_config = {'dropout': 0.5, 'hidden_dim': 64}\n",
        "assert header_config['hidden_dim'] == net_config['hidden_dim'] or header_config['hidden_dim'] == net_config['hidden_dim'] * 2\n",
        "'''"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine all V_ together"
      ],
      "metadata": {
        "id": "FxOddxufB2dr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7PZMBJSWbEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4306c6-3922-46e1-e9a1-8d8f01b38512"
      },
      "source": [
        "V_cred = pd.read_csv(\"V_cred.csv\", index_col=0) \n",
        "V_info = pd.read_csv(\"V_info.csv\", index_col=0)             \n",
        "V_remit = pd.read_csv(\"V_remit.csv\", index_col=0) \n",
        "V_cons = pd.read_csv(\"V_cons.csv\", index_col=0)             \n",
        "V_trade = pd.read_csv(\"V_trade.csv\", index_col=0) \n",
        "train_y = pd.read_csv(\"train_y.csv\", index_col=0)\n",
        "\n",
        "V_cred_public = pd.read_csv(\"V_cred_public.csv\", index_col=0) \n",
        "V_info_public = pd.read_csv(\"V_info_public.csv\", index_col=0)             \n",
        "V_remit_public = pd.read_csv(\"V_remit_public.csv\", index_col=0) \n",
        "V_cons_public = pd.read_csv(\"V_cons_public.csv\", index_col=0)             \n",
        "V_trade_public = pd.read_csv(\"V_trade_public.csv\", index_col=0) \n",
        "public_y = pd.read_csv(\"public_y.csv\", index_col=0)\n",
        "\n",
        "print(V_cred.shape)\n",
        "print(V_info.shape)\n",
        "print(V_remit.shape)\n",
        "print(V_cons.shape)\n",
        "print(V_trade.shape)\n",
        "print(train_y.shape)\n",
        "\n",
        "V_part = [ pd.concat([V_info, \n",
        "                      V_cred.iloc[:,8*i:8*(i+1)],\n",
        "                      V_remit.iloc[:,3*i:3*(i+1)],\n",
        "                      V_cons.iloc[:,4*i:4*(i+1)],\n",
        "                      V_trade.iloc[:,7*i:7*(i+1)]], axis=1) for i in range (13)]\n",
        "V_all = pd.concat([V_part[i] for i in range (13)], axis = 1)\n",
        "V_all = (V_all-V_all.mean())/V_all.std()\n",
        "print(V_all.shape) # put all data together (23906 * 338)\n",
        "\n",
        "V_part_public = [ pd.concat([V_info_public, \n",
        "                      V_cred_public.iloc[:,8*i:8*(i+1)],\n",
        "                      V_remit_public.iloc[:,3*i:3*(i+1)],\n",
        "                      V_cons_public.iloc[:,4*i:4*(i+1)],\n",
        "                      V_trade_public.iloc[:,7*i:7*(i+1)]], axis=1) for i in range (13)]\n",
        "V_all_public = pd.concat([V_part_public[i] for i in range (13)], axis = 1)\n",
        "V_all_public = (V_all_public-V_all_public.mean())/V_all_public.std()\n",
        "print(V_all_public.shape) # put all data together (1845 * 338)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23906, 104)\n",
            "(23906, 4)\n",
            "(23906, 39)\n",
            "(23906, 52)\n",
            "(23906, 91)\n",
            "(23906, 1)\n",
            "(23906, 338)\n",
            "(1845, 338)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "oversampling"
      ],
      "metadata": {
        "id": "83zpsxWuTf7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# oversampling\n",
        "\n",
        "SAR_idx = []\n",
        "for i in range (len(train_Y)):\n",
        "    if (train_Y.iloc[i,0] == 1):\n",
        "        SAR_idx.append(i)\n",
        "print(len(SAR_idx), SAR_idx)\n",
        "\n",
        "for i in range (len(SAR_idx)):\n",
        "    if (i % 50 == 0):\n",
        "        print(i, \"/\", len(SAR_idx))\n",
        "    for j in range (30):\n",
        "        V_cred.loc[len(V_cred)] = V_remit.loc[SAR_idx[i]]\n",
        "print(V_cred)\n",
        "'''"
      ],
      "metadata": {
        "id": "oAkJuOXFTfUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.LSTM(units = 50, return_sequences = True, input_shape = (13,26)))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "#model.add(keras.layers.LSTM(units = 50, return_sequences = True))\n",
        "#model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.LSTM(units = 50))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer='nadam')\n",
        "\n",
        "#model = keras.models.load_model('path/to/location')\n",
        "\n",
        "\n",
        "tempx = np.array(V_all)\n",
        "tempy = np.array(train_y)\n",
        "tempx = np.reshape(tempx, (tempx.shape[0], 13, -1))\n",
        "tempx[np.isnan(tempx)] = 0\n",
        "print(tempx.shape)\n",
        "model.fit(tempx, tempy, epochs = 50, batch_size = 32, class_weight = {0:1, 1:100})\n",
        "\n",
        "model.save('model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwjcyQq7VL7u",
        "outputId": "d1d946c9-859c-46f7-ccfd-9f86e3e12831"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23906, 13, 26)\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "748/748 [==============================] - 18s 18ms/step - loss: 1.2768\n",
            "Epoch 2/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 1.1778\n",
            "Epoch 3/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 1.1421\n",
            "Epoch 4/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 1.1077\n",
            "Epoch 5/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 1.0872\n",
            "Epoch 6/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 1.0296\n",
            "Epoch 7/50\n",
            "748/748 [==============================] - 14s 18ms/step - loss: 1.0292\n",
            "Epoch 8/50\n",
            "748/748 [==============================] - 14s 19ms/step - loss: 0.9537\n",
            "Epoch 9/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.9604\n",
            "Epoch 10/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.9141\n",
            "Epoch 11/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.8699\n",
            "Epoch 12/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.8444\n",
            "Epoch 13/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.8620\n",
            "Epoch 14/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.8366\n",
            "Epoch 15/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.8304\n",
            "Epoch 16/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.7864\n",
            "Epoch 17/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.7598\n",
            "Epoch 18/50\n",
            "748/748 [==============================] - 14s 19ms/step - loss: 0.7386\n",
            "Epoch 19/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.7485\n",
            "Epoch 20/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.7437\n",
            "Epoch 21/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6797\n",
            "Epoch 22/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.7076\n",
            "Epoch 23/50\n",
            "748/748 [==============================] - 14s 18ms/step - loss: 0.7263\n",
            "Epoch 24/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.7242\n",
            "Epoch 25/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6742\n",
            "Epoch 26/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6667\n",
            "Epoch 27/50\n",
            "748/748 [==============================] - 17s 23ms/step - loss: 0.6328\n",
            "Epoch 28/50\n",
            "748/748 [==============================] - 15s 20ms/step - loss: 0.6527\n",
            "Epoch 29/50\n",
            "748/748 [==============================] - 15s 20ms/step - loss: 0.6965\n",
            "Epoch 30/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6533\n",
            "Epoch 31/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6420\n",
            "Epoch 32/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6176\n",
            "Epoch 33/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6491\n",
            "Epoch 34/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.5863\n",
            "Epoch 35/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6567\n",
            "Epoch 36/50\n",
            "748/748 [==============================] - 14s 19ms/step - loss: 0.6100\n",
            "Epoch 37/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.5906\n",
            "Epoch 38/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.5599\n",
            "Epoch 39/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.6005\n",
            "Epoch 40/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.6106\n",
            "Epoch 41/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.6082\n",
            "Epoch 42/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.5586\n",
            "Epoch 43/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.5850\n",
            "Epoch 44/50\n",
            "748/748 [==============================] - 13s 18ms/step - loss: 0.5927\n",
            "Epoch 45/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.5635\n",
            "Epoch 46/50\n",
            "748/748 [==============================] - 14s 19ms/step - loss: 0.5470\n",
            "Epoch 47/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.5783\n",
            "Epoch 48/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.5325\n",
            "Epoch 49/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.5300\n",
            "Epoch 50/50\n",
            "748/748 [==============================] - 13s 17ms/step - loss: 0.5043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_21_layer_call_fn, lstm_cell_21_layer_call_and_return_conditional_losses, lstm_cell_22_layer_call_fn, lstm_cell_22_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_score(model, x, y):\n",
        "    prediction = model.predict(x)\n",
        "    print(prediction, prediction.shape)\n",
        "    result = pd.concat([pd.DataFrame(prediction, columns=[\"prob\"]), pd.DataFrame(y)], axis=1) \n",
        "    result = result.sort_values(by = 'prob')\n",
        "    print(result)\n",
        "    for i in range (len(result)):\n",
        "        if (result.iloc[i,1] == 1):\n",
        "            print(\"The\", i, \"th lowest prediction has SAR with prob\", result.iloc[i,0])\n",
        "\n",
        "!zip -r model.zip model.pth\n",
        "from google.colab import files\n",
        "files.download(\"model.zip\")\n",
        "\n",
        "check_score(model, tempx, tempy)\n",
        "testx = np.array(V_all_public)\n",
        "testy = np.array(public_y)\n",
        "testx = np.reshape(testx, (testx.shape[0], 13, -1))\n",
        "testx[np.isnan(testx)] = 0\n",
        "\n",
        "SAR_idx = []\n",
        "for i in range (len(public_y)):\n",
        "    if (public_y.iloc[i,0] == 1):\n",
        "        SAR_idx.append(i)\n",
        "print(len(SAR_idx), SAR_idx)\n",
        "check_score(model, testx, testy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZeQcGAotjr3u",
        "outputId": "5d539f9d-6aa3-4f42-d3ae-f3290a873e99"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model.pth/ (stored 0%)\n",
            "  adding: model.pth/variables/ (stored 0%)\n",
            "  adding: model.pth/variables/variables.index (deflated 63%)\n",
            "  adding: model.pth/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model.pth/saved_model.pb (deflated 90%)\n",
            "  adding: model.pth/assets/ (stored 0%)\n",
            "  adding: model.pth/keras_metadata.pb (deflated 90%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6982ef58-050f-40f0-9666-4af15ce9491d\", \"model.zip\", 548894)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "748/748 [==============================] - 5s 6ms/step\n",
            "[[2.4444619e-04]\n",
            " [6.1140767e-05]\n",
            " [8.6536998e-01]\n",
            " ...\n",
            " [5.4440283e-05]\n",
            " [2.6745145e-04]\n",
            " [9.3435854e-05]] (23906, 1)\n",
            "           prob  0\n",
            "1913   0.000020  0\n",
            "2092   0.000020  0\n",
            "5731   0.000021  0\n",
            "2305   0.000021  0\n",
            "23789  0.000022  0\n",
            "...         ... ..\n",
            "8357   0.993268  1\n",
            "6686   0.994810  1\n",
            "7995   0.994894  1\n",
            "14879  0.995880  1\n",
            "17369  0.998028  1\n",
            "\n",
            "[23906 rows x 2 columns]\n",
            "The 19191 th lowest prediction has SAR with prob 0.25234562\n",
            "The 19221 th lowest prediction has SAR with prob 0.25619867\n",
            "The 19312 th lowest prediction has SAR with prob 0.26723936\n",
            "The 19770 th lowest prediction has SAR with prob 0.337388\n",
            "The 19940 th lowest prediction has SAR with prob 0.35705876\n",
            "The 20187 th lowest prediction has SAR with prob 0.40423423\n",
            "The 20189 th lowest prediction has SAR with prob 0.40484288\n",
            "The 20561 th lowest prediction has SAR with prob 0.49177474\n",
            "The 20785 th lowest prediction has SAR with prob 0.5343445\n",
            "The 20845 th lowest prediction has SAR with prob 0.53990394\n",
            "The 20919 th lowest prediction has SAR with prob 0.5426812\n",
            "The 20943 th lowest prediction has SAR with prob 0.54736495\n",
            "The 21070 th lowest prediction has SAR with prob 0.57107776\n",
            "The 21135 th lowest prediction has SAR with prob 0.5836808\n",
            "The 21144 th lowest prediction has SAR with prob 0.5855124\n",
            "The 21146 th lowest prediction has SAR with prob 0.58599836\n",
            "The 21158 th lowest prediction has SAR with prob 0.5895082\n",
            "The 21164 th lowest prediction has SAR with prob 0.5918198\n",
            "The 21171 th lowest prediction has SAR with prob 0.5945529\n",
            "The 21183 th lowest prediction has SAR with prob 0.5968026\n",
            "The 21204 th lowest prediction has SAR with prob 0.60284907\n",
            "The 21371 th lowest prediction has SAR with prob 0.6550251\n",
            "The 21461 th lowest prediction has SAR with prob 0.6737614\n",
            "The 21465 th lowest prediction has SAR with prob 0.6745909\n",
            "The 21533 th lowest prediction has SAR with prob 0.69615376\n",
            "The 21542 th lowest prediction has SAR with prob 0.7012801\n",
            "The 21552 th lowest prediction has SAR with prob 0.7059643\n",
            "The 21556 th lowest prediction has SAR with prob 0.7070974\n",
            "The 21561 th lowest prediction has SAR with prob 0.7081112\n",
            "The 21584 th lowest prediction has SAR with prob 0.71395767\n",
            "The 21588 th lowest prediction has SAR with prob 0.7154483\n",
            "The 21741 th lowest prediction has SAR with prob 0.7398335\n",
            "The 21742 th lowest prediction has SAR with prob 0.7399361\n",
            "The 21765 th lowest prediction has SAR with prob 0.74547887\n",
            "The 21803 th lowest prediction has SAR with prob 0.7511183\n",
            "The 21822 th lowest prediction has SAR with prob 0.7545527\n",
            "The 21860 th lowest prediction has SAR with prob 0.76368266\n",
            "The 21862 th lowest prediction has SAR with prob 0.76375717\n",
            "The 21890 th lowest prediction has SAR with prob 0.76628745\n",
            "The 21891 th lowest prediction has SAR with prob 0.7663794\n",
            "The 21905 th lowest prediction has SAR with prob 0.7677258\n",
            "The 21907 th lowest prediction has SAR with prob 0.76785517\n",
            "The 21919 th lowest prediction has SAR with prob 0.77086025\n",
            "The 21943 th lowest prediction has SAR with prob 0.7715236\n",
            "The 21959 th lowest prediction has SAR with prob 0.7757468\n",
            "The 21960 th lowest prediction has SAR with prob 0.7757678\n",
            "The 21976 th lowest prediction has SAR with prob 0.77701885\n",
            "The 21980 th lowest prediction has SAR with prob 0.77787364\n",
            "The 22189 th lowest prediction has SAR with prob 0.7956206\n",
            "The 22204 th lowest prediction has SAR with prob 0.7957618\n",
            "The 22245 th lowest prediction has SAR with prob 0.7999793\n",
            "The 22248 th lowest prediction has SAR with prob 0.80046266\n",
            "The 22255 th lowest prediction has SAR with prob 0.80133927\n",
            "The 22277 th lowest prediction has SAR with prob 0.8044163\n",
            "The 22283 th lowest prediction has SAR with prob 0.80573225\n",
            "The 22288 th lowest prediction has SAR with prob 0.8060065\n",
            "The 22292 th lowest prediction has SAR with prob 0.806592\n",
            "The 22326 th lowest prediction has SAR with prob 0.8083684\n",
            "The 22329 th lowest prediction has SAR with prob 0.8086685\n",
            "The 22334 th lowest prediction has SAR with prob 0.809571\n",
            "The 22375 th lowest prediction has SAR with prob 0.81208104\n",
            "The 22389 th lowest prediction has SAR with prob 0.8132385\n",
            "The 22417 th lowest prediction has SAR with prob 0.8149826\n",
            "The 22433 th lowest prediction has SAR with prob 0.81590044\n",
            "The 22457 th lowest prediction has SAR with prob 0.81879884\n",
            "The 22529 th lowest prediction has SAR with prob 0.82256246\n",
            "The 22532 th lowest prediction has SAR with prob 0.8226156\n",
            "The 22551 th lowest prediction has SAR with prob 0.823857\n",
            "The 22564 th lowest prediction has SAR with prob 0.8250257\n",
            "The 22568 th lowest prediction has SAR with prob 0.82601774\n",
            "The 22646 th lowest prediction has SAR with prob 0.82897115\n",
            "The 22647 th lowest prediction has SAR with prob 0.8291016\n",
            "The 22649 th lowest prediction has SAR with prob 0.8292996\n",
            "The 22668 th lowest prediction has SAR with prob 0.83199257\n",
            "The 22674 th lowest prediction has SAR with prob 0.832658\n",
            "The 22698 th lowest prediction has SAR with prob 0.83437157\n",
            "The 22757 th lowest prediction has SAR with prob 0.83829457\n",
            "The 22844 th lowest prediction has SAR with prob 0.8422933\n",
            "The 22860 th lowest prediction has SAR with prob 0.8435055\n",
            "The 22861 th lowest prediction has SAR with prob 0.84383905\n",
            "The 22868 th lowest prediction has SAR with prob 0.8439854\n",
            "The 22907 th lowest prediction has SAR with prob 0.8460925\n",
            "The 22913 th lowest prediction has SAR with prob 0.84670687\n",
            "The 22916 th lowest prediction has SAR with prob 0.8468215\n",
            "The 22940 th lowest prediction has SAR with prob 0.84798616\n",
            "The 22945 th lowest prediction has SAR with prob 0.8486269\n",
            "The 22957 th lowest prediction has SAR with prob 0.84973425\n",
            "The 22964 th lowest prediction has SAR with prob 0.84998554\n",
            "The 22970 th lowest prediction has SAR with prob 0.85082096\n",
            "The 22972 th lowest prediction has SAR with prob 0.8511668\n",
            "The 22994 th lowest prediction has SAR with prob 0.8523935\n",
            "The 23013 th lowest prediction has SAR with prob 0.85363793\n",
            "The 23070 th lowest prediction has SAR with prob 0.8602879\n",
            "The 23103 th lowest prediction has SAR with prob 0.8617159\n",
            "The 23126 th lowest prediction has SAR with prob 0.8636589\n",
            "The 23170 th lowest prediction has SAR with prob 0.8654309\n",
            "The 23191 th lowest prediction has SAR with prob 0.8672781\n",
            "The 23192 th lowest prediction has SAR with prob 0.8672967\n",
            "The 23220 th lowest prediction has SAR with prob 0.8710243\n",
            "The 23224 th lowest prediction has SAR with prob 0.87195057\n",
            "The 23235 th lowest prediction has SAR with prob 0.8732041\n",
            "The 23245 th lowest prediction has SAR with prob 0.87350327\n",
            "The 23262 th lowest prediction has SAR with prob 0.87472504\n",
            "The 23272 th lowest prediction has SAR with prob 0.8762217\n",
            "The 23278 th lowest prediction has SAR with prob 0.87706685\n",
            "The 23288 th lowest prediction has SAR with prob 0.87978953\n",
            "The 23289 th lowest prediction has SAR with prob 0.88003474\n",
            "The 23295 th lowest prediction has SAR with prob 0.8809793\n",
            "The 23300 th lowest prediction has SAR with prob 0.88193357\n",
            "The 23302 th lowest prediction has SAR with prob 0.88270694\n",
            "The 23308 th lowest prediction has SAR with prob 0.8833438\n",
            "The 23321 th lowest prediction has SAR with prob 0.8869377\n",
            "The 23329 th lowest prediction has SAR with prob 0.8897436\n",
            "The 23351 th lowest prediction has SAR with prob 0.89476556\n",
            "The 23355 th lowest prediction has SAR with prob 0.8949691\n",
            "The 23367 th lowest prediction has SAR with prob 0.8982175\n",
            "The 23381 th lowest prediction has SAR with prob 0.9016483\n",
            "The 23387 th lowest prediction has SAR with prob 0.90324557\n",
            "The 23389 th lowest prediction has SAR with prob 0.9039544\n",
            "The 23411 th lowest prediction has SAR with prob 0.9094099\n",
            "The 23430 th lowest prediction has SAR with prob 0.91133046\n",
            "The 23441 th lowest prediction has SAR with prob 0.91304874\n",
            "The 23449 th lowest prediction has SAR with prob 0.91518384\n",
            "The 23452 th lowest prediction has SAR with prob 0.91556543\n",
            "The 23464 th lowest prediction has SAR with prob 0.91986424\n",
            "The 23467 th lowest prediction has SAR with prob 0.92068624\n",
            "The 23475 th lowest prediction has SAR with prob 0.92133135\n",
            "The 23477 th lowest prediction has SAR with prob 0.9213859\n",
            "The 23487 th lowest prediction has SAR with prob 0.92407465\n",
            "The 23499 th lowest prediction has SAR with prob 0.9267729\n",
            "The 23505 th lowest prediction has SAR with prob 0.9272623\n",
            "The 23553 th lowest prediction has SAR with prob 0.9322965\n",
            "The 23554 th lowest prediction has SAR with prob 0.93256223\n",
            "The 23555 th lowest prediction has SAR with prob 0.93277335\n",
            "The 23561 th lowest prediction has SAR with prob 0.9338145\n",
            "The 23566 th lowest prediction has SAR with prob 0.9344373\n",
            "The 23570 th lowest prediction has SAR with prob 0.93473345\n",
            "The 23580 th lowest prediction has SAR with prob 0.93536896\n",
            "The 23610 th lowest prediction has SAR with prob 0.9372165\n",
            "The 23618 th lowest prediction has SAR with prob 0.93794966\n",
            "The 23621 th lowest prediction has SAR with prob 0.9382932\n",
            "The 23624 th lowest prediction has SAR with prob 0.9387521\n",
            "The 23633 th lowest prediction has SAR with prob 0.9434118\n",
            "The 23634 th lowest prediction has SAR with prob 0.94399625\n",
            "The 23637 th lowest prediction has SAR with prob 0.94494474\n",
            "The 23641 th lowest prediction has SAR with prob 0.9455726\n",
            "The 23644 th lowest prediction has SAR with prob 0.94610137\n",
            "The 23646 th lowest prediction has SAR with prob 0.94654804\n",
            "The 23647 th lowest prediction has SAR with prob 0.9466489\n",
            "The 23682 th lowest prediction has SAR with prob 0.95190895\n",
            "The 23686 th lowest prediction has SAR with prob 0.95271087\n",
            "The 23695 th lowest prediction has SAR with prob 0.9545917\n",
            "The 23698 th lowest prediction has SAR with prob 0.9552019\n",
            "The 23700 th lowest prediction has SAR with prob 0.9562647\n",
            "The 23701 th lowest prediction has SAR with prob 0.95694107\n",
            "The 23702 th lowest prediction has SAR with prob 0.9569675\n",
            "The 23711 th lowest prediction has SAR with prob 0.95765954\n",
            "The 23716 th lowest prediction has SAR with prob 0.95848167\n",
            "The 23720 th lowest prediction has SAR with prob 0.95978355\n",
            "The 23723 th lowest prediction has SAR with prob 0.96156794\n",
            "The 23732 th lowest prediction has SAR with prob 0.9636671\n",
            "The 23735 th lowest prediction has SAR with prob 0.963906\n",
            "The 23741 th lowest prediction has SAR with prob 0.96427214\n",
            "The 23749 th lowest prediction has SAR with prob 0.96481806\n",
            "The 23752 th lowest prediction has SAR with prob 0.9655471\n",
            "The 23753 th lowest prediction has SAR with prob 0.9660236\n",
            "The 23754 th lowest prediction has SAR with prob 0.9661965\n",
            "The 23757 th lowest prediction has SAR with prob 0.96667516\n",
            "The 23760 th lowest prediction has SAR with prob 0.968995\n",
            "The 23761 th lowest prediction has SAR with prob 0.9696666\n",
            "The 23762 th lowest prediction has SAR with prob 0.9697766\n",
            "The 23765 th lowest prediction has SAR with prob 0.97074854\n",
            "The 23766 th lowest prediction has SAR with prob 0.97101825\n",
            "The 23769 th lowest prediction has SAR with prob 0.97107136\n",
            "The 23770 th lowest prediction has SAR with prob 0.9710816\n",
            "The 23772 th lowest prediction has SAR with prob 0.97156227\n",
            "The 23779 th lowest prediction has SAR with prob 0.97306055\n",
            "The 23780 th lowest prediction has SAR with prob 0.97313786\n",
            "The 23784 th lowest prediction has SAR with prob 0.97391164\n",
            "The 23787 th lowest prediction has SAR with prob 0.97432154\n",
            "The 23794 th lowest prediction has SAR with prob 0.97481346\n",
            "The 23795 th lowest prediction has SAR with prob 0.9749455\n",
            "The 23798 th lowest prediction has SAR with prob 0.9758281\n",
            "The 23799 th lowest prediction has SAR with prob 0.97588116\n",
            "The 23803 th lowest prediction has SAR with prob 0.9772127\n",
            "The 23808 th lowest prediction has SAR with prob 0.97785\n",
            "The 23809 th lowest prediction has SAR with prob 0.97789246\n",
            "The 23812 th lowest prediction has SAR with prob 0.9785843\n",
            "The 23813 th lowest prediction has SAR with prob 0.97869545\n",
            "The 23816 th lowest prediction has SAR with prob 0.97965366\n",
            "The 23817 th lowest prediction has SAR with prob 0.98003453\n",
            "The 23819 th lowest prediction has SAR with prob 0.9818308\n",
            "The 23820 th lowest prediction has SAR with prob 0.9826886\n",
            "The 23823 th lowest prediction has SAR with prob 0.98305255\n",
            "The 23824 th lowest prediction has SAR with prob 0.98308694\n",
            "The 23828 th lowest prediction has SAR with prob 0.98369443\n",
            "The 23839 th lowest prediction has SAR with prob 0.9840194\n",
            "The 23840 th lowest prediction has SAR with prob 0.9845278\n",
            "The 23842 th lowest prediction has SAR with prob 0.98458564\n",
            "The 23844 th lowest prediction has SAR with prob 0.985396\n",
            "The 23845 th lowest prediction has SAR with prob 0.98554164\n",
            "The 23854 th lowest prediction has SAR with prob 0.9858756\n",
            "The 23858 th lowest prediction has SAR with prob 0.9875395\n",
            "The 23859 th lowest prediction has SAR with prob 0.9875459\n",
            "The 23860 th lowest prediction has SAR with prob 0.9877566\n",
            "The 23861 th lowest prediction has SAR with prob 0.987973\n",
            "The 23863 th lowest prediction has SAR with prob 0.9882792\n",
            "The 23866 th lowest prediction has SAR with prob 0.98878336\n",
            "The 23867 th lowest prediction has SAR with prob 0.9888674\n",
            "The 23876 th lowest prediction has SAR with prob 0.9891542\n",
            "The 23877 th lowest prediction has SAR with prob 0.9894754\n",
            "The 23880 th lowest prediction has SAR with prob 0.9899373\n",
            "The 23881 th lowest prediction has SAR with prob 0.9899571\n",
            "The 23883 th lowest prediction has SAR with prob 0.9902492\n",
            "The 23884 th lowest prediction has SAR with prob 0.99051964\n",
            "The 23885 th lowest prediction has SAR with prob 0.9905929\n",
            "The 23886 th lowest prediction has SAR with prob 0.99065\n",
            "The 23887 th lowest prediction has SAR with prob 0.9908019\n",
            "The 23888 th lowest prediction has SAR with prob 0.99091035\n",
            "The 23890 th lowest prediction has SAR with prob 0.99104595\n",
            "The 23891 th lowest prediction has SAR with prob 0.99107\n",
            "The 23892 th lowest prediction has SAR with prob 0.991737\n",
            "The 23893 th lowest prediction has SAR with prob 0.99180186\n",
            "The 23894 th lowest prediction has SAR with prob 0.99193406\n",
            "The 23895 th lowest prediction has SAR with prob 0.99202573\n",
            "The 23896 th lowest prediction has SAR with prob 0.99221057\n",
            "The 23898 th lowest prediction has SAR with prob 0.9924032\n",
            "The 23899 th lowest prediction has SAR with prob 0.9926155\n",
            "The 23900 th lowest prediction has SAR with prob 0.99313104\n",
            "The 23901 th lowest prediction has SAR with prob 0.9932682\n",
            "The 23902 th lowest prediction has SAR with prob 0.9948102\n",
            "The 23903 th lowest prediction has SAR with prob 0.99489427\n",
            "The 23904 th lowest prediction has SAR with prob 0.99587977\n",
            "The 23905 th lowest prediction has SAR with prob 0.9980283\n",
            "11 [327, 345, 351, 446, 592, 908, 1080, 1384, 1550, 1593, 1659]\n",
            "58/58 [==============================] - 0s 6ms/step\n",
            "[[4.7325226e-05]\n",
            " [4.0236756e-02]\n",
            " [1.2531118e-03]\n",
            " ...\n",
            " [8.2116807e-05]\n",
            " [5.9941381e-01]\n",
            " [1.1279846e-04]] (1845, 1)\n",
            "          prob  0\n",
            "143   0.000021  0\n",
            "228   0.000021  0\n",
            "354   0.000021  0\n",
            "267   0.000024  0\n",
            "388   0.000024  0\n",
            "...        ... ..\n",
            "1482  0.970445  0\n",
            "212   0.974719  0\n",
            "917   0.982926  0\n",
            "1340  0.982926  0\n",
            "1326  0.982993  0\n",
            "\n",
            "[1845 rows x 2 columns]\n",
            "The 89 th lowest prediction has SAR with prob 4.144469e-05\n",
            "The 129 th lowest prediction has SAR with prob 4.6167446e-05\n",
            "The 789 th lowest prediction has SAR with prob 0.0013073861\n",
            "The 1068 th lowest prediction has SAR with prob 0.046151683\n",
            "The 1069 th lowest prediction has SAR with prob 0.04774298\n",
            "The 1070 th lowest prediction has SAR with prob 0.04774298\n",
            "The 1387 th lowest prediction has SAR with prob 0.55911285\n",
            "The 1441 th lowest prediction has SAR with prob 0.64166254\n",
            "The 1668 th lowest prediction has SAR with prob 0.84554857\n",
            "The 1760 th lowest prediction has SAR with prob 0.87399757\n",
            "The 1792 th lowest prediction has SAR with prob 0.8873805\n"
          ]
        }
      ]
    }
  ]
}